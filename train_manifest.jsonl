{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/1_0.wav", "duration": 46.0, "text": "hello everyone welcome to lecture one of cs7 fifteen which is the course on deep learning in today\u2019s lecture is going to be a bit non technical we are not going to cover any technical concepts or we only going to talk about a brief or partial history of deep learning so we hear the terms artificial neural networks artificial neurons quite often these days and i just wanted you take you through the journey of where does all these originate from and this history contains several spans across several fields not just computer science we will start with biology then talk about something in physics then eventually come to computer science and so on so with that let us start"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/1_1.wav", "duration": 28.0, "text": "so just some acknowledgments and disclaimers i have taken lot of this material from the first people which i have mentioned on the bullet and there might still be some errors because its dates as back as one thousand, eight hundred and seventy-one so maybe i have got some of the facts wrong so feel free to contact me if you think some of these portions need to be corrected and it would be good if you could provide me appropriate references for these corrections so let us start with the first chapter which is on biological neurons as i said its spans several fields will start with biology"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/1_2.wav", "duration": 31.0, "text": "and we will first talk about the brain and neurons within the brainso way back in one thousand, eight hundred and seventy-one one thousand, eight hundred and seventy-three around that time joseph von gerlach actually proposed that the nervous system our nervous system is a single continuous network as opposed to a network of many discrete cells so his idea was that this is one gigantic cell sitting in our nervous system and it is not a network of discrete cells and this theory was known as the reticular theory"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/1_3.wav", "duration": 40.0, "text": "and around the same time there was the some breakthrough or some progress in staining techniques where camillo golgi discovered that a chemical reaction that would allow you to examine the neurons or the nervous tissue so he was looking at this nervous tissue using some staining technique and by looking at what you see in this figure on the right hand side the yellow figure even he concluded that this is just once single cell and not a network of discrete cells so he was again a proponent of reticular theory so this is about camillo golgi"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/1_4.wav", "duration": 35.0, "text": "and then interestingly santiago cajal he used the same technique which golgi proposed and he studied the same tissue and he came up with the conclusion that this is not a single cell this is actually a collection of various discrete cells which together forms a network so it is a network of things as opposed to a single cell there so that is what his theory was and this was eventually came to be known as the neuron doctrine"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/1_5.wav", "duration": 77.0, "text": "although this was not a consolidated in the form of a doctrine by cajal that was done by this gentleman so he coined the term neuron so now today when you think about art here about artificial neural networks or artificial neurons the term neuron actually originated way back in one thousand, eight hundred and ninety-one and this gentleman was responsible for coining that and he was also responsible for consolidating the neuron doctrine so already as you saw on the previous slide cajal had proposed it but then over the years many people bought this idea and this guy was responsible for consolidating that into a neuron doctrine interestingly he is not only responsible for coining the term neuron he is also responsible for coining the term chromosome so two very important terms were coined by this one person so now here is a question so around one thousand, nine hundred and six when it was time to give the nobel prize in medicine what do you think which of these two proponents say there are two theories one is reticular theory which is a single cell and then there is this neuron doctrine which is a collection of cells or collection of neurons that a nervous system is a collection of neurons so what do you think which of these two guys who are proponents of these two different theories who would have got the actual nobel prize for medicine"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/1_6.wav", "duration": 31.0, "text": "so interestingly it was given to both of them so till one thousand, nine hundred and six in fact way later till one thousand, nine hundred and fifty also this debate was not completely set settled and then the committee said both of these are interesting pieces of work we yet do not know what really actual what the situation is actually but these conflicting ideas have a place together and so the nobel prize was actually given to both of them and this led to a history of a some kind of controversies between these two scientists and so on"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/1_7.wav", "duration": 89.181, "text": "and this debate surprisingly was settled way later in one thousand, nine hundred and fifty and not by progress in biology as such but by progress in a different field so this was with the advent of electron microscopy so now it was able to see this at a much better scale and by looking at this under a microscope it was found that actually there is a gap between these neurons and hence it is not a one single cell it is actually a collection or a network of cells with a clear gap between them or some connections between them which are now known as synapses so this was when the debate was settled so now why am i talking about biology why am i telling you about biological neuron and so on so this is what we need to understand so there has always been interested in understanding how the human brain works from a biological perspective at least and around this time the debate was more or less settled that we have this our brain is a collection of many neurons and they interact with each other to help us do a lot of complex processing that we do on a daily basis right from getting up in the morning and deciding what do we want to do today taking decisions performing computations and various complex things that our brain is capable of doing now the interest is in seeing if we understand how the brain works can we make an artificial model for that so can we come up with something which can simulate how our brain works and what is that model and how do we make a computer do that or how do we make a machine do that so that is why i started from biological neurons to take the inspiration from biology"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/10_0.wav", "duration": 39.0, "text": "so welcome to lecture two of cs seven thousand and fifteen which is the course on deep learning so we will talk about mcculloch pitts neuron thresholding logic perceptrons and a learning algorithm for perceptrons and talk about the convergence of this algorithm and then we will talk about multilayer network of perceptrons and finally the representation power of perceptrons so let us start module one which is on biological neurons so remember during the history we had started all the way back in the 1880s when we spoke about biological neurons so we will just start there spend a few minutes on it and then go on to the computational models which is mcculloch pitts neuron"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/10_1.wav", "duration": 40.0, "text": "so now this is a course on deep learning so we are going to talk about deep neural networks now the most fundamental unit of a deep neural network is something known as an artificial neuron and the question is why is it called a neuron where does the inspiration come from so we already know that the inspiration comes from biology and more specifically it comes from the brain because we saw that way back in the 1890s this term neuron was coined for neural processing units or the cells in our brain so now before we move on to the computational neurons or the artificial neurons we will just see the biological neurons in a bit more detail and then we will move on from there"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/10_2.wav", "duration": 62.0, "text": "so this is what a typical biological neuron looks like so here actually there are two neurons this portion is called the dendrite so it is used to receive inputs from all the other neurons so that is the place where the input comes in then remember we said that in 1950s we discovered that these neurons are actually discrete cells and there is something which connects them so that connection is called a synapse and it decides the strength of the connection between these two neurons so there is an input there is some strength to the connection then once this neuron receives inputs from various other neurons it starts processing it so that is the central processing unit which is called the soma and once it is done this processing it will it is ready to send its output to other set of neurons so that output is carried on by the axon so we have inputs we have some weights attached to the input we have some processing and then an output so that is what a typical biological neuron looks like"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/10_3.wav", "duration": 26.0, "text": "and let us see a very cartoonish illustration of how this works right how the neuron works so our sense organs interact with the outside world and then they pass on this information to the neuron and then the neuron decides whether i need to take some action in this case the action could be whether i it should laugh or not right whether the input is really funny enough to evoke laughter so if that happens this is known as something that the neuron has fired"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/10_4.wav", "duration": 47.0, "text": "now of course in reality it is not just a single neuron which does all this there is a massively parallel interconnected network of neurons so you see a massive network here now the neurons in the lower level site so these neurons they actually interact with the sensory organs they do some processing based on the inputs so they decide whether i should fire or not and if they fire they transmit this information to the next set of neurons and this process continues till the information is relayed all the way back and then finally you decide whether you need to take any action or not again in which this case it should be laughter so that is how it works and when i say massively parallel interconnected network i really mean it because there are ten raise to eleven which is roughly one hundred billion neurons in the brain"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/10_5.wav", "duration": 23.0, "text": "now this massively parallel network also ensures that there is some division of work now what do you mean by that is not that every neuron is responsible for taking care of whether i should laugh or not or not every neuron is responsible for processing visual data some neurons may possess visual data some neurons may possess speeds data and so on so there is this division of work every neuron has a certain role to play so for example in this cartoonish example that we took"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/10_6.wav", "duration": 35.0, "text": "so there might be this one neuron which fires if the visuals are funny right whatever you are seeing is funny there will be one neuron which finds sheldons speech to be funny the way he speaks so that might be funny and there might be another neuron which actually finds the dialogue content to be funny and now all of this pass on the information to the next level and this guy would fire if at least two of these three inputs are funny so that means i have some threshold based on which i decide whether to react or not if it is really funny then only i laugh it otherwise i will not laugh"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/10_7.wav", "duration": 58.0, "text": "so the neurons in the brain as was obvious in the previous slide are arranged in a hierarchy and i will take a more realistic example where we look at the visual cortex so is this is the portion of the brain which is responsible for processing visual information right so as you see here you have our retina from where the information starts flowing and it goes through various levels so you see you follow the arrows and you will see there are several levels there is one level here then another here another here and so on right so it is again as i was trying to illustrate in that cartoon the information is relayed through multiple layers and then it goes all the way back to the spinal cord which decides that in this case i need to move the muscle right so that is what is being decided here right so the information flows through a hierarchy of layers and in this particular case i am going to focus on these three circled layers which are v1 v2 and ait right so these actually form a hierarchy and let us see what this hierarchy does right so at layer one you detect edges and corners so i am looking at you all i just see some dots and some shapes so that is what layer one recognizes i just recognize some edges and some dots and so on"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/10_8.wav", "duration": 50.0, "text": "now layer two tries to group all of these together and come up with some meaningful feature groups right so it realizes oh these two edges actually form the nose these two dots actually form the eyes and these two edges actually form the mouth right so that is slightly higher level of processing that it is doing and then layer three further collects all this and leads to higher level objects right so now it is realizing all these things put together is actually a human face right so you add edges and circles or dots then you had some feature groups and then the feature groups combine into objects right so that is how this hierarchy processes"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/10_9.wav", "duration": 31.105, "text": "so here is a disclaimer i understand very little about how the human brain works right and what you saw is a very oversimplified explanation of how the brain works right what i told you is there is an input a layer of networks which does a network which has many layers which does some processing and then you have an output right that is the very simplistic view that i gave you this is an oversimplified version but this version suffices for everything that we need for this course right this is not a biology or a neural processing course right so it is enough for this course so that is where we will end module one"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/100_0.wav", "duration": 24.0, "text": "so we will start so we were in the 3rd lecture on cnn\u2019s where we were looking at different visualization tools for understanding what your convolutional neural network is learning and we did a bunch of things and now you move on to the next module where we talk about something known as deep dream very interestingly titled but i am sure most of you have already seen this or read about this"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/100_1.wav", "duration": 613.964, "text": "so here is the idea right so far we were seeing that if we start from a blank image then we could suitably modify it by constructing an optimization problem whose parameters are the pixels of the image and we can modify the image so that it starts looking like a certain class of interest right but now suppose instead of starting with a blank image i start with a natural image right say a sky or any image that you have in your dataset i start with this and then i focus on neurons in some layer of the convolutional neural network i am focusing on these neurons say any one of these neurons i am focusing on and i want to change the image so that these neurons so when i say neurons i actually mean only a single neuron but for illustration i will show multiple neurons so i want to change the image so that this neuron fires even more so how would we achieve this what will we do so say this is the neuron which i want to fire even more so what is my optimization problem first of all what are the parameters of the optimization problem student refer time one hundred and fifty-one the pixels of the image that is clear now i want this to fire even more so what is the objective function what you are going to maximize lets call this neuron as hij what you are going to maximize student refer time two hundred and eighteen sorry student no refer time two hundred and twenty-one no i want this neuron to fire more student refer time two hundred and twenty-seven maximize hij right i mean that is i mean why so that sort of a thing ok but of course we will do something so that it is a neat differentiable thing and so on so you want to maximize the activation of one such neuron hij so we could just formulate the following optimization problem that i want to maximize hij two ok and of course the parameters of the optimization are the image pixels and if i consider one such pixel in the image then i essentially need to compute this gradient the gradient of the loss function which is hij two with respect to this image pixel and i can do it in these two parts the lead ability of the loss function with respect to hij and the derivative of the hij with respect to the image pixel this we have seen a million times while doing back propagation of course you are not gone all the way back to imn but we saw last time that it is just one more term in the chain rule and this again looks straightforward right the derivative of the loss function with respect to hij looks straight forward so i have a very simple way of computing the derivative of the loss function with respect to any pixel of the image"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/101_0.wav", "duration": 9.0, "text": "deep art ok now we will go to deep art now here any questions on that ok"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/101_1.wav", "duration": 128.0, "text": "so now here is what here is a again an iq test right so what will happen ok so this is deep art ok someone wanted to try this that if you take natural images or camera images and if you have art from various famous artists and i want to render this original image in this art form and how can i do so i will explain this the bit of a leap of faith in what is happening here but just indulge me right so let us see"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/101_2.wav", "duration": 85.0, "text": "now next and here is where there is a bit of leap of faith we want the style of the generated image to be the same as the style image so i gave you one content image and one style image so for content the loss function is clear now for style how do you capture the style of the image so the explanation given here and i am not very sure about this but maybe it comes from some traditional computer vision literature but i just take it on faith that if you have this volume here which is say sixty-four two hundred and fifty-six two hundred and fifty-six or any other dimension right then v t v which is a sixty-four sixty-four dimensional image or matrix captures the style of the image so this is what has been written in the original paper i am not really dug deep but my feeling is it comes from some of the traditional literature from computer vision right so that is not important we will just take it for granted that that gives the image and here is the illustration for that as you go deeper and deeper so this is if you plot the sixty-four cross sixty-four image that you got then you get different styles as you go deeper and deeper you get a better representation of the style of the original image right so that is the argument made in the original paper now if you assume that this is correct then can you design a loss function for the style part of it i want the style of the created image to be the same as the style of the style image"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/101_3.wav", "duration": 45.0, "text": "so how would i do that so this is the content image this is the actual oh sorry this is a style image correction ok so i would just want that this vt v which captures the style and i could do it for any one of the layers or all layers depending on what i want to do i just want that this style should be as close to each other so i can have a similar matrix squared error kind of a function right so that is what this is trying to capture these are the style gram so this is v t v for the style image and this is v t v for the generated image if i pass it through the convolutional neural network i want both of these to match"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/101_4.wav", "duration": 40.567, "text": "so i want the content to match i want the style to match so then what is my total objective function going to be student sum of these sum of these right so this is what my total objective function is going to be i want the content to match and i also want the style to match so i will use an objective function which tries to balance between these two and alpha and beta are some hyper parameters ok and if you do this and train the algorithm and try to modify the pixels along with some other bunch of tricks then you will get this gandalf rendered in this style that you have given right so this is again some code is available for this you can go and try it out and it is interesting it is in a very interesting idea that you could have taken these two things and now you could be imaginative right you could do all sorts of things with if you have two different images how do you want to combine them and so on right so that is the basic key idea here"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/102_0.wav", "duration": 9.0, "text": "with that we go on to the last module which is fooling deep convolutional neural networks"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/102_1.wav", "duration": 36.0, "text": "so turns out that using this idea of optimization where we are able to actually change the image to suit our needs right and these needs were one was we wanted to change the image so that it fires for a particular class the other was deep dream where we wanted to change the image so that it is starts seeing patterns which were otherwise not observed in the image and the other was d part where we trained the image or we optimized over the image so that we could produce some artistic images and these are the different optimization problems that we have seen but the same idea can actually also be used to full convolutional neural networks and i have already hinted at this earlier so let us see how to do that"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/102_2.wav", "duration": 55.0, "text": "so now suppose we feed an image to a convnet and i know this is the bus image right but now what i do is this is a trained convolutional neural network and what i do is instead of setting the cross entropy loss to maximize bus i will set up the cross entropy loss to maximize ostrich and then i will back propagate through the network i will not modify any of these weights or parameters and i am only change the image right so what i am trying to do is i know that this is the bus image but now i am setting the objective that it should fire for the ostrich class so now i am going to back propagate and change this image so that the blog the likelihood of the ostrich class increases you get this set up its very straight forward ok and turns out that if you do this with very minimal changes to the image you can actually fool the convolutional neural network ok"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/102_3.wav", "duration": 44.0, "text": "so this is the change right you have the original image the second image is actually the amount of change you made and the third image is the original image plus this change now to the human eye there is no distinction here right you would all of first would still think this is a bus and in fact i do not even see that there is a noise in the third bus that you see same for some other class they have taken some bird or something like that and added some noise to it and a temple and in all of these cases the network actually predicts that the modified image is an ostrich right or some very random class from the original class so why is this happening and before asking that question let me just finish and it need not be that you start with an original image and then try to modify it"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/102_4.wav", "duration": 38.0, "text": "actually you can start with a blank image and do the same experiment where you modify the image minimally so that p of robin becomes one or close to one and you will get some very arbitrary noisy looking images which no in which to at least you and me do not look like a cheetah or robin or armadillo but the network thinks that these are the classes that these images belong to now this is definitely a risky how many of you appreciate that it is bad ok now and a network is not just predicting it is predicting it with a very high confidence right nine hundred and ninety-six percent confidence so why is this happening can even think of a reason for that student"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/102_5.wav", "duration": 180.111, "text": "no but ok in that case i would have been fine if there are one thousand classes it should have given eleven thousand probability to all the classes right but this is like worse than random classifier right it is saying with ninety-nine percent confidence that this is a ostrich or whatever class that is so why is this happening and the interesting thing is that this in some sense ties back to the universal approximation theory or at least some ideas with that can you think of why this is happening ok so let us try to see a very intuitive explanation for this so on"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/103_0.wav", "duration": 20.0, "text": "in this lecture we will talk about sequence learning problems and in particular some neural network architectures which deal with sequences so recurrent neural networks is what we are going to see so we will start with the first module which is on sequence learning problem"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/103_1.wav", "duration": 76.0, "text": "so what are sequence learning problem so so far we have dealt with two types of networks one is feedforward neural networks and the other is convolution neural networks and both these networks the input was always of a fixed size so what do i mean by that is if you take a convolution neural network you are feeding thirty-two thirty-two images to it or two hundred and twenty-seven two hundred and twenty-seven images to it and this size will always fixed all your training images all your test images were always scaled or cropped to this particular size ok similarly when we used feedforward neural networks so one example was word2vec the size of the input was always fixed we had this input of size two v right or k v in general if you are looking at the k word window right so this input was not varying from one training instance to another training instance or one training instance to the test instance or anything and secondly each input to the network was independent to the previous or future inputs so i pass an image of an apple i get the prediction apple then i pass some other image to the network and i get a different prediction it does not matter whether my previous image was a apple or a car or a mango or whatever it just reads each of these inputs independently there is no dependence between the inputs and the size of the inputs is fixed"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/103_2.wav", "duration": 143.0, "text": "but in many applications the input is not of a fixed size so and also successive inputs may not be independent of each other so let us understand this with the example of auto completion that all of us are used to while typing smss or whatsapp or other things so given the first character d i want to predict the next character which is e then once i have predicted e i want to predict the next character again and so on till i get the full word ok this is what my task is"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/103_3.wav", "duration": 185.0, "text": "so these problems are known as sequence learning problems where you have a sequence of inputs and then you need to produce some outputs and each input actually corresponds to one time step so this is the input at time step one time step two time step three time step four and so on so let us at some more examples of such sequence learning problems"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/103_4.wav", "duration": 58.866, "text": "finally it is not always necessary that sequences are composed of only words what other kinds of sequences are you familiar popular sequences speech is one video is another so a video could be treated as a sequence of images and now you could have a video where some someone is performing surya namaskar and as you can understand that i need to look at the entire sequence and only then be able to make a prediction right if i stop at this point if i only consider this this is only namaskar no surya namaskar right so you have to look at the entire sequence and then decide what the output is and you do not care about the intermediate outputs i do not care what is the prediction till this point this of course is again some aasan but i do not care about that i care about the full sequence that i am dealing with it is just to motivate that sequences can be of all types and i apologize to the speech people i do not really understand much of speech processing so i never give speech examples but video is something i understand so i can give examples on that"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/104_0.wav", "duration": 13.0, "text": "so we have seen sequence learning problems now we are interested in the question of how to model these right so we look at something known as recurrent neural networks"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/104_1.wav", "duration": 4.0, "text": "and our question that we are interested is how do you model tasks which involves such sequences ok"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/104_2.wav", "duration": 144.0, "text": "so here is the wishlist that we have what will model will come up with should account for the dependence between inputs because that is the strong case that we have made that the output actually depends on multiple inputs and not just a single input you should also account for variable number of inputs because a video could be three hundred seconds it could be twenty seconds twenty-five seconds a sentence could be of arbitrary lines and so on and it also makes sure that the function at each time step is the same right but every time step they are trying to do the same activity ok so we will focus on each of these items from our wishlist and then try to arrive at a model for dealing with such problems"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/104_3.wav", "duration": 39.0, "text": "and this parameter also sharing also ensures that the network becomes agnostic to the length of the input because now whether i have a word which has ten characters or twenty characters it does not matter because at every time step i am going to execute the same function that is why it is important that at every time step we have the same function so since we are going to complete the same function the number of times it does not matter and we can just create multiple copies of this network that we have and for any arbitrary length n we can still compute the output ok still not quite there we still need to take care of a lot of things but we are just slowly addressing each item from our wishlist"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/104_4.wav", "duration": 61.0, "text": "now how do we account for dependence between inputs or rather actually the right way of asking this is how do we account for the case that the output actually depends on multiple inputs and not just the current input ok how do we account for that feed in the ok good so let us first see an infeasible way of doing this ok so you are given the first time step x1 you have a network which predicts one from x1 you know at the same second time step you also want to look at the previous inputs so why not just feed it x1 and y x2 both and then try to predict y two at the third time step feed in x one x two x3 and predict y3 and so on forever is this fine probably the word infeasible is there so y is so what is the problem with this yeah good so i am looking in terms of the conditions that we have on the wishlist which condition does is violet what is the function being executed at each time step ok so let us see"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/104_5.wav", "duration": 240.0, "text": "the function being executed at every time step is different so y1 is function of x one y two is a function of x one x two remember that this is not just saying that you are passing to inputs everything changes because you now you need to have u1 and u2 here you need to have u one u two u three right so everything changes it is not the same function how many of you get this it is a different function being executed at every time step so now if i have a sequence of length one hundred what happens i need y one hundred which takes f x one to x one hundred as inputs and has how many parameters u one to u one hundred right you could you could share u one to u ninety-nine for y ninety-nine and y one hundred but we still need those many of that right so that network is now sensitive to the length of the input and on the length of the input goes you will have to construct more and more functions right and imagine that if the training time the maximum sequence length that you had seen was twenty-five and suddenly a test time you get a sentence which is of length thirty you do not even know how to compute that because you have not train any parameters for doing that"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/104_6.wav", "duration": 45.907, "text": "and this is a more compact way of representing that that you say that you compute s i and then you are feeding it back so this is just more compact way of representing a recurrent neural network"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/105_0.wav", "duration": 17.0, "text": "so that was recurrent neural networks now whenever we propose a network what do we do next training right so what we will look at it back propagation through time this is not the title of a fiction and movie or anything this is an algorithm that we will see"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/105_1.wav", "duration": 64.0, "text": "so before we proceed right let us look at the dimension of the parameters that we have and i expect you to tell me the dimensions so i will define somethings for you which are very hard so xi belongs to rn so let us be clear about that si belongs to rd that means the si is a d dimensional vector and yi belongs to rk which has k classes ok so now what is u what is v d k is it d k i am asking soham now i mean we have be written it as d k and w is student refer time one hundred and five d t sure everyone sure ok right so these are the dimensions why am i talking about these dimensions whenever we talk about gradients what we talk about partial derivatives or gradient or something we need to know what is the size of the parameter with respect to which we are taking the gradient because that is what the size of the gradient matrix is going to be right that is why i am asking you to focus on this"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/105_2.wav", "duration": 20.0, "text": "now how do we train this network title of the module student backpropagation backpropagation ok how why do i have a module if i am only going to tell you about backpropagation do you see any problem with this why cannot you just apply the standard backpropagation algorithm ok so we will try to understand this with the help of a concrete example and we will go back to our example of predicting characters ok"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/105_3.wav", "duration": 43.0, "text": "so this is the auto completion task and for simplicity we will assume that english has only these three characters d e p and then a stop to indicate that the word has been completed ok this is what you are going to consider that my vocabulary size is just four that means i can only predict one of these k four classes k is equal to four ok and at each time say i want to predict one of these things what is the suitable output function for this task can everyone say with probability nine hundred and ninety-nine percent student half max half max ok what is the suitable loss function for this task small pleasures in life that is all i get ok"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/105_4.wav", "duration": 79.0, "text": "suppose we initialize u v w randomly and networks predicts the following probabilities ok so let us understand what is happening i fed it d as the input i have just started training so my u w and v are all some randomly initialized weight matrices right now and so it has predicted this as my probability distribution this is the predictions that i have got from the network and i also know what is the true probability distribution what is the true probability distribution for the first time step zero one zero zero and so on right you can see it second times that is also zero one zero zero third is zero zero one zero and the last one should have been zero zero so given the situation and before i talk about learning algorithms what is the first thing that i need to define objective function right so what is the objective function here how many errors do i have i mean i can make my errors at four places whether i making an error or not is the separate case but i can have four loss functions so then these are the two questions that i am interested in what is the total loss made by the model and how do we back propagate this loss and update the parameters of the model as usual i am ignoring the biases which is w u and v so we can answer these two questions then we are done right if you can do this then we are done"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/105_5.wav", "duration": 184.0, "text": "so the total loss what is the total loss actually take a guess sum of all the loss right good so just going to be the sum of the loss over the times steps that you are i mean very logical and what else would it be and we know that the loss at every time step is so this is the loss at time step t hence y t and what is c actually the true class at time step t right so it is would be e at first time step e at second time step then p and then stop ok so that what c is so this is we all comfortable with is this is the cross into p loss and i am going to sum at over all the t time setup that i have now for back propagation what we need is we need to be able to compute the gradient of this loss function with respect to w u v"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/105_6.wav", "duration": 415.504, "text": "so l4 actually depends on s four s four depends on what w and s three s three depends on what w and s two s two depends on what an s one depends on w and s zero always assume there is s zero what kind of a network is this what kind of a function is this what did i ask to revise this is not an order derivative what kind of function is this"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/106_0.wav", "duration": 14.0, "text": "and that takes us to the problem of vanishing and exploding gradients ok so you want to see what is a problem with this back propagation through time which could lead to certain interesting situations"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/106_1.wav", "duration": 3.0, "text": "so we will focus on this st sk and let me just go back so remember that this formula had this st sk right where st could be the last time step and sk could also be the first time step because you are summing over all the time steps right"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/106_2.wav", "duration": 432.0, "text": "so you could have a term which is st capital t which is the last time step the first time step and the derivative of the last time step with respect to the first time step right so that is a situation that we are dealing with so we will consider one such generic element which is st sk and we will just try to expand it so remember i have done this short circuiting so i am now just going to expand it again so this is going to be t t one t one t two and so on up to k one sk ok and i can write it as this generic formula everyone find with this i have just replace this as a product and written it more compactly now let us look at one such term here sj sj1 now just to confuse you guys from next slide i will go over to sj sj one or not confuse you i just did not pay attention to this so instead of s plus one and j and i am going to do j and j minus one right it remains the same does not matter"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/106_3.wav", "duration": 174.068, "text": "student no updates no updates and you just stuck where you are if the gradient explodes what happens think in terms of the wb plane you suddenly have a very large gradient what will happen is just gone way far from where you are right now because your update is w is equal to w minus eta into this gradient and this you have got a very large value now it just going to move somewhere very far from where you are and that is never go where your suddenly jump to a different universe ok so that is the problem in training recurring neural networks you could have this problem of exploding or vanishing gradients and we have done a mathematical derivation of why you have this problem ok"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/107_1.wav", "duration": 158.0, "text": "so i just go back to the formula which i had for computing the gradient of the loss function with respect to w and i cannot repeat enough times that all these notations are actually a bit of abuse of notation because these are gradients and not partial derivatives so i should actually be using this notation but for ease of explanation i use i stick to my original notations ok so now let us look at each of these quantities here and tell me the dimensions of these quantities let us start with the left hand side what is the dimension of this w was what matrix what is i am talking about the circle entity what is the magnitude what is the dimension of that k d student refer time one hundred and nine d d student refer time one hundred and eleven d d someone n d student refer time one hundred and thirteen n d and n k are the two options which are left w is the recurrent weight so w is what dimension student refer time one hundred and twenty d d so what is this gradient d d ok what about this fast st what the hidden representation so that was d dimensional so what is this d one ok what about this why do you guys still struggle with this student refer time one hundred and forty-two d d and this d cross student refer time one hundred and forty-four d cross it is very straightforward right what is the dimension of numerator what is the dimension of denominator thats all right"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/107_2.wav", "duration": 50.0, "text": "so we will just look at one element of this tensor and it is going to be skpwq r so let us just see that you have s k as this vector and you have w as this matrix so i am considering one such weight which is w p comma q and one such element from here which is s k sorry so q r and i am considering one element from this which is s k p so i am trying to compute the derivative of one element of the vector with respect to one element of the matrix so this is going to give me one entry in my tensor and that entry is going to be what p q r how many of you are fine with this ok fine"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/107_3.wav", "duration": 154.03, "text": "so now recall that a k was equal to w into s k minus one plus b and s k was sigmoid of a k i think again i have miss that u into x k but that will not matter because that is not there in the derivative ok you are fine with so far"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/108_0.wav", "duration": 52.0, "text": "so we have been looking at a new kind of or a different kind of neural network which is recurrent neural network and last class we spent some time on showing that it is how to train these recurrent neural networks because of the specific problem of exploding and vanishing gradients in particular we saw that if you want to propose if you want to back propagate the gradient from time step t the final time step to an arbitrary time step k then you have this multiplicative term in the back propagation which could explode or vanish so today we are going to try to see if we are trying to focus on something which can help us solve this problem to whatever extent right so that is why we will look at lstms a long short term memory cells and gated recurrent units ok so let us start with that"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/108_1.wav", "duration": 16.0, "text": "so first we will introduce the idea of selective read selective write and selective forget and then we will try to build on this intuition and see how could you could realise it by using lstms and gated recurrent units and whether that help in solving the vanishing and exploding gradient problem"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/108_2.wav", "duration": 75.0, "text": "so recording the state of an rnn records information from all the previous time steps that was the whole idea that you add this recurrent connections so as you keep going on at this time step the cell is not only recording information from the current time step but it also has some kind of an accumulated history from all the previous time steps right but now the issue is that this state or this blue coloured vector that you see is going to be of some finite size right we will say that it is a one hundred dimensional vector or a one thousand dimensional vector but whatever be the size it is going to be some finite dimension now as you keep writing information to that cell you are morphing the information that you had written at the earlier time steps right do you get that so now that is the problem right because on one hand you are saying that you want to record the information from all the previous time steps but the at the same you at the other hand you just have a finite amount of memory to deal with so it is bound to read over ridden and the information will get morphed so much that it is completely impossible to say what was the original contribution at time step one or time step two once you have reach some time step twenty thirty or so on right so that is the problem with recurrent neural networks and we will tie it back to the problem that we had with the vanishing and exploding gradients right"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/108_3.wav", "duration": 38.0, "text": "so in fact the similar problem occurs when you try to when the information flows backwards during back propagation right it is very hard to assign the responsibility of the error caused at time step t to arbitrary time steps before it right to very far away time steps it is very hard and that is the vanishing gradient problem right because we have this multiplicative term and the gradients vanish so that that is very hard to do so both during forward propagation the information vanishes and even during backward propagation the information vanishes right and we saw a formal argument of this while doing vanishing gradients so this is just an illustrative diagram but we also saw that formally the guardians do vanish under certain conditions right"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/108_4.wav", "duration": 66.0, "text": "now let us see an analogy for this and from here on we will build on some ideas which will help us arrive at lstms and gated recurrent units right so the analogy is a whiteboard so you have a whiteboard and it is always of a fixed size right i mean the whiteboard is not infinite you just have some size for the whiteboard and you keep writing information on that so at every time steps i keep going and writing something on the board and i am trying to derive something or just try to make a story or anything right i just keep trying to write information on the board now since the whiteboard is fixed size at every time i am essentially morphing the information which was written at the previous time step and after many time steps it would be impossible to find out that now whatever my state of the board is how did time step one contribute to that state right because it is written all over the board i do not know where i started what i did and so on and its going to be very hard for me to find and this happens right when you do these long derivations on on the whiteboard it becomes very hard to track where did i start where was this variable defined and so on right because it is a fixed size you cannot really i will end of deleting some terms and so on right"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/108_5.wav", "duration": 147.0, "text": "so and we will make this more concrete with the help of an example right suppose i am trying to drive an expression on the board and typically what we do is we use three things we use selectively write on the board selectively read the already written content and selectively forget or erase some content so let us see what i mean by these three ideas ok"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/108_6.wav", "duration": 46.0, "text": "so now as the whiteboard is full and i will have to selectively delete some information and as this obvious in this trivial example that you can get rid of bd because you have already encoded the information in bd a and now the next step which is ac into bd plus a can do on the whiteboard and this is how you keep doing at every time step you selectively write at every stage here again note that i am not written acbd a would be something like i do not know what was it five x thirty-four one hundred and seventy right i am not using two steps i am just writing everything in a single step because i do not have enough space right so selectively writing selectively reading and selectively forgetting things which are there in a constant memory is something that we do regular right"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/108_7.wav", "duration": 76.907, "text": "and then other ways of motivating this so you could even think of our brain as something which can store only a finite number of facts right as we keep going or if we will learning more and more things we can only retain a finite number of facts and what happens inadvertently is that you erase some of the steps not consciously of course you do not have a delete button or anything but you erase some of these things that you forget a lot of things which had happened a year back or so and also at various times if i ask you what was this which i have done in last class most of you forget to do the selective read but that is what you do right you always do selective forget but that is what we typically do in our brain also right any time when you are dealing the finite size memory you will always have this three operations either they are explicit or implicit but the intuition is that you end up doing this ok so now since the rnn also has a finite state size can we do something like this selective read write and forget so that one during forward pass even if the information gets morphed it gets morphed in a principle manner right so even in the whiteboard example i was morphing the information i was deleting the information written at time step one time step two but i was being a bit smart about that i was retaining some good information and only deleting what was not required so can we do this in analogy so this analogy really sets it up but now the solution is not going to live up to the expectation but it will have some it will be something in this direction ok"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/109_1.wav", "duration": 10.0, "text": "so with that motivation let us go to the next module where we will talk about long short term memory and gated recurrent units ok"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/109_2.wav", "duration": 146.0, "text": "so now all this was fine in terms of ok i gave you a derivation on the board and say that this is not required but can i give you a concrete example where rnns also need to selectively read write and forget right only then you will be convinced that this kind of morphing is bad in the case of rnns so i will start with that example and then once we agree that we need selective read write and forget how do we convert this into some mathematical equations right because conceptually it is fine but you have to write some equations so that the rnn can do some computations where you have selective read write and forget right so that is what we are going to do over the rest of the lecture"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/109_4.wav", "duration": 22.0, "text": "now the next part is how do we convert this intuition into some mathematical equations right so let us look at that so in this diagram recall that the blue colored vector is called the state of the rnn it has a finite size so now i will just call it as s t belongs to some r n and the state is analogous to the whiteboard and sooner or later it will get overloaded with information and we need to take care of this right so now our wish list is selectively read write and forget ok so let us start with that"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/109_5.wav", "duration": 232.0, "text": "so what we want to do is that and this is the problem definition now that we have computed the state of the rnn this is a blue colored vector although it is not blue but this the blue colored vector from the previous diagram where the state of the rnn was computed i know what the state is at time step s t minus one now i want from here to here go from here to here that means from s t minus one i want to compute the new state of the rnn right so i had something written on the whiteboard i want to write something new i want to change the state of the whiteboard and this is the new information that has coming to me right the x t is the new information at time step t and while doing this i want to make sure that i use selectively write read and forget so these three operations have to come in somewhere in the between so that i am true or faithful to the analogy which i have been giving right that is the this is the our problem definition now going from s t minus one to s t and introducing these three operations along the way that is what we are interested in doing"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/109_6.wav", "duration": 512.0, "text": "how to do this why to do this all that is not clear i am just telling you the intuition how and why will become clear later is that fine ok so we want to be able to take st1 and write only selective portions of it or pass only selective portions of it to s t"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/109_7.wav", "duration": 26.0, "text": "i know i am repeating myself but it is very important that you understand this situation how many of you get this now and as i said these parameters will be learned along with other parameters and o t is called the output gate because it decides what to output to the next cell state ok still you see that there is a lot of gap here we have not reached st yet we are still at st1 we have computed some intermediate value but we have not reached s t yet and along the way we had three things selective write read and forget we have only taking care of selective write so far ok"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/109_8.wav", "duration": 70.0, "text": "now let us look at selective read so what this selective read do you are going to get new information at time step t which is x t right and now instead of this original cell state you have used the selectively written cell state because that is what you have written now so that is what you should use now using a combination of these two i am going to compute some intermediate value ok and just stare at this equation this equation form is very similar to the rnn equation form right only thing is that instead of s t minus one i am using h t minus one and for good reason because i know that h t minus one contains only selectively written values from ht1 is that fine and x t is the new input still there is some gap here i have not reached st yet i am still at an intermediate value so this is the new input which i have received now what should i do with this new input selectively read this input i do not want to take all of this input because may be the input which i have got now is a stop word and i do not want to read all of it right do you get that"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/109_9.wav", "duration": 40.0, "text": "so now it captures all the information from the previous state as well as the current input and we want to selectively read this so now what would you do to selectively read again the same situation that you have a the answer is already here you have s tilde and you do not want to pass it on as it is to st this is st is somewhere here which you do not know how to get to but you know that you do not want to pass on all the input that you have read you want to selectively pass it on so what will you do now again introduce a student gate gate and this gate will be called student read gate input gate or the read gate right ok ss"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/109_10.wav", "duration": 56.0, "text": "so now what can you give me an equation for the gate i t is equal to sigma of that is good because sigmoid is what we need it is going to be a fractional thing let me add the easy part w into student ht1 ht1 that is telling you what has happened so far and u times xt you see the same equation same form the parameters have changed so these we will call as wi ui and vi and they are depending on the input as well as the previous state previous temporary stay that we had computed ok so that is exactly what your input gate is going to be and now this operation is the selectively reading operation how many you are fine at this point ok and then this product is going to use to be it is will help us to read selectively from this temporary value that we have constructed or the input that we have taken ok"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/109_11.wav", "duration": 470.0, "text": "so far what do we have we have the following we have the previous state which was s t minus one then we have an output gate which was o t minus one using these two we have done selective write right we have taken the previous state and the gate and then a selective write is that fine ok we need to check if the sigmoid should come here because sigmoid is already there in the computation of s t minus one right oh it is not there so this already has one sigmoid right yeah so then again a sigmoid on that is it there ok we will figure it out just check the equation right so there may or may not be the sigmoid the sigmoid already applied to s t minus one but we can figure that out ok so this is the selective write portion then you compute the current temporary state ok and just look at the similarity between these equations then you have an input gate and using these two we have done a selective read ok so you have taken care of selective write and selective read but you are still not reached s t i still do not have an arrow here i still need to figure out how to compute the st finally ok so what is the operation which is remaining now selective student forget forget ok so what do you think should we forget we want to find new st so let us see what we will forget right"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/109_12.wav", "duration": 247.586, "text": "so lstm actually has many variants with include different number of gates and also different arrangement of the gates so as i was saying that you could say that input is one minus output or input is one minus forget or things like that and also why this particular parametric form right why not make w zero into st1 instead of ht1 and so on so the all points of things that you could do or all of these are valid these are all valid variants of lstms so there is this paper called lstm a search space odyssey so you can go and look at i think we link it in the in the reading material right ah so you can see that there are actually many variants of lstms but this is the most standard and default variant which you will find in most platforms on tensor flow or pytorch refer time two thousand, seven hundred and twenty-six form"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/11_0.wav", "duration": 7.0, "text": "let us start with module two which is about mcculloch pitts neuron"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/11_1.wav", "duration": 124.0, "text": "so as we are done this during the history lecture way back in one thousand, nine hundred and forty-three mcculloch and pitts they proposed highly simplified computational model of the brain so now let us see what\u2019s the motivation we know that our brain is capable of very complex processing it\u2019s capable of taking a lot of inputs from various sources and then help us taking various decisions and actions now what if you want a computer to do this we want a module which is very similar to how the brain works or at least how we think the brain works which takes a lot of inputs and then does some processing and helps us take a decision so what they proposed is this model which will take a lot of inputs and these inputs are all binary all these inputs that you see here these inputs are fed to this mcculloch pitts neuron which is an artificial neuron and it is divided into two parts so the first part collects all the input so remember you had these dendrites which were taking all the information from everywhere so this just collects all the information and then the second part is aggregation i have collected a lot of information from all the sources now the second function will decide what this aggregation is and based on that it will take a decision whether to fire or not so the output is again boolean if it\u2019s zero then neuron does not fire if it\u2019s one the neuron fires so let us take a concrete example so suppose i am trying to make a decision whether i should watch a movie or not so x1 could be is the genre of the movie thriller similarly there could be another variable say xn which says is the actor matt damon so these are all various such factors that i could take is the director christopher nolan the music given by someone and so on so all these are probably factors which help me decide whether i want to watch this movie or not and you want this neuron to help us make that decision"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/11_2.wav", "duration": 151.0, "text": "so now what is happening here is these all inputs they can be either excitatory or inhibitory so let me tell you what inhibitory is first so you are taking input from a lot of sources now see one of these sources or one of these inputs is am i ill today am i down with fever so if that input is on irrespective of who the actor director or whatever is i am not going to watch the movie right because i just cannot leave from my bed so these are known as inhibitory inputs irrespective of what else is on in your input features if this input is on your output is always going to be zero that means the neuron is never going to fire so you could think of it as suppose my mood is not good today i do not feel like getting up or if i injured my leg or anything right if any of these conditions is on irrespective of what the other factors are i am not going to watch the movie so that is an inhibitory input and excitatory input are on the other hand is not something which will cause the neuron to fire on its own but it combine with all the other inputs that you have seen could cause the neuron to fire and how so this is how so these are all the inputs that your neuron is taking all i am going to do is i am going to take a sum of these i am going to take aggregation of all of these so what does this count actually give me the number of inputs which are on the number of inputs which are value one that is all this aggregate this is a sum of all the ones in my input now this is what g does this is a very simple function is taking a sum of my inputs now the function y takes this as the input that means it takes this sum as the input and if the sum is greater than a certain threshold then it fires if the sum is less than the certain threshold then it does not fire so again see what is happening here is it is same as now if you depend on the actor director and genre and so on and you fine at least two of these three conditions are satisfied at least i am happy with the actor and the director even though the genre is not something that i care about i will watch the movie or you might be a very niche go movie watcher who only goes to a movie if the actor matches your requirement the director matches your requirement and the genre and the music and everything matches your requirement so you are threshold in that case it should be high so this is how it is going to help you make decisions now again a very simplified model and this is theta is called the thresholding parameter that is the value which decides whether the neuron is going to fire or not and this over all thing is known as the thresholding logic so this is what a mcculloch pitts neuron looks like"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/11_3.wav", "duration": 51.0, "text": "now let us implement some boolean functions using this mp neuron so from now on i will just called it mp neuron and we will try to implement some boolean functions using it so now why are we interested in boolean functions it is because we have overly simplified the way we take decisions we are saying that the way we take decisions is we take a lot of boolean inputs is actor matt damon and genre thriller and so on and based on that we produce a boolean output so an input is all booleans so we have x1 to xn which are all booleans and your output is also boolean so that is a boolean function that you are trying to learn from x to y is that clear you have x just happens to contain n different variables here ok and lot of decision problems you could cast in this framework you can just imagine right whether to come for lecture today or not again is you could cast in it depending on various boolean inputs"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/11_4.wav", "duration": 114.0, "text": "this is a very concise representation of the mcculloch pitts neuron what it says is it takes a few boolean inputs and it has certain threshold if the sum of these inputs crosses this threshold then the neuron will fire otherwise it will not fire that is the simple representation of the m p neuron now suppose i am trying to learn the and function when would the and function fire all the inputs are on so what should be the value of the threshold in this case three everyone agrees what about the or function one let us see a few more this function so let me tell you what this function is so you see this circle here so that means that this input is an inhibitory input if that is on then the neuron is not going to fire that is how i am representing it so now tell me what should the threshold for this be it is not so hard see if x2 is on it is not going to fire so you have four rows zero zero zero one one zero one one so two of those are ruled out and it is not going to fire now out of the remaining two when do you wanted to fire so what should be the threshold one now what about this function zero or three three is not even a valid option zero everyone agrees to that and what about this zero so you get this so now if you have a certain number of input variables and the function that you are trying to model the decision that you are trying to make is a boolean function then you could represent using these mp neurons whether all boolean functions can be represented in this way or not that is still not clear i am just showed you some good examples we will come to the bad examples later on here is the question"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/11_5.wav", "duration": 12.0, "text": "so can any boolean function be represented using a mcculloch pitts neuron so before answering this question we will see a bit of a geometric interpretation of what mp neuron is actually trying to do"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/11_6.wav", "duration": 47.0, "text": "so let us take or function where you have two inputs x1 and x2 and this neuron is going to fire if x1 plus x2 is greater than equal to one that is clear that is how the definition is now if you look at this x1 plus x2 greater than equal to one now let us ignore the greater than part first so we will just talk about x1 plus x2 equal to one what is this equation of a line everyone gets that ok now in this case since we are dealing with boolean inputs and we have two access x1 and x2 how many input points can we have four right zero zero zero one one zero one one"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/11_7.wav", "duration": 99.0, "text": "so you could have these four points so just note that this is an x1 and x2 axis but only four inputs are valid here this is not a real numbered access this is only boolean inputs possible here now what is the line x1 plus x2 equal to one tell you which line is that so one which passes through one zero here and zero one here this is that line now what do we want that for all those inputs for which the output is actually one they should lie on the line or on the positive side on the line and all those inputs for which the output is zero they should lie on the other side of the line is that happening so what is actually mp in unit actually learning linear decision boundary it just what it is doing in effect is actually it is dividing the input points into two halves such that all the points lying on that line right are sorry all the points for which the input should be zero lie below this line and all the points for which the output should be one sorry in both cases it should have been output so let me just repeat it all the points for which the output is zero lie below this line and all the points for which the output is one either lie on this line or above the line is that fine and so let us convince ourselves about this even it is not already clear from the equation for how many of you it is already cleared from the equation that this is exactly what it does for a large number of periods but still we will just do a few examples and move ahead"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/11_8.wav", "duration": 69.0, "text": "now for the and function what is the decision boundary it is x1 plus x2 no that is the decision boundary equal to two so again i have these four points only these four points are possible now where is my decision line passing through that one one and intercepting this somewhere around two zero and this around zero two so that is the line which i am interested in now again do you see that our condition is satisfied that all the inputs for which we want the output to be one are on or above the line and all the inputs for which we want the output to be zero or below the line now what about this function what is the threshold zero so what would the line be x1 plus x2 equal to zero which passes through the origin right and again all the points are either on or above the line so this part we are going to call as a positive half space and this we are going to call as the negative half space"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/11_9.wav", "duration": 74.0, "text": "now what if we have more than two inputs in a two dimensional case when we just had x1 and x2 we are trying to find a separating line in the three dimension case what will we do plane in the higher dimensions hyper plane so this is now your three dimensional case again there are three axis here but not all points are possible how many points are possible eight points and which is the function that we are trying to implement or so for these eight out of these eight points for how many is the output one seven and for one it is zero so what is the kind of plane that we are looking at we are looking for a plane such that seven points lie on or above it and one point lies below it and which is that point zero so now what is the equation of that hyper plane x one plus x two plus x three is equal to one you see this so you see that all the seven points are visible but the points zero zero is not visible because it is on the other side of the plane so this is doable in three dimensions also and again in higher dimensions also right we could find in hyper plane"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/11_10.wav", "duration": 30.189, "text": "so the story so far is that single mcculloch pitts neuron can be used to represent boolean functions which are linearly separable so a linearly separable function is such that there exists a line such that for that function whichever points produce an output of one lie on one side of the line and whichever points produce an output zero lie on the other side of the line"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/110_0.wav", "duration": 5.0, "text": "so that was lstm and grus"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/110_1.wav", "duration": 74.0, "text": "now the issue is that i have given you a very explanation that why you selectively read write and forget should work but you have not actually formally proven or even given an intuition for with these sets of equations how are we sure that the gradients will flow back right we introduced a bunch of equations remember in the case of lstms sorry in the case of rnns the problem was because of the recurrent connections right because you had these recurrent connections this w which was the recurrent parameter right which was connecting cell state st1 to cell state st this was repeatedly appearing in your gradients right and that was causing the problem because when you had this multiplicative factor lambda into w and then if you compute the and this was some raise to t so then if you compute this magnitude then if the magnitude of w blows up then the whole thing will explode if the magnitude of w vanishes then the whole thing will vanish right that is the problem that we had"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/110_2.wav", "duration": 36.0, "text": "so this was because of the recurrent connections do we have recurrent connections in lstms or grus for that matter do you have recurrent connections yes or no student yes yes so then that problem could still occur right i mean if you had that the crux of the problem for the vanishing gradient was this recurrent connection which is getting multiplied and hence reading to problem but we still have recurrent connections the case of lstms also and why should things become any easier in this case how many if you get the question how many if you can give me the answer selectively that is a good answer so can you think of what is happening here so first thing that we going to do now so i will go on to the next module"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/110_3.wav", "duration": 276.0, "text": "when i going to give you intuition for what is happening and then we will do slightly in fact a rigorous proof of why it actually solve the vanishing and exploding gradient problem ok so let us look at the intuition first how lstms avoid the problem of vanishing gradients i am only focusing on vanishing gradients exploding gradients are actually easier to deal with why student refer time two hundred and twenty-six what can you do what are we interested in when we compute a gradient direction so if the magnitude is very large what can we do just normalize it and restricted to be a certain magnitude so that is known as gradient clipping so exploding gradients in that sense is still not a big problem but vanishing gradients is because if it vanishes you cannot do anything because you could think of it that you already have a learning rate which is getting multiplied with the vector the gradient now in addition to the learning rate which was anyways clipping the norm of the gradient right so you are doing an expressive clipping also so it just like a additional learning rate inductions right ok"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/110_4.wav", "duration": 46.0, "text": "so this is just the same thing written in words so if the stated time t minus one did not contribute much to the state at time t because ft was tending to zero right then during backpropagation the gradients flowing into st1 minus one will also vanish because again during backpropagation the gradients will get multiplied by ft and they will vanish but this kind of vanishing gradient is fine this is fair because if we did not contribute in the forward direction why should i help you hold your responsible in the backward direction right so that is fair so the key difference from rnns is that the flow of gradients is now controlled by gates which give the same regulation in the forward pass as well as the backward pass right so only if you contributed to something you will be held responsible if your contribution vanished your responsibility in the backward pass will also vanish right so that is the intuition"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/110_5.wav", "duration": 12.511, "text": "and will next see an proof for this a proof actually it s as based on the intuition but i just make it more formal in terms of introducing the notations and so on so that problem we will do it in the next class ok"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/111_1.wav", "duration": 170.0, "text": "ok so will start from where we left off so in the last class we started with this motivation that recurrent neural networks have this problem of vanishing and grade exploding gradients and we wanted to arrive with some principle way of avoiding this so you have first started with this intuition that in many real life situations like for example the human brain or the whiteboard we tend to these to these three operations called selective read selective write and selective forget and they essentially help us in dealing with these finite sized memories right or whether it is a whiteboard which is finite sized or your brain or whatever it is right so can we is it possible to kind of improve rnn\u2019s which also suffer from this problem that they have this finite sized memory and hence if you are trying to capture everything from time step one then by the time you reach time step t where say t is thirty or forty or so on its quite natural that whatever you have learned earlier will get move off to an extent that it just is not recognisable anymore right so you wanted to deal with this problem and with that we motivated selective read write and forget and then we introduced some equations or converted this into a model and this is the diagram that you see is the model actually that is the lstm cell yeah and it has these three gates output gate input gate and forget gate and which perform these three functions of selective read write and forget so intuitively all these was fine but we need to be more technical in terms of you trying to deal with a problem of vanishing and grade exploding gradients so how does it solve that problem all that makes or the story seems fine but how does this actually relate to the math so we saw some intuition for that and the intuition hinsed on this observation that during forward pass the gates control how much of information passes from one state to another and in particular if you have the situation that from one time step to another say the forget gate tells you that keep forgetting point five of the previous state then by the time you reach say the one hundred state you would have forgotten five raise to one hundred of the first state so that means even during forward pass the information from state one vanishes so if it vanishes during backward path that is also fine because state one did not contribute to state one hundred and that was the intuition that all this hinsed on now we are not going to do much different from this intuition we just going to see the corresponding equations for these intuitions and just make a more i would not call it rigorous but more mathematical proof on why lstm solve the problem of vanishing gradients and we are also sure that they actually do not solve the problem of exploding gradients and then we will see a simple trick of dealing with exploding gradient that is what we will do in the remainder of this particular lecture and then will move on to the next lecture in this lecture"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/111_2.wav", "duration": 54.0, "text": "so we will now see an illustrative proof of how the gates control the flow of gradients right"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/111_3.wav", "duration": 69.0, "text": "now in particular what is happening here is the following that you have this loss at time step t you have the time step is four now what if this loss or this error occurred because w was not good enough to compute a good value for s1 right so w was at a certain configuration based on that you computed s1 and that s1 was not good enough which eventually led to the error at time step four all of you if you can imagine this situation that you mean you not being not be able to do something well at s1 now this needs to be told to w so that it can improve right and that information has to come through s1 that information is already going from here but this information is about how badly it performed in computing s4 this is not how badly it can perform in computing s1 so that information has to travel to w all the way through s1 and that was not happening because this path do not look at the bullets this path was actually vanishing and that is what this multiplicative term says that as the number of times that increased that time that path would vanish ok so that is the actual problem that we are trying to deal"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/111_4.wav", "duration": 66.0, "text": "so now what is the general situation here right the general principle is that the gradient of l theta at particular time step say here we are considering l4 so i will just call it lt with respect to any parameter theta i the parameters at w u v b and c with respect to any parameter it would vanish if all the paths leading to that parameter if it vanishes so with respect to this particular path so that is the only path which leads to w through s1 if there were multiple paths if there was say one such direct path right if we had you some other kind of connection which gave us this direct path then it would still have been fine but there was only one path leading to w through s1 at the gradient vanishes along that path then the gradient will vanish ok if there were multiple paths then only if the gradient varnishes across all the paths then the gradient would vanish is it fine what is the corresponding rule for exploding gradients if there are multiple paths the gradient would explode if student refer time six hundred and six if it vanishes through any one if it explodes though any one of the paths ok"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/111_5.wav", "duration": 27.0, "text": "so these are the two things that we need to consider ok so to prove that in the case of l st m this does not happen for the first case will have to show that there are at least one path through which it does not vanish and for the second case because we are going to show that it explodes we just have to show that there is at least one path through which it can explode ok so these are the two things that we need to prove and the first thing that we are going to focus on is the vanishing gradient problem"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/111_6.wav", "duration": 244.0, "text": "so will start with the dependency graph for lstm\u2019s that means i want to draw something similar for lstm\u2019s involving all the different elements in lstm so what are these different elements the two rhyming things one being gates states ok so gates and states that the two things that we care about so let us look at all these so starting with states at time step k one at time step k one you have this two states sk one and hk1 ok using hk1 you are going to compute the output gate at time step k and it is also depends on these parameters wo uo and bo right which is obvious from the equation just to make sure that this diagram remains tractable i am going to get rid of the parameters and i will come back to them later so right now will just focus on the states and the gates ok and then you have these other intermediate states and the other gates right so you had fk you had ik so add these three gates the temporary state and then what else what are the other two things at time step k so we saw this diagram about all the computations which happen at time step k right how many computations happen three states and three gates right so you seen the three gates and this one temporary state so which are the other two things there is no selective forget with you guys is early everything forget hint look at the grey cells and change the time step what will you get away are you all i mean we did lstm\u2019s two days right i mean are you all with that or should i we need to revise something mean i do not need to revise it but we going to is it fine ok so sk and the other thing hk remember that sk also depends on hk just stare at this for thirty seconds and make sure that you are with it right all the equations are there these are the see six equations that or the six computations which happen at time step k there are three gates and three states and the dependency graph is obvious from these equations except for the fact that i have ignored the parameters how many if you are comfortable with the equations and the graph corresponding graph please raise your hands high so i think it should be right we have these six equations and we have this dependency graph"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/111_7.wav", "duration": 143.0, "text": "and this exactly what i said i am interested in knowing that if this loss can reach wf through sk right so all the three highlighted things that what i am interested in i am interested in the path to wf through sk of course there are many other paths to wf but they do not account for the problem in sk is that fine everyone is clear the setup ok now and we can ask similar questions about all the other parameters the w\u2019s the us the the input gate parameters the output gate parameters and so on right there is nothing so special about wf the same question holds for all these other parameters also ok now how does lstm ensure that this does not vanish so let us see that"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/111_8.wav", "duration": 58.0, "text": "so now consider one such path which is this highlighted path that is a valid path to reach to sk now let us denote the gradient along this path to be t naught and the total gradient is going to be a sum of many such paths right so i am calling this path as t naught and this is what the gradient look like ok so this is simple just this red path the next red path and then the series of problematic multiplications right you have this recursive multiplications again so everyone agrees that red is good the red path there is no recursion the gradient will flow right we just need to focus on the blue path everyone is convinced about that right ok so that is good the first term is fine as i said because it directly connected to l t there is no recursive or no other intermediate nodes so the gradient will just flow through that there is not a problem there and now we look at the other terms which is first is dht st and the other is this ok"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/111_9.wav", "duration": 88.0, "text": "so let us look at ht st what is this going to be tensor vector matrix scalar at this point in the course i want a unanimous answer student matrix matrix right and recall that in particular the equation was of this form ok so what is the derivative going to look like even without computing can you tell me something profound about it it will be a dash matrix big matrix how many if you say diagonal matrix how many if you do not think it is a diagonal matrix please raise your hands total sum is never one so remember that ht is equal to ht1 ht2 up to htd and you have ot equal to ot1 ot2 otd and st equal to st1 st2 std so ht2 depends only on ot2 and st2 right it does not depend on in particular does not depend on any of the other st\u2019s so we have already seen this before in such cases whats the i jth entry of this matrix of the gradient matrix derivative of hti with respect to stj which of these terms are going to be zero wherever student i not equal to zero i is not equal to zero that means it results in a student diagonal matrix diagonal matrix"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/111_10.wav", "duration": 36.0, "text": "so that is exactly what is written here and the diagonal elements are going to be this is that fine everyone with this ok so now this diagonal matrix which contains this on the diagonal i am going to represent it by the following notation is that ok fine so this is a diagonal matrix where every element is i mean this is actually a vector right everyone agrees this is a vector so this diagonal is this vector is along the diagonal of this matrix how many if you get this notation if you do not get this you will not understand anything else"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/111_11.wav", "duration": 435.311, "text": "now let us consider st st1 ok this is what st is equal to so what is the derivative of st st1 ft right ft right what else why no why are you rebelling what the i mean st only right if it is can you treat this as a constant no why because this is a dash network student refer time one thousand, six hundred and thirty-four so in an ordered network the derivative will have two terms which are those student explicit explicit and implicit in the explicit term what you assume the other terms to be a constant right fine so st i mean s tilde t also depends on st1 so we cannot treated as a constant so once again this derivative is going to contain an explicit term and an implicit term now i am going to make a worst case assumption i making this assumption that actually the implicit term vanishes notice that this not favourable to me i am trying to prove that the gradient does not vanish the gradient is a sum of two terms i am saying it let the worst case be that one of these terms vanishes ok so this is not a favourable assumption this is a unfavourable assumption which i am making so let us fine so i making the assumption that the implicit term vanishes so what is the explicit term actually student ft ft and what kind of a matrix is that student diagonal matrix if you agree that it is a matrix first of all it is a diagonal matrix again and what is the diagonal student ft ft right so i am going to represent it as d of ft is that fine"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/112_0.wav", "duration": 43.0, "text": "department of computer science and engineering indian institute of technology madras lecture \u2013 fifteen encoder decoder models attention and mechanism and in this lecture we are going to talk about encoder decoder models and attention mechanism so this is a very interesting lecture at least interesting to me because this is very put all these pieces that we have learnt so far right we have learnt three types of networks feedforward networks recurrent neural networks and convolutional neural networks and we have seen independent applications of each of these word to vec and image classification and so on now today what we are going to see is how do we do different combinations of these networks and come up with a wide range of applications like apply them to a wide range of applications ok so let me start by an introduction to encoder decoder models and then we do various applications of encoder decoder models"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/112_1.wav", "duration": 531.0, "text": "so what we are going to do is we will start by revisiting the problem of language modeling so the problem of language modeling was that you are given some t one words or characters and you want to predict the tth word or character right this is like auto complete in short right whenever we are typing something you have type four words you want to predict the fifth word or you have typed four characters and you want to predict the fifth character ok so more formerly this is what we are interested in how many of you get this equation this expression so we are given a sequence of t one words and you want to find out what the value of y would be at time step t and we want to find out that value which maximizes this property that is what this argmax equation means and now we will try to see how to model this using a rnn so let us see we are going to start with go that is that we want to start generating a sentence and then we will produce the first word which is i ok and what is it that we are predicting at this point what is the network supposed to predict what is the output supposed to predict actually it is supposed to predict a dash over the vocabulary a broadly distribution over the vocabulary right so this is what is happening we will of course come back to this on the next few slides but you have say words w1 w2 up to w v in your vocabulary at every time step you want to find a distribution over these words and then pick the word which had the maximum probability at that time step right that is exactly what this quantity is that is what we want the rnn in to model and then we want to keep doing this till we reach the end of the sentence ok so that is the language modeling problem and as we had made a case for it earlier the word produce the time step t depends on a few previous words how does a recurrent neural network ensure that at any time step i am going to give it only one word as the input so how does that ensures that it depends on all the previous words also through the recurrent connections and the gate and sorry it is not the gate the state st ok fine"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/112_2.wav", "duration": 33.0, "text": "now one more thing that you need to notice that s0 which is the input at time step one the previous so s11 so that we do not know what it is so we just keep it as a parameter we say that s0 is also weight vector and you are going to learn it along with all the other parameters in the network does not make sense because you do not know what s0 means is a semantics of it is not clear like what was generated at the 0th time step we do not really know right so will just make it a learnable parameter and that would be trained along with all the other parameters of the network"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/112_3.wav", "duration": 65.0, "text": "so before we move on what we are going to do is we are going to see a very compact representations for rnns grus and lstms so remember rnn is the following equation rnn is defined by the following equation the st is a recursive function of st1 and xt right so i am just going to write it as that st is equal to rnn of st1 xt instead of writing all these parameters and sigma\u2019s and all that i am just going to write it compactly as this now this is what what is this gru so how may going to write it as students gru gru of students st1 xt st1 xt what is this students lstm lstm how may going to write it lstm of when the output of the lstm is both ht1 and st1right fine so in some sometimes i will just say st sometimes i will say both ht minus ht and st as per whatever i needed right so this is i am not going to write these equations and parameters again i will just say that lstm of this assume that is a function which does this calculation and gives you back ok ok"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/112_4.wav", "duration": 279.0, "text": "so far what you have done is we have seen how to model the conditional probability distribution given the previous t minus one words now let me give you a different application right what if we want to generate a sentence given an image so this is what i am interested in doing i am giving an image and i want to generate a sentence can we just think of it formally what is it that you want to do so we saw that in this case formally we were interested in this conditional distribution in this case what is it that we are formally interest in if i were to write it as something formal what would i write it as ok i will give you a hint what kind of a distribution is this a conditional distribution right given the previous sequences previous sequence of words generate the tth word now in this situation can you stated an similar words given the students image image generate the students sentence sentence or given the image and the description that are generated so far because i am going to write the description one word at a time given the image and the description that have written so far generate the next word in the mission so what kind of conditional distribution is that pyt given students y one to t minus one y1 to t minus one students comma comma students image image does that make sense everyone gets that ok so what so this is what we want right so here now we are interested in this quantity as a post to this quantity does that make sense ok and this is again a conditional distribution"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/112_5.wav", "duration": 193.0, "text": "ok but still there are some issues and there are other ways of making this condition on f c seven in particular what you could have done as she was trying to suggest initial is that maybe you have a vocabulary of all the objects that are possible in your image right so maybe in your image there is man woman there is flying desk frisbee or there is dog cat and all these things right so you do an object detection first get out all the object which are there and then make the distribution conditional on these objects right so you can say that i will allow for a ten words to describe the image so there word one is equal to man because i have detected the object man in the image word two is equal to frisbee because i have detected the object frisbee in the image that is all that is another way of doing it ok so i just want to make it clear that there are different ways of making the conditional distribution conditional on the image itself we are choosing to make it conditional on f c seven of i right that is the neural way of doing it ok"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/112_6.wav", "duration": 130.388, "text": "so what would the diagram look like just passing the input to every stage of the decoder ok i have already started using terminology which have not introduced but i will just introduce it shortly"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/113_0.wav", "duration": 373.0, "text": "and for all these applications we are trying to answer the following questions what kind of network can we used to encode the input in the previous application what do we use cnn what kind of network can be used to decode the output what did we use student rnn rnn what are the parameters of the model we will see that and what is an appropriate loss function right"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/113_1.wav", "duration": 40.0, "text": "and same task textually entailment i want model two option two so this is what will happen we will just concatenate h capital t which is this guy along with the input at every time step right how many if you get this the rnn is still taking just two inputs one is the previous state the other is the concatenation of the current input as well as input that we got from the encoder everyone get this ok so this is model two i am going forward i am not going to do both model one and model two it is model two is just a very simple variation of model one a parameters loss function training algorithm everything remains the same ok"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/113_2.wav", "duration": 289.0, "text": "let us look at machine translation what is the input an english sentence what is the output a hindi sentence what is the encoder going to be student rnn rnn what is the decoder going to be student rnn6rnn what is the loss function going to be student refer time seven hundred and thirty-seven soft max who said soft max student refer time seven hundred and forty-two what is the loss function going to be student sum of sum of cross entropies training algorithm all the way through time right ok so let us can you draw can you write the equations just copy it from the previous slide right actually copy it from the previous slide right if you have the rnn you have the rnn as a decoder again in option when you will set s zero to h t you have the loss function the parameters and your training algorithm ok and for option two it is back propagation will fine and for option two what will happen option two what will happen student refer time eight hundred and seventeen this will change right so just focus on that we just passed in the last time say belong with that"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/113_3.wav", "duration": 92.0, "text": "document summarisation what is the input sequence what is the output rnn rnn everywhere fine i will not even bother to ask you"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/113_4.wav", "duration": 201.583, "text": "the next one video classification what is the decoder decoder is probability distribution okay what is the decoder student feed forward neural network feed forward neural network"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/114_0.wav", "duration": 4.0, "text": "so let us go on to the next module which is attention mechanism"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/114_1.wav", "duration": 302.0, "text": "so let us motivate not the task of attention let us motivate attention mechanisms with the help of machine translation ok so what is happening in the models that we have seen so far the current model that we saw for machine translation by the way all the models that i have shown you so far are wrong or rather incomplete we will complete all of them right and that is where attention fits in ok that was for the camera a encoder reads the sentence and its computes the encoding once right we read the entire sentence and be encoded it and then we have these two options either the pass the encoding at the zero time step or pass this encoding at every time step is this how humans translate a sentence what is the human analogy for this you have read the sentence once done and now we are going to remember this entire thing throughout and then translate imagine if you doing this for sentences which have twenty-five words which is a typical wikipedia sentence what is wrong with this we have read the input ones and we have encoded it what is likely to happen you will forget something you are going to lose information not just that is the entire sentence important that every time step student refer time one hundred and twenty-eight only certain words are important you see this conceptually something wrong that we are doing here is is saying ok i have encoded the sentence and then start decoding from there ok thats the conceptual error that we are making so let us see how humans actually try translate it right"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/114_2.wav", "duration": 287.0, "text": "so in fact what i am saying is that i could just take a weighted combination of all the blue vectors that i have at the encoder and the weights of this weighted combination right now i am assuming that someone oracle has given me is that ok if i had his weights does this makes more sense then having the vanilla encoder decoder model everyone agrees with that ok now the question of course us who is going to give us these weights we will come back to that later but at least given the weights this make sense so at every time step they just going to focus on the words which are actually important just take a weighted combination of those words and we will just feed that to the decoder and intuitively this should work better because unlike before where we were overloading the decoder with the entire sentence remember twenty-five words thirty words entire sentence was being passed to the decoder now you are just overloading it with the amount of information that it actually needs to produce that particular word hence intuitively this should work better right ok now how do you convert this intuition into a model"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/114_3.wav", "duration": 434.0, "text": "so this is what the equation for the jt is that we had an alpha j actually denotes the probability of focusing on the jth word at the tth time step ok now we are now trying to learn these alphas instead of an oracle telling us what these alphas are so learning is always going to involve some parameters so let us define a parametric form for alphas and just a couple of notations"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/114_4.wav", "duration": 77.0, "text": "so there is a hope of doing better because now the model is actually making a more informed choice right it is a more informed way of learning how to do translation by focusing on certain words at every time step and now these parameters how will they get adjusted they will get adjusted because at every at a given time step you produced a wrong output you did that maybe because this parameter was wrong which is the v parameter or maybe because these recurrent connections were wrong or maybe because your attention weights are not proper so now adjust the attention weights and that should given sufficient data it should be able to learn which words to focus on just as humans learn how to do translation right even when we are doing learning how to translate or when we learn translating from one language to another we are not given this word by word supervision right we just do a lot of translations or read a lot of translations and somehow understand that while translating i need to focus on certain words and at every time step this is the word that i need to focus on so given enough words it should be able to learn that at least someone gets the joke good so that is the hope and in practice indeed these models work better as compared to vanilla encode you do not know where the statement comes from"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/114_5.wav", "duration": 271.0, "text": "so now let us what we will do is so this entire thing hints on hope only right that is all that is all i am saying but it does makes sense right because you have these additional parameters which you can learn and you can back propagate through them i will just not stop there will actually prove what happens not proved by demonstrate what happens in practice right so with this attention model in mind let us look back at the encoder decoder model that we had for machine translation integrate the attention mechanism with it and then let us see the end to end equation that we get ok"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/114_6.wav", "duration": 67.0, "text": "so you can go back and try adding attention mechanisms to all the models that we have seen before right see how will you compute so remember the only purpose of ok what kind of a network is the attention network it is a single feed forward neural network right this is just transforming a simple linear transformation of the inputs and in a nonlinearity on top of that and then just again one more transformation right it is a simple feed forward neural network only these three equation somehow need to be fitted in all the other models that we have seen so far right this is a very generic framework just as the encoder decoder framework or the very generic framework the encode attend decode framework is also very generic framework you can go back and model all the applications that we saw and you can change them change them to at the other case ok try to answer the same set of questions what\u2019s the data what\u2019s the encoder what\u2019s the decoder what\u2019s the loss what\u2019s the training function and in particular remember that in when you go back represent all the applications that you have done the data is not going to change no one is going to give us the supervision for the alphas that is one thing which is not going to change ok"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/114_7.wav", "duration": 174.871, "text": "so here is one more thing so this probably tie to this question like how do we be sure that the alphas actually learn something meaningful now what do i mean by this if i have to convince you that alphas are actually learning something meaningful and let us take the context of machine translation what do i need to show you suppose the model has generated an output for a given input sentence it has generated a translation what do i need to show you to convince that it is learn some kind of weights at every time step what should i show you student refer time two thousand, four hundred and forty-six what does the attention weights look like right so let us see"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/115_1.wav", "duration": 86.0, "text": "so let us start s last lecture we are looking at encoder decoder models and we saw that a bunch of problems from different domains and different modalities images text videos and so on and even this cross modal or multi modal applications where you are taking a video and trying to describe it so video is one modality description texts is another modality and so on we were able to propose modals for all of these using this encoder \u2013 decoder architecture and then we motivated this attention mechanism where we said that encoder decoder is trying to do this silly thing where it tries to encode the entire input once and that is what how humans do it he do this back and forth thing where at every time step if we are trying to produce a translation or a single word in the translation we just focus on certain words in the input sentence and kind of ignore the other so the attention mechanism which is this bunch of equations that you see here that allowed you a neural way of modelling attention and the key thing to note here is a there was a supervision for the attention no one actually tells us that this is the portion of the text which is important at time step t but they still works better because this is the better modelling choice and i give you that bicycle analogy and also it is a better modelling choice we are able to no one has given you these supervisions but you are still have more parameters in the model to learn this kind of a behaviour"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/115_2.wav", "duration": 29.792, "text": "and then we also saw that we could actually visualise these attention based and from some experiments on some papers we saw that actually learn some meaningful attentions in the particular case on the figure on the on the right hand side so the one that clearly shows that for a monotonic kind of a translation scenario between english and french most of the attentions weights are along a diagram and that is exactly what you would expect right so that is where we end it"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/116_0.wav", "duration": 13.0, "text": "and so now in this lecture we will go on to the next module which is talking about attention over images so let us first motivate why is it so different and what could be done there right"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/116_1.wav", "duration": 4.0, "text": "so the question is how do we model an attention mechanism for images"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/116_2.wav", "duration": 31.0, "text": "so in the case of text we have a representation for every location of the input sequence right so every location in the input sequence in the case of text was a word and then you are looking at this problem of transliteration every location was a character and whether it is a character or a word for everything it was discrete so we could just know that this is the important time step t and then we know that along all the inputs at different time steps you want to pay attention to certain time steps right so that the definition they was very straightforward right"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/116_3.wav", "duration": 602.038, "text": "now for images what do we do so for images we typically take the representation from a cnn right it could be fc seven or any of the convolution layers or max pooling layers right now there is no concept of time step there right because the entire image is given to you at one go so now how do you decide where to pay attention to but if you think about it does makes sense at least the motivation is very clear so for example for this figure if i am trying to generate the description as man throwing a frisbee in a garden or in a park or something like that right so when i am generating a word man i would want to focus only on the man and not focus on any other part of the image similarly when i am generating the word frisbee i would like to focus on this may be when i am saying throwing i would like to focus on his hand action or something like that and in a park i would like to focus on the background and so on so it does make sense that each word in the description is complete covering from coming from a different space in the image or different position in the image but the representation that we use say the fc seven representation that doesnot contain any location information it just a flat and vector that we had so now how do we do this how do we get attention on locations is is a motivation and the problem clear and motivation is straight forward the problem is that we are using fc seven representation is just a flat vector remember that was the fully connected vector and does not have any location based encoding so if for example if the fully connected vector is of size five hundred and twelve i cannot say that the first twelve or first twenty-four of these five hundred and twelve dimensions correspond to this set of pixels the next twenty-four corresponds to this set of pixels and so on right so that is the problem how do i what do i attend to how do i decide where to attend to because that is what i am saying that the vector the elements of the vector or the dimension of the vectors do not have any semantic right that is not that the first dimension corresponds to first location what you want an attention on this locations in the image right but the first dimension in the vector fc seven vector does not correspond to any specific location in the image you know that was a fully connected vector right so it corresponds to everything in the image so what something simpler than that why do i say something simpler than that object detection is itself is a in itself is a another convolution neural network which does this and so on right and we saw this past or seen in past class seen in problems now let us solve the problem at hand the problem at hand is that i want i will just rephrase a problem definition so that the answer becomes obvious i want a representation which allows to give which allows me to get some location information no but the fully connected layer if you back track it was fully connected by definition right the answer is really straight forward the problem only arise at the fully connected layer right because that is fully connected but what about the outputs on the convolution layers do they have position information student yeah sir yes"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/117_0.wav", "duration": 14.0, "text": "so we will go on to the next one which is hierarchical attention so again something very popular in nowadays become very common for various things so again not very difficult idea to understand"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/117_1.wav", "duration": 252.0, "text": "so let us first look at the motivation for this and then we will look at the solution so consider a dialog right today everyone is interested building chatbots every second start up wants to build their own chatbot and every second startup out of that they wants to build for the agriculture domain or the banking domain or the healthcare domain so here is what a typical dialog looks like right this is of course not for any profound purpose this is but you can see this is an important dialog right very relevant and very important so this is what a dialog looks like so let us try to break it down into the kind of entities that we deal with so can you tell me about a dialog what is a dialog it is a dash think in terms of things that we have discussed so far student refer time one hundred and seven sequence good right again the safest answer is sequence from now on no it is only for one lecture it is a is it a just a sequence or sequence of sequences right so it contains a sequence of utterances so each of these lines here is an utterance and each utterance in turn is a sequence of words right ok so what we have here is a sequence of sequence as input and this is very common in many many applications right so can you think of an encoder for such a sequence of sequence rnn of rnn\u2019s good that is the answer right"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/117_2.wav", "duration": 237.0, "text": "what is missing here attention ok so let us look at another example consider the task of document classification or summarisation what is the difference between two in classification what the what were the decoder be feed forward neural network with the softmax what would be decoder be in the case of summarisation students rnn rnn good what is the document sequence of sequence not sequence of sequence of sequence it can be a sequence of sequence of sequence also right i did not think of that then it could be a sequence of sequence of sequence of sequence ok let us look at the not so funny case which is sequence of sequence what is the sequence of sequence of it is the sequence of sentences which in turn is a sequence of words which in turn is a sequence of character we will not go there we will just keep it till words so it is a sequence of sequence so again you need some kind of a hierarchical encoder here right so will encode each sentence then you will treat the sentence sequence as a sequence encode that and then you will pass it to the classifier now think of this problem right now if we want to do document classification how would you go about it actually you want to classify whether this is a politics or sports or health or whatever refer time five hundred and fifty-seven i think in terms of attention what would you do actually first we will find the important words in the sentence to find the important words you will have to read all the students refer time six hundred and ten if you want to find the important words you will have to read all the sentences so what will you do first find the students word in sentences word in sentences and then important words within the sentence so what kind of an attention mechanism do you need student hierarchy hierarchical right"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/117_3.wav", "duration": 12.0, "text": "and then the decoder is just a softmax we do not need to go with that and loss and everything is fine so this again whatever it is we should always be comfortable and writing the end to end equations from x to y right and you can write it in this case"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/117_4.wav", "duration": 50.0, "text": "now let us make it a bit interesting how would you model attention in such a hierarchical encoder decoder model how many attention functions would you need two one for attention over sentences the other for attention over students works works ok can you think of these equations not a very big stretch from what we have done already right i mean at level one it should be straight forward at level two just ignore level one how many if you can imagine the equations it is not very hard i am not joking i am i mean just think about it and the level one should be straight forward because that is just the same as ok so first we need to attend to the most important words in a sentence and then we need to attend to the most important sentence in a document ok"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/117_5.wav", "duration": 351.0, "text": "let us have see how to model this so we have document again the same input then you have the word level rnn ok now what be the word level attention equation look like"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/117_6.wav", "duration": 274.668, "text": "ignore the equations on the slide it was something like this v transpose tan h of w student s t st1 uw1j student b b ok now imagine that your decoder is a feed forward neural network what will be missing in that case there is no s t minus one there is no previous state of a decoder because we just want to make a prediction once by paying attention to all the important words and sentences in your document right so which part will go away wst1 ok fine now the other thing that you are doing is alpha was actually or other alpha i j is actually exponent of e i j divided by summation of other k sorry alpha j t e j t e k t is that fine it is just the softmax equation is that ok right now the only thing that you see different and these two equations here is first you do not have the w s t minus one because the decoder only has one time step and second we have taken out this v transpose from here and instead we have added it here is that ok does that make sense this is just different way of writing it so again you write the attention equation for the words now ok now what about the sentence now first of all earlier what were we using for the green guy what was the representation for the green vector it was the what was the green vector in the absence of attention what was the green vector h t i right the last time step of sentence one is it fine everyone with me please raise your hands if you are with me ok now what would it be it would be a dash sum of w vectors a weighted sum attention weighted sum right so that is exactly what this equation is capturing so what did you saying is there is representation of sentence i is a weighted sum of the representations of all the words in that sentence is it ok so that we will get a representation for s one s two up to s capital k all the sentences that you have now what do you want to do for the second level what do we want we want to compute the importance of that sentence for the tth time step right so let us call that beta so i am interested in beta if we need to really read out this i said again alpha is being used in both the places right so you want to find out the importance of the jth sentence at the tth time step what is it going to be a function of one is a sentence representation what is the sentence representation given by student s j s j and what else the decoder state at the previous time step right does the decoder have a previous time step state here no so it will just depend on s j and that is exactly what this equation is capturing right and again the same trick that i have added this extra parameter to the exponent is that fine and the final representation being fed to the feed forward network is a weighted sum of the sentence representations right so this again has to be si si ok i really sorry about this but i am pretty sure that once we correct the slides and then you go back and look at it should be clear right it just two sets of equation one set of equation sorry os sorry that is correct sorry so this the idea is there are two sets of attention mechanisms for each you will have your own set of equations the basic form if you can work out what the f attention would depend on the actual form would depend from would differ from paper to paper or the toolbox to toolbox that does not matter so much you just need to know that you have these as the input you are going to add some parameters to every input that means you are going to do linear transformation and then you just need to make sure that alphas eventually turn out to be scalars right that is why you will have this additional vector getting multiplied at one point"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/12_0.wav", "duration": 8.0, "text": "now let us go to the next module which is perceptron"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/12_1.wav", "duration": 137.0, "text": "so far the story has been about boolean input but are all problems that we deal with we are only dealing with do we always only deal with boolean inputs so yeah so what we spoke about is boolean functions now consider this example this worked fine for a movie example where we had these as actor so much and his director and so on but now consider the example where you are trying to decide you are in oil mining company and you are trying to decide whether you should mine or drill at a particular station or not now this could depend on various factors like what is the pressure on the surface on the ocean surface at that point what is the salinity of the water at that point what is the aquatic marina aquatic life at that point and so on so these are not really boolean function the salinity is a real number density would be a real number pressure would be a real number and so on right and this is a very valid decision problem companies would be interested in doing this so in such cases our inputs are going to be real but so far mcculloch pitts neuron only deals with boolean inputs so we still need to take care of that limitation now how did we decide the threshold in all these cases i just asked you you computed it and you told me right but that is not going to work out i mean it does not scale to larger problems where you have many more dimensions and the inputs are not boolean and so on so we need a way of learning this threshold now again returning to the movie example maybe for me the actor is the only thing that matters and all the other inputs are not so important then what do i need actually i need some way of weighing these inputs i should be able to say that this input is more important than the others now i am treating all of them equal i am just taking a simple sum if that sum causes a threshold i am fine otherwise i am not fine but maybe i want to raise the weight for some of these inputs or lower the weight for some of these inputs so whether it is raining outside or not maybe does not matter i have a car i could go or i could wear a jacket or an umbrella or something so that input is probably not so important and what about functions which are not linearly separable we have just been dealing with the goody stuff which is all linearly separable but we will see that even in the restricted boolean case there could be some functions which are not linearly separable and if that is the case how do we deal with it so these are some questions that we need to answer"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/12_2.wav", "duration": 91.0, "text": "so first we will start with perceptron which tries to fix some of these things and then we will move forward from there so as we had discussed in the history lecture that this was proposed in one thousand, nine hundred and fifty-eight by frank rosenblatt and this is what the perceptron looks like do you see any difference with the mcculloch pitts neuron weights you have a weight associated with each of the input otherwise everything seems so this is a more general computational model than the mcculloch pitts neuron the other interesting thing is that of course we have introduced these weights and you also have a mechanism for learning these weights so remember in the earlier case our only parameter was theta which we are kind of hand setting right but now with the perceptron we will have a learning algorithm which will not just help us learn theta but also these weights for the inputs how do i know that actor is what matters or director is what matters given a lot of past viewing experience past given a lot of data about the movies which i have watched in the past how do i know which are the weights to assign this so we will see an algorithm which will help us do that and the inputs are no longer limited to be boolean values they can be real values also so that is the classical perceptron but what i am talking about here and the rest of the lecture is the refined version which was proposed by minsky and papert which is known as the perceptron model so when i say perceptron i am referring to this model so this diagram also corresponds to that"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/12_3.wav", "duration": 121.0, "text": "so now let us see what the perceptron does this is how it operates it will give an output of one if the weighted sum of the inputs is greater than a threshold so remember that in the mp neuron we did not have these weights but now we have these weighted sum of the inputs and the output is going to be zero if this weighted sum is less than threshold not very different from the mp neuron now i am just going to do some trickery and try to get it to a better notation or a better form so is this i have just taken the theta on this side now is this notice this here the indices were one to n now i have made it zero to n and the theta is suddenly disappeared so what has happened student w zero is minus theta right and x0 is one does anyone not get this right if i just start it from one to n then it would be summation i equal to one to n wi xi plus w0 x0 but i am just saying w0 is equal to minus theta and x0 is equal to one which exactly gives me back this right so very simple x0 equal to one and w0 is equal to minus theta so in effect what i am assuming is that instead of having this threshold as a separate quantity i just think that that is one of my inputs which is always on and the weight of that input is minus theta so now the job of all these other inputs and their weights is to make sure that their sum is greater than this input which we have does not make sense so this is how this is the more accepted convention for writing the perceptron equation so it fires when this summation is greater than equal to zero otherwise it does not fire"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/12_4.wav", "duration": 18.0, "text": "now let me ask a few questions so why are we trying to implement boolean functions i have already answered this but i will keep repeating this question so that it really gets drill in why do we need weights again we briefly touched upon that and why is w naught which is negative of theta often called the bias"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/12_5.wav", "duration": 33.0, "text": "so again let us return back to the task of predicting whether you would like to watch a movie or not and suppose we base our decisions on three simple inputs actor genre and director now based on our past viewing experience we may give a high weight to nolan as compared to the other inputs so what does that mean it means that as long as the director is christopher nolan i am going to watch this movie irrespective of who the actor is or what the genre of the movie so that is exactly what we want and that is the reason why we want these weights"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/12_6.wav", "duration": 50.0, "text": "now w0 is often called the bias as it represents the prior so now let me ask a very simple question suppose you are a movie buff what would theta be zero i mean you will watch any movie irrespective of who the actor director and genre now suppose you are a very niche movie watcher who only watches those movies which are which the genre is thriller the director was christopher nolan and the actor was damon then what would your threshold be three high in this case i always ask this question do you know of any such movie always takes a while interstellar so the weights and the bias will depend on the data which in this case is the viewer history so that is the whole setup that is why you want these weights and that is why you want these biases and that is why we want to learn them"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/12_7.wav", "duration": 23.0, "text": "now before we see whether or how we can learn these weights and biases one question that we need to ask is what kind of functions can be implemented using the perceptron and are these function any different from the mcculloch pitts neuron so before i go to the next slide any guesses i am hearing some interesting answers which are at least partly correct"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/12_8.wav", "duration": 44.0, "text": "so this is what a mcculloch pitts neuron looks like and this is what a perceptron looks like the only difference is this red part which is weights which has added so it is again clear that what the perceptron also does is it divides the input space into two halves where all the points for which the output has to be one would lie on one side of this plane and all the points where which the output should be zero would lie on the other side of this plane so it is not doing anything different from what the perceptron was doing so then what is the difference you have these weights and you have a mechanism for learning these weights as well as a threshold we are not going to hand code them so we will first revisit some boolean functions and then see the perceptron learning algorithm"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/12_9.wav", "duration": 93.587, "text": "so now let us see what does the first condition this condition if i actually expand it out then this is what it turns out to be and what is that condition telling me actually w naught should be less than zero clear so now based on these what do you have here actually what is this a system of linear inequalities right and you know you could solve this you have algorithms for solving this not always but you could find some solution and one possible solution which i have given you here is w0 is equal to minus one w1 equal to eleven and w2 equal to eleven so just let us just draw that line so what is the line it is eleven x1 plus eleven x2 is equal to one that is the line and this is the line and you see it satisfies the conditions that i have is this the only solution possible no right i could have this also as a valid line if i could draw properly right all of these are valid solutions so which result in different w1 w naught and w 0s so all of these are possible solutions in fact i have been telling you that you had to set the threshold by hand for the mcculloch pitts neuron but that is not true because you could have written similar equations there and then decided what the value of theta should be so you could try this out for the mcculloch pitts neuron also you will get a similar set of conditions or i mean similar set of inequalities and you can just say what is the value of theta that you could set to solve that"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/13_0.wav", "duration": 16.0, "text": "before we go to the next section which is on learning i just want to introduce the concept of errors and error surfaces and tell you what it relates to these multiple solutions that we were talking about"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/13_1.wav", "duration": 97.0, "text": "so for simplicity what we will do is we will just set the threshold to minus or minus w to one which is setting the threshold to minus one and now i will try different values of w1 and w2 ok so i was saying that there are multiple values of w1 and w2 possible and these are all real numbers we are not constrained by having them as boolean values so now this is one solution which i tried i tried setting w1 to minus one and w2 to minus one what is wrong with this line does it lead to any errors how many just one error so this makes an error of one out of the four inputs now let me just try some other values of w1 and w2 this line again one error what about this line not four three because zero zero is anyways on this side of a line so now given this now tell me that i my quest is to find these w so i would want to find w1 w2 and so on given this discussion on errors can you tell me a condition that i am looking for i want to find w1 w2 or up to wn such that errors are minimized and in the best case errors are zero so that is what i want so this just i want to make a case that these search for w\u2019s is driven by certain objective and this objective is to minimize the error so now since we are doing this let us plot the error surface corresponding to different values of w naught w1 and w2"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/13_2.wav", "duration": 107.063, "text": "once again for simpler analysis we will just keep w naught to be fixed at minus one and now what i have so just do not read this bullet as of now even this one so i have this w2 here so that is my one axis and i have w1 here which is my another axis now what i am going to do is i am going to try different values of w1 and w2 so this axis can go from minus infinity to plus infinity of course for showing the sake of showing here i have just had it from minus four to four so now what i am going to do is i am searching for some values of w\u2019s w1 and w2 so that my errors is zero and let us do a brute force and i will just try every value between minus four to four ok in fact one of the solutions which i proposed actually was this eleven eleven right that is the line which we saw on the previous slide and which led to zero errors and that is the dark blue surface here so how did i compute this error actually i just substituted minus sorry eleven eleven here and then i put in all the four values combinations for x1 x two and i realized that i am able to satisfy all of them so i do not get any error now instead of that if i had put something different so let me just go back to the previous slide which was see minus one minus one which is i think yeah somewhere around here right minus one minus one i guess so for that i am in this light blue region where the error was one i make errors for one of the inputs so it is a very brute force way of finding this and this is not going to work because we have lots of inputs to check but this is just to give you an intuition that we are looking at errors and we are trying to find a value of w1 w2 which minimize this error so that is the idea behind errors and error surfaces"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/14_0.wav", "duration": 7.0, "text": "we will now go to the next module which is the perceptron learning algorithm"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/14_1.wav", "duration": 8.0, "text": "we now see a more principled approach of learning these weights and threshold but before that we will just again revisit our movie example and make it slightly more complicated"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/14_2.wav", "duration": 66.0, "text": "now here what the situation is that we are given a list of m movies and a class associated with each movie indicating whether we like the movie or not so now we have given some data of the past m movies that we have seen and whether we like this movie or not and now instead of these three variables we have these n different variables based on which we are making decisions and notice that some of these variables are real they are not boolean anymore the rating could be any real number between zero to one ok and now based on this data what do we want is the perceptron to do actually so i have given you some data these factors i have also given you the label one and zero so if the perceptron if i tell you my perceptron has now learnt properly what would you expected it to do perfect match so whenever i feed it one of these movies it should give me the same label as was there in my data and again there are some movies for which i have a label one which are positive and some movies which i have a label zero so i am once again looking to separate the positives from the negatives so it should adjust the weights in such a way that i should be able to separate so that is the learning problem that we are interested in"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/14_3.wav", "duration": 144.0, "text": "so now with that i will give you the algorithm this is the perceptron learning algorithm we have certain positive inputs which had the label one we have certain negative inputs which had the label zero and now i don\u2019t know what the weights are and i have no prior knowledge of what the weights are going to be i need to learn them from the data so what i am going to do is i am just going to initialize these weights randomly as i am also going to pick up some random values for this so this should be small n so this should be small n and now here is the algorithm while not convergence do something so before i tell you what to do can you tell me what is meant by convergence when will you say that it has converged when it is not making any more errors on the training data right or its predictions are not changing on the training data so that is the definition of convergence now here is the algorithm i pick up a random from point from my data which could either be positive or negative so it comes from the union of positive negative basically all the data that i have i pick up a random point from there if the point is positive right and this is the condition which happens what does this tell me if the point was positive what did i actually want greater than zero but the condition is less than zero that means i have made an error so i have made an error then i will just add x to w i see a lot of thoughtful nodding and i hope you are understanding what is happening let us see so what is w actually a dimensional n dimension n plus one right because w naught is also inside there so actually there should be w naught also here right and what is x again n dimensional right and that is why this addition is valid so let us understand that w and x both are n dimensional now let us look at the other if condition can you guess what the other if condition is if x belongs to n and summation is greater than equal to zero then so that means you have completely understood how this algorithm works well that is so now consider two vectors w and x so remember what we are trying to prove is or get an intuition not prove actually get an intuition for why this works ok"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/14_4.wav", "duration": 79.0, "text": "so we will consider two vectors w and x and this is what my vectors look like very similar to the case that we are considering w0 to wn and one to n so this again x naught is just one now this condition that i have been talking about is nothing but the dot product how many of you have gone through the prerequisites for todays lecture ok good so it is just a dot product now we can just read write the perceptron rule as this instead of the dot product i mean instead of using that summation thing we can just say that it is a dot product now we are interested in finding the line w transpose x equal to zero so that is our decision boundary which divides the input into two halves now every point on this line satisfies the equation w transpose x equal to zero what does that mean actually so just a simple example is that if i have the line x1 plus x2 equal to zero then all the points which lie on the line satisfy this equation so you could have one minus one two minus two and so on but two two is cannot be a point on this line at every point lying on this line satisfies this equation so every point lying on this line actually satisfies the equation w transpose x equal to zero"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/14_5.wav", "duration": 44.0, "text": "so can you tell me what is the angle between w and any point on this line how many say how many of you say perpendicular why dot product is zero so if the dot product is zero they are orthogonal so that means if i take this line then my vector w is orthogonal to this it is orthogonal to this point or this point to this point to every point on the line which is just the same as saying that the vector is perpendicular to the line itself right as simple as that so the angle is ninety degrees because the dot product gives you the cos alpha and that is zero right and since it is perpendicular as i said to every point of the line it is just perpendicular to the line itself"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/14_6.wav", "duration": 94.0, "text": "so this is what the geometric interpretation looks like this is our decision boundary w transpose x and the vector w is actually orthogonal to this line and that is exactly the intuition that we have built so far now let us consider some points which are supposed to lie in the positive half space of this line that means these are the points for which the output is actually one now can you tell me what is the angle between any of these points and w or you guys are actually trying to tell me the angle we have got some measuring stuff no so i will give you three options i e equal to ninety greater than ninety and less than ninety less than ninety it is obvious from the figure now if i take any point which lies in the negative half space what is the angle going to be between them it is greater than ninety again obvious and it also follows from the fact that cos alpha is w transpose x by something and we know that for the positive points w transpose x is greater than equal to zero that means cos alpha would be greater than equal to zero that means the angle alpha would be less than ninety degrees and for the negative points w transpose x is actually less than zero that means cos alpha would be less than zero that means alpha would be greater than ninety degrees so it actually follows from the formula itself but it is also clear from the figure so keeping this picture in mind let us revisit the algorithm so this is the algorithm"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/14_7.wav", "duration": 75.0, "text": "now let us look at the first condition which was this now if x belongs to p and w transpose x is less than zero then means that the angle between x and the current w is actually greater than ninety degrees but what do we want it to be less than ninety degrees and our solution to do this is but we still do not know why this works now anyone knows why this works so let us see why this works so what is the new cos alpha going to be it is going to be proportional to this it is going to be proportional to this i will just substitute what w new is fine that means if cos alpha new is going to be greater than cos alpha what is alpha new going to be it will be less than and that is exactly what we wanted this angle was actually greater than ninety degrees so you want to slowly move it such that it becomes less than ninety degrees it is not going to get solved in one iteration and that is why till convergence so we will keep doing this i will keep picking xs again and again till it reaches convergence that means till we are satisfied with that condition"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/14_8.wav", "duration": 53.0, "text": "let us look at the other condition x belongs to n and w transpose x was greater than equal to zero then it means that the angle alpha is actually less than ninety degrees and we want it to be the opposite i will just quickly skim over this w minus this x ok i forgot to mention that this is actually a positive quantity i mean that is why that result holds that means cos alpha new is going to be less than cos alpha and this slight bit of mathematical in correctness i am doing here but that does not affect the final result so i will just gloss over that and you can go home and figure it out but still it does not take away from the final intuition and interpretation so now the new cos alpha is going to be less than the original cos alpha that means the angle is going to be greater and that exactly what we wanted"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/14_9.wav", "duration": 4.0, "text": "so we will now see this algorithm in action for a toy data set"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/14_10.wav", "duration": 88.0, "text": "so this is the toy data set we have and we have initialized w to a random value and that turns out to be this i just picked up some random value for w and ended up with this particular configuration for w now we observe that currently w transpose x is less than zero for all the positive points and it is actually greater than equal to zero for all the negative points if you do not understand w transpose x it is just that the all the positive angle points actually have a greater than ninety degree angle and all the negative points actually have a less than ninety degree angle so this is exactly opposite of the situation that we want and now from here on we want to actually run the perceptron algorithm right and try to fix this w how does it work remember we randomly pick a point so say we pick the point p1 do we need to apply a correction yes why because it is a positive point and the condition is violated so now we add w equal to w plus x and we get this new w so notice that we have a new w we again repeat this we again pick a new point and this time we have picked p2 do we need a correction yes at least from the figure it looks like the angle is greater than ninety so we will again do a correction we will add w is equal to w plus p this x is actually sorry p2 and this is where we end up"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/14_11.wav", "duration": 20.0, "text": "now again we pick a point randomly n1 do we need a correction so this is what our w is this line here and n1 so we need a correction now what is the correction going to be it will be minus and then the w changes"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/14_12.wav", "duration": 7.0, "text": "now we pick another point n3 do we need a correction no at least on the figure it seems like the angle is greater than ninety and we continue this"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/14_13.wav", "duration": 4.0, "text": "for n2 we do not need a correction now for p3 again we do not need a correction"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/14_14.wav", "duration": 9.0, "text": "the angle looks less than ninety sorry actually it is we need a correction the angle is slightly greater than ninety and this is our correction and now we keep cycling"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/14_15.wav", "duration": 2.0, "text": "now as i keep cycling over the points i realize that i no longer need any correction"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/14_16.wav", "duration": 70.102, "text": "it should be obvious from the figure that for this particular value of w now all my positive points are making an angle less than ninety and all my negative points are actually making an angle greater than ninety that means by definition now my algorithm has converged so i can just stop it so i can just make one pass over the data if nothing changes i will just say it has converged now does anyone see a problem with this it will never converge in some cases so can someone tell me why we are considering only cases where the data is linearly separable that we already assumed so what you are trying to tell me is that you are going over these points cyclically so let me just rephrase and put words in your mouth that what you are trying to tell me actually is that i take a point i adjust w but now for the next point i maybe go back to the same w because that point asked me to move it again and i keep doing this again and again and basically end up nowhere that is why this will never converge that is exactly what you are trying to tell me now that is exactly what i am forcing you to tell me so that is not the case this algorithm will converge"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/15_0.wav", "duration": 11.0, "text": "in this module we will talk about the proof of convergence for the perceptron or the learning algorithm that we saw in the previous module"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/15_1.wav", "duration": 10.0, "text": "so we have some faith and intuition that it actually works we just need to formally prove it that it actually converges so that is what we are going to do in this module"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/15_2.wav", "duration": 151.0, "text": "so before that a very few very simple definitions so if you have two sets of points p and n in an n dimensional space and we call say that these points are absolutely linearly separable if there exists some n plus one real numbers which has w0 to wn such that every point which belongs to p right p is the case where the output is one then these set of weights satisfy this condition and every point which lies in the negative set the set of weights satisfy this condition so nothing very different from what has we have been saying so far it is just formally defining it now our proposition is that if the set p and n are finite and there is a fixed number of points in that which was the case in the toy example that we were doing and which will be the case in most examples that we do and linearly separable the perceptron learning algorithm updates the weight vector ok before i go there ok let me not give you the definition and let me ask you the definition so now i have given this definition the first definition and given this part of the proposition can you tell me what do i need to prove if i need to prove that the algorithm converges that is one way of looking at it but what was happening in that wrong argument which was i was making that it continuously kept toggling that means i am not making a finite number of updates right i have to keep changing again and again and this process continues in a loop so that is how i am going to define convergence that the perceptron learning algorithm updates a weight vector of finite number of times it only needs to update it finite number of times and it will reach a configuration such that now it is able to separate the p from the n ok that is what the proof of convergence means so in other words if you are going to pick up these vectors randomly from the set p and n cyclically as we were doing in the toy example then a weight vector wt is found after a finite number of steps which will separate these two steps these two sets so that is what we are trying to prove so that is the definition of converge does it make sense"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/15_3.wav", "duration": 343.0, "text": "so proof is on the next slide and it is going to take me around five to ten minutes to prove it so just stay focused all right so here is a few set up right so i am going to before i go to the actual proof i am going to make a set up so that it becomes easier for us to prove it so the first thing that i am going to say is that if there is a point which belongs in negative set then the negative of that point belongs in the positive set and that is very clear because if the point belongs in the negative set then w transpose x is less than zero but then w transpose minus x would be greater than equal to zero right so i take the negative of the point i can just put it in the positive set so instead of considering these two different things p and n i am just going to consider one p prime which is an union of p and all the n points negative ok will the set up clear if this is a setup then what is the condition that i need to ensure for every point in p dash student refer time three hundred and fifty-seven w transpose p should be greater than equal to zero right so i do not care about the negative case i have just made everything positive now and it is i am not done anything wrong here it is just a simple trick ok and now this is how the algorithm will look in this setup these are the inputs with label one inputs with label zero n minus contains a negation of all the points in n and p prime is a union of these now again i start by initializing w randomly while convergence i will do something i will pick a random p from p prime now what is the if condition less than zero do i need the other if condition no right because everything is now positive ok and the other small thing that i am going to do is i am going to normalize p ok so that again does not mean because we are talking in terms of angles and i am not changing the direction of the vector i am just shrinking it right so i am just or maybe scaling it also i am just making it unit norm so that does not change anything so it is still everything still holds and in particular you can see here so if this condition was true this condition will also be true ok so so far just i am done some simple tricks to make things easier for me later on so now p has been normalized now remember that this data is linearly separable that is what we started the proposition if p and n are linearly separable then the perceptron learning algorithm will converge so now if p and n are linearly separable irrespective of whether we have the perceptron learning algorithm or not what do we know there exists a w star which is the solution vector right there exists at least one w star which is the solution vector right such that it will separate the p points from the n points so this vector which we do not know but we just know that it exists so you can refer to it so we will call this w star fine now we start the proof"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/15_4.wav", "duration": 94.0, "text": "now are you ok with this this is the minimum quantity right so any pi that i put in here it is always going to be greater than or worst case equal to delta now again this w2 itself i could write it as wt minus one plus pj because that also would have come up from some update in the previous step ok again this is there which i could call it as delta and still retain the greater than equal to here ok fine so let us see where are we heading with this now notice that we do not make a correction at every time step when i was running that toy algorithm i was not making a correction at every time step we were only making a correction at those time steps for which the condition was violated so now if i am at t\u2019th time step maybe i have made only k which is less than or equal to t corrections at max i would have made t corrections but it could have been less than that also so now every time we make a correction we are adding a value delta to this so at the time step t what would happen i had started off from w naught i have reached time safety and i have made a case that i have not made t updates i have made k less than equal to t updates so how many deltas would get added k delta so i could say that with respect to w naught where i had started from this is what this quantity is ok is that fine anyone has a problem with this"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/15_5.wav", "duration": 137.0, "text": "so far what are we shown we started with this this condition was true again not less than equal to and hence we made the correction and this was the point that we picked up at the t th step and thence we made that correction and we also showed that the numerator is actually greater than equal to this quantity we showed it by induction fine now let us look at the denominator and particularly let us look at the denominator squared ok is a step right this is actually wt plus one dot product wt plus one but wt plus one can be written as wt plus p i this bracket needs to disappear right is that ok fine now what is what is this quantity that is less than equal to zero so now can you guess what is the next thing that i am going to write that is correct yeah it is a negative quantity so that is going to be less than equal to this so that is fine and what about pi square or this term because this is less than right that is why correct is this fine ok now what is pi square one now can you guess what i am going to do by induction so what is wt square again just this wt plus one square was wt square plus one wt square is going to be wt minus one square plus one right and how many such ones will get added k of those right starting from w naught ok"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/15_6.wav", "duration": 113.0, "text": "so what have we shown the numerator is greater than equal to this the denominator is less than this ok now if i put them together i actually get that cos beta is going to be greater than equal to the numerator over the denominator ok now what is this quantity proportional to k k square k cube square root of k k by two student square root of k square root of k right you have i mean roughly speaking you have a k here you have a square root of k here so i could roughly speaking say that it is proportional to square root of k so as k grows what will happen to cos beta it will grow and that is fine right it can keep growing student refer time one thousand, three hundred and thirty-one only until one right so cos beta is going to be proportional to k what is k the number of updates that you make now if i were to take that degenerate case which you guys were hinting at where that it will keep changing again and again what will happen to k it will keep going to infinity can that happen no because cos beta will blow up right and that is not allowed so k has to be finite so that cos beta stays within its limits right hence are we done how many if you think we are done how many if you are satisfy that we are done"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/15_7.wav", "duration": 37.623, "text": "so yeah so this says that we can only have a finite number of such k updates that we make and after that the algorithm will converge so we have a proof of convergence now coming back to our questions this is where we had started at one point what about non boolean inputs so perceptron allows that we took imdb rating and critics rating as an input do we always need to hand code the threshold no in our perceptron learning algorithm are all inputs equal no we now assign weights to input what about functions which are not linearly separable we still do not know so that is where we are headed now not possible with a single perceptron but we will see how to handle this"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/16_0.wav", "duration": 10.0, "text": "so in this module we look at linearly separable boolean functions again and we will try to make some more statements about them"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/16_1.wav", "duration": 16.0, "text": "so what do we have do so the guiding question that we have is what do we do about functions which are not linearly separable and let us see one such very simple function can you guess what function i am going to talk about all of you are paying attention in the first lecture"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/16_2.wav", "duration": 81.0, "text": "so here is the xor function now these are the set of inequalities that result from xor function i hope right now let us see the first condition implies that w naught should be less than zero second condition implies this third condition implies this fourth condition implies this just looking at this can you tell me can you find a configuration for w naught w1 w2 such that these inequalities can be satisfied together no right because two and three want it to be greater than minus one minus w naught and when you take an addition of that it has to be less than minus one so that is not going to happen so you see a contradiction so this is a simple boolean function which the perceptron cannot handle because it is not linearly separable it is not linearly separable there does not exist a line if there does not exist a line you cannot find the line in fact you can look at it visually so these are the red points for which the output should be zero or one and the blue points are the points for which the output should be zero if we need to change this i think we were using blue as positive and red as negative and you cannot just draw a line there is no way you can draw a line such that the blue points lie on one side and the red points lie on the other side so it is a simple two input function so it is not that i have taken a very contrived example"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/16_3.wav", "duration": 79.0, "text": "most real world data is not linearly separable and it always contains some outliers right so here maybe you have some data where you are trying to say that people which live in this part of the world belong to a certain or maybe people who live or work here have a certain qualification people who work in this company may have a certain different qualification and there might be some outliers right it is not that is always going be very clean so now what do i mean and it is not necessary that the points will only be outliers in fact there could be a clear case where there are no outliers but still you cannot find a line such that you separate the positive from the negative can you think of such an example good right this is clear data there is no outliers here as well i mean it is just saying that everyone who lies within this boundary has a certain characteristic and outside that boundary people have a different characteristic right and there is no outlier here but you cannot separate this data with a line so all functions that you deal with will not go or are not going to be linearly separable so we have to work around those right and while a single perceptron cannot deal with this we will show that a network of perceptron\u2019s can indeed deal with such data so that is where we are headed"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/16_4.wav", "duration": 10.0, "text": "so before going there we will discuss some more boolean functions in more detail and i will try to see what kind of nonlinearly separable boolean functions are there"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/16_5.wav", "duration": 141.231, "text": "so first of all how many boolean functions can you design from two inputs how many can you design sixteen looks like a good number from three inputs two hundred and fifty-six how many if you understand this let us see so let us begin with some easy ones that you already know right so these are two inputs x1 x2 what is this function always off the other extreme is always on and i have already given you the answer f sixteen so then you have the and function and or function then some other functions right so why did you reach sixteen actually because with two inputs we will have these four values to take care of and each of these are again binary so you actually have two raise to two raise to n right so for three inputs two raise to two raise to three would be two hundred and fifty-six now that is the easy part of these how many are linearly separable i will have to do any actually stare it in and seriously try to find the answer when you cannot really do that so turns out all of them except xor and in not of xor ok so for the two input cases there are two functions which are not linearly separable for n inputs how many functions would be not linearly separable it is an arbitrary n is not the answer you are not going to disappoint me not n ok but what is the answer so for n inputs we will have two raise two n functions of these we do not know how many are going to be not linearly separable that is not a solved problem although i encourage you to go and find the answer i am looking for a good will hunting kind of a moment but all it suffices to know is that there exists some which are not linearly separable and that everyone agrees that there exists some right and as n grows probably that number will increase and so on but it is not known exactly you cannot write it as a function so what we have done so far is looked at boolean functions how many boolean functions can exist and of that we just have concluded that there would be some which are not linearly separable"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/17_0.wav", "duration": 15.0, "text": "we will go to the next module where we talk about a network of perceptrons and then we talk about the representation power of a network of perceptrons so this module should have been titled as network of perceptrons so now in particular what we are going to see is how any boolean function whether linearly separable or not can be represented using a network of perceptrons"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/17_1.wav", "duration": 32.0, "text": "now what do i mean by represented during a network of perceptrons what it means is that i will give you a network of perceptrons you take any boolean function feed any value of x1 to xn and the network will give you the same y as it is expected from the truth table ok that is what representation means just to put it out clearly"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/17_2.wav", "duration": 106.0, "text": "and now i am going to again do a setup i am not giving you the solution i am just making some set up and then we will discuss the solution so for this discussion we will assume that true equal to plus one and false equal to minus one so instead of zero and one we will assume minus one and plus one and these are your inputs x1 and x2 we are taking the two input case and i will have four perceptrons first i will have four perceptrons and i will also have very specific weights connected to form the inputs to these perceptrons so red means minus one and blue means plus one right so the first two inputs are connected with a weight of minus one the next two inputs with minus one plus one plus one minus one and the last would be plus one now once i have this i will set the bias of all these perceptrons to minus two so that will that means they will fire only if they are weighted sum of the inputs is greater than two now after this i will have one more perceptron so i had two inputs i converted that to four values these four values are now going to feed into one more perceptron and these weights i will not fix them these are the weights that i am going to learn ok these and the final output of this perceptron which is the green perceptron is the output of the network right so now coming back to what i said that it can represent any function what i mean is that you take any function feed in any combination of x1 x2 this network will give you y and i am telling you that it will match the truth table of that function"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/17_3.wav", "duration": 51.0, "text": "now let us define some terminology this will also stay with us for the rest of the course so this network contains three layers the layer containing the inputs it is called the input layer very creative the middle layer containing the four perceptrons is called the hidden layer and the output layer which gives you the output is called the output layer output perceptron which gives you the output is called the output layer right so you have a input layer a hidden layer and an output layer and the outputs of the four perceptrons i am going to call them as h1 h2 h3 and h4 and the red and blue edges are called the weights for the layer one which we have not learned we have actually set them by hand and the weights for w1 w2 w3 w4 are called the weights for the second layer other the layer two weights and these are the weights that we want to learn"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/17_4.wav", "duration": 85.0, "text": "now i make this claim that this network it can take any boolean function it can implement any boolean function so this same network can implement any boolean function that means if i take this network and if i try to learn the values of w1 w2 w3 w4 for any boolean function whether it was originally linearly separable or not i will be able to implement it so isn\u2019t this an astonishing claim any boolean function do you think this is an astonishing claim well not really if you really understand what is happening here right so let us see what exactly is happening here so when will perceptron one fire when the input is false false zero zero will it fire for any other input when will perceptron two fire any other input same for the next perceptron same for the next perceptron so you start getting an intuition of what is happening here you do ok let us see so now for this particular network now that i have given you some intuition of what is happening basically every node or every neuron in the hidden layer is catering to one of the inputs and it will fire only for that input it will not fire for anyone else"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/17_5.wav", "duration": 161.0, "text": "so now let us try to implement the xor function and see what are the so now let us try to implement the xor function and see what are the set of inequalities that result from this earlier when we try to look at the set of inequalities we ended up with a contradiction let us see if that happens now so this is x1 x2 this is your xor function so that is just like any truth table then i am noting down the intermediate values and then my final input to the green perceptron is going to be summation of these and it will fire if this summation is greater than equal to zero or else it will not fire now for the first case when the input is zero comma zero what is h1 going to be one and everything else is going to be zero that is exactly what we saw in the previous slide so what is the summation going to be just w1 right so it is w1 h1 plus w2 h2 so on but h2 to h4 are zero so only thing that remains is w1 for the second case w2 for the third case w3 for the 4th case w4 so is it clear now what is happening let us go a bit more into detail right so now for the xor condition what are the conditions that we need w1 should be less than w0 because this should not fire w2 should be greater than equal to zero w3 should be greater than equal to sorry w naught not w is not zero and w4 should not fire so w4 should be less than w0 are there any contradictions here by design no right so we have made sure that for the final layer only one of these guys feeds to it so it does not matter what the remaining outputs are they do not interfere with each other unlike earlier where we had conditions like w1 should be something w2 should be something and then w1 plus w2 should be something there are no such contradictions here because we have made sure that every neuron in the middle layer actually caters to one specific input and now the weights in the final layer can be adjusted so that we get the desired output for that input so i can set whatever value of w1 i need to set so that i can fire the neuron in fact i could just fix w0 as zero and then i can adjust the weights of w1 w2 w3 w4 and i can implement the xor function so are you convinced that this can be used to implement any boolean function how many if you are not convinced so the negative question never works how many if you are convinced sure now what if we had three inputs"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/17_6.wav", "duration": 16.0, "text": "before that it should be clear that the same network can be used for any of the remaining fifteen functions and for each of these functions we will end up with a different value of w1 w2 w3 w4 but you will be able to satisfy the truth table right and you can go home and try it which i am sure you will do"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/17_7.wav", "duration": 15.0, "text": "ah so what if we have a function of three inputs two hundred and fifty-six what is two hundred and fifty-six no eight fine sure"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/17_8.wav", "duration": 36.0, "text": "so this is what it will look like and anything specific about the weights of the initial layer can you tell me what the weights would be just tell me red red red red blue blue whatever colours you like this thing first perceptron what would the weight colours be red red red then enough so this is how it will look right right and now this same thing will work with the same logic for any boolean function of three inputs you will get these eight inequalities and they will not interfere with each other and you can set the values of w1 to w8 so that you can satisfy it ok fine"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/17_9.wav", "duration": 8.0, "text": "so what if we have n inputs two power n perceptrons in the middle layer right ok"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/17_10.wav", "duration": 66.0, "text": "so now here is the theorem any boolean function of n inputs can be represented exactly by a network of perceptrons containing one hidden layer with two raised to n perceptrons and one output layer containing one perceptron we just saw an informal proof of this we just constructed i just gave you the answer it this is how you will get it now note that a network of two raised to n plus one perceptron is it sufficient or necessary or both sufficient yes that is what it says is it necessary no we already saw the and function which we can just represent using a single perceptron right so it is not necessary but it is sufficient so this is a very powerful theorem if you think of it right so now this whole objection right remember this history and when we have the c i winter when people showed that perceptron cannot handle the xor function that is for a single perceptron if you have a network of perceptrons you can actually have any boolean function but what is the catch as the value of n increases the number of neurons increases exponentially right but still in theory you could have a solution"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/17_11.wav", "duration": 33.0, "text": "now again why do we care about boolean functions i keep coming back to this why do we care about boolean functions because you took this and so the question that i the question that i want to answer is how does this relate back to our original problem right we know any boolean function can be implemented how do we go back to our original problem which is whether we like a movie or not right and you could see that there is a whole family of problems there right whether we like a movie or not whether we like a product or not whether i want to go home today or not yes no any kind of a yes no problem it is a whole family of problems there"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/17_12.wav", "duration": 95.0, "text": "so let us see so we are given this data from our past experience right so we are told that this is what the movie looks like these are the actor\u2019s director\u2019s joiners everything we also know whether we like these or not so we have a set of positive points and we have a set of negative points right and now we want to have a computational model which can satisfy this data that means once the model is trained once whatever algorithm i algorithm i use has converged it should be able to give me the correct output for a given input that is what we are interested in and that is a real classification problem that we are interested in now for each movie we are given these factors as well as the decision and i said pi\u2019s and ni\u2019s are positive and negative points the data may or may not be linearly separable it is not necessary that the data is linearly separable those were the goody cases it but in general that may not happen but do we worry about it now no what the previous theorem told us is that irrespective of whether your data is linearly separable or not i can give you a network which will be able to solve this problem modulo that it might be very expensive in the number of neurons in the middle layer but if you keep that aside i have a solution for this and that is why we care about boolean functions because many problems we could actually cast to it in a simplistic way if we ignore the real inputs and if you even think of the real inputs suppose it could take all values between zero to one you can always make it binary you could say that is the value between zero and one is the value between one and two and you could make it as small the scale as small as possible right so that is why we care about this"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/17_13.wav", "duration": 50.029, "text": "so the story so far has been that the network of networks of the form that we just saw it which contain one input layer output layer and one or more hidden layers these are known as multilayer perceptrons but a more appropriate terminology would be multi layered network of perceptrons because the perceptron is not multilayered you have a network of perceptrons and that network has many layers right but generally there is abuse of notation we always call it mlp which is multilayered perceptrons and the theorem that we just saw gives us the representation power of an mlp and basically tells us that it can represent any boolean function that we want to deal with so that is where we will end this class and in the next class we will talk about sigmoid neurons"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/18_0.wav", "duration": 21.0, "text": "we are in lecture three of cs7015 and today we are going to cover the following modules we are going to talk about sigmoid neurons gradient descent feedforward neural networks representation power of feedforward neural networks"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/18_1.wav", "duration": 31.0, "text": "so let us start so here are some acknowledgments so for one of the modules i have borrowed ideas from the videos of ryan harris on \u201cvisualize back propagation\u201c they are available on youtube you can have a look if you want for module thirty-five i have borrowed ideas from this excellent book which is available online it is the url as mentioned in the footnote and i am sure i would have been influenced in borrowed ideas from other places and i apologize if i am not acknowledge them probably properly if you think there are some other sources from which i have taken ideas and let me know i will put them in the acknowledgments"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/18_2.wav", "duration": 8.0, "text": "so with that we will start with module thirty-one which is on sigmoid neurons so the story i had is that it is enough about boolean functions"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/18_3.wav", "duration": 145.0, "text": "now we have done a lot of boolean functions but now we want to move on to arbitrary functions of the form y is equal to f of x where x could belong to rn and y could belong to r so what do i mean by this so let me just explain this with the help of an example so i will again go back to our oil mining example oil drilling example where we are given a particular location say in the ocean and we are interested in finding how much oil could i drill from this place and that is what i would base my decision alright whether i want to actually invest in this location or not and then what we are saying is that this could depend on several factors so we could have x1 x2 x3 up to xn right where this could be the salinity of the water at that location so this could be a real number this could be the density of the water it is average density this could be the pressure on the surface of the ocean bed and so on and so forth so each of these values independently belongs to the set of real numbers so each of this is a real number and we have n of these so together they belong to rn so i can read that i have n such real numbers and i could just put them in a vector and say that i have a input x which belongs to r raised to n so we have this x which we can say belongs to rn and in this particular case we want to predict y we want to take this as an input and predictor y and what is y in this case you want to predict the quantity of oil that we could mine so what does ry belong to again a set of real numbers and it could be some gallons or litres or kill of water so this again belongs to r so these are the kind of functions that we are interested in now we want a function which takes us from i am having this x which belongs to rn right it is a vector of dimension n and takes us to a value belonging to r so you clearly see that this is different from the case when we had n variables each of this was just boolean so these were only zero one inputs now we have real inputs and these are the kind of functions that we are interested in"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/18_4.wav", "duration": 370.0, "text": "now can we have a network which can represent such functions now what do i mean by represent such functions we already spoke about this when we were doing boolean functions so what do we mean by representing the function we mean that if i am given a lot of training data right so i am given these x1 x2 each of these belongs to rn and i am also given the corresponding labels now i want a network which should be able to give me the same predictions as is are there in my training data so it should be able to take any of these x\u2019s as input and it should give me the same y i corresponding to it and i am saying approximately which means i am with some error rate whether if it is within some to with as long as it is close to the actual value i am fine with it so that is what i mean by a network which can represent such functions is that working definition of representing clear right so that is a very similar to the definition that we were used for boolean functions we had said that we should be exactly be able to get the truth table the network should be able to represent the truth table exactly so that is very similar to the definition that i am using here"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/18_6.wav", "duration": 8.0, "text": "so let us start so recall that a perceptron will fire if the weighted sum of it is inputs is greater than the threshold just recall that fine"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/18_7.wav", "duration": 74.0, "text": "so now i claim that the thresholding logic which is used by a perceptron is actually very harsh now what do i mean by that let us see so let us return to a problem of deciding whether we like or dislike a movie that is the same problem that we have been dealing with and now consider that we base our decisions only on one input which is the critics rating which lies between zero to one and this is what my model looks like it takes the input as the critics rating i have learned some weight for it and my threshold is five what does this mean it means that if for a given movie the rating is fifty-one will it predict like or dislike like so then i should go and watch the movie what about a movie for which the critics rating is forty-nine dislike so now you see what i mean by harsh so both these values are very close to each other but for one i say i like it for the other i say that i would not like it so it is not how we make decisions right you would have probably said something equal for both the movies you would have not given such a drastic decision"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/18_8.wav", "duration": 51.0, "text": "so why is this happening so you might say oh this is a characteristic of a problem that you have picked up maybe that is the critics rating which is between zero to one or something but i want to convince you that this is not a characteristic of the problem that i have picked up but this is something to do with the perceptron function itself so this is what the perceptron function looks like so this sum of all the inputs the weighted sum of all the inputs i am calling it by a quantity z and this is what i am going to plot on the this axis so this is my z axis now what does the perceptron say that when this value of z becomes greater than w naught or minus of w naught it will fire and when it is less than minus of w naught it will not fire that is what it says so this is a characteristic of the perceptron function itself it is going to have this"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/18_9.wav", "duration": 23.0, "text": "sharp decision boundary that whenever your sum crosses this threshold you will say one and whenever your sum does not cross this threshold you will say zero so in this toy example over the movie critics it just happened that this was five and so it was saying yes for fifty-one and it was saying no for forty-nine so this will happen for any problem that you pick up"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/18_10.wav", "duration": 123.0, "text": "so to counter this we introduce something known as sigmoid neurons and this is just a smoother function or a smoother version of the step function you see that how many if you know what a sigmoid function what is the formula for a sigmoid function quite a few good and here is one such sigmoid function which is called the logistic function so remember that sigmoid is a family of functions these are functions which have this s shaped logistic function which i have shown here is one such function and the other function that we will see in this course is something known as the tanh function so let me just get into a bit more detail with this logistic function i just want you to understand it properly so this quantity here remember we were writing it as w transpose x which was summation i equal to zero to n wi xi remember this so now i am just going to consider this to be one over one plus e raise to minus w transpose x now i am going to ask you some questions and try answering those what happens when w transpose x tends to infinity what happens to the sigmoid function one and that is exactly what is happening here as this tends to infinity as this keeps growing so remember this axis is z which is the same as w transpose x right this is w transpose x so as it tends to infinity your sigmoid goes to one what happens if w transpose x is minus infinity zero and that is exactly what is happening here and what happens when w transpose x is equal to zero half so this is that value corresponding to half is that clear so that is how a sigmoid function behaves fine"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/18_11.wav", "duration": 50.0, "text": "now we no longer see a sharp transition it is a very smooth function and the sigmoid function lies between the values produced by the sigmoid function rate what is the range that they lie between zero to one what is another quantity of interest that you know which lies between zero to one probability so that is one advantage of sigmoid functions so now you can interpret the value given by a sigmoid function as a probability so what does it mean in our movie example again so it just tells me in those two cases that with fifty one percent probability i like the movie or with forty-nine percent probability i like the movie so now this is not very drastic or very harsh right i am not saying yes or no i am not committing myself i am just giving you a number which is proportional to how much i like the movie so it can be interpreted as a probability"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/18_12.wav", "duration": 19.0, "text": "now here\u2019s the overall picture it so this is the difference between the perceptron function and the sigmoid function so notice that here we had this if else condition right which was leading to that sharp boundary now here we do not have that defence condition we just have a function which is a smooth function"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/18_13.wav", "duration": 40.587, "text": "and here is another picture so this is not smooth not continuous and not differentiable everyone agrees with that it is not smooth here right it is not differentiable here whereas this is smooth continuous and differentiable and the contents that we covered today it will be very important to deal with functions which are smooth continuous and differentiable so for lot of this course calculus is going to be the hero of the course lot of the things that we do will be based on calculus and in calculus always if you have smooth and continuous and differentiable functions they are always good so that is why we want to deal with such functions"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/19_0.wav", "duration": 11.0, "text": "we will start module two which brings us to a typical supervised machine learning setup this is a very important module please pay attention"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/19_1.wav", "duration": 173.0, "text": "so now we have a sigmoid neuron we have taken care of the fact that the perceptron was a very harsh function so we have a smooth function so things are fine now what next where do we go from here what is my next topic going to be yes a lot of you are giving the right answers we need to learn these weights it does not help just to define the function this function depends on certain weights and now i need to give you an algorithm which will help you to learn these weights now remember when i talked about perceptrons before giving you an algorithm what did i revisit what did i talk about the error surfaces and then i had motivated from there that our goal is to find a set of weights which give us close to give us zero error in that case or in general\u2019s speaking generally they should give us a minimum error they should help us to minimize the error rate so i need to set up that similar story here so we will again revisit the concept of error"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/19_2.wav", "duration": 274.0, "text": "so this brings us to a typical machine learning setup which has the following components so this perhaps is the most important slide in the course and i will say this at least for one hundred other slides in the course but at least for now this is the most important so you are given some data xi yi and you are given n such elements right so let me just elaborate on this and give me i will give you some instances of this let me give you some instances of this right so one thing we say i already told you was this so this is my x and this is my y so one example which i gave was about movies so this was genre actor and critics rating and so on this is one instantiation of this problem i could also give you another instantiation which was i just told you oil right so this is how much oil can i get and here my factors were salinity density and so on there were many other factors so this was my x again x belongs to rn where n is some number integer and another example could be say fraud detection so i have a customer i am a bank i have a customer who has bought some credit card and i want to predict whether he or she would commit a fraud and i would look at factors like what is his occupation maybe salary maybe family size and so on there could be various factors which i could look at so here again this becomes an x ok and you could think of various such examples right where you are given an x and you are given a y ok so this is the data that you have now what is machine learning where does machine learning fit into this so we know that there is some relation which exists between y and x in each of these cases all of us are convinced that there is some relation so whether a person would commit a fraud would depend on these factors it is reasonable to assume that it is not a very wild assumption whether you would find oil at a location would depend on some of these factors and it is related and similarly for the movie case so there exists some true relation between x and y such that if i plug this value of x into the relation it would give me the value of y there exist a true relation this true relation could be governed by various things right it could be governed by physical laws example in the oil mining case it could be even governed by biological laws again the marine life in that location and so on it could be governed by economic law\u2019s it could be covered by psychology right we do not know why a person cheats what is his function that he is using when he cheats and so on right so these could depend on various factors but we all agree that some function exists hence we get these values for this particular input for every input we get a certain value so there is some function which takes us from the input to the output we do not know what this function is we never know in practice it is a very very complex function is all that we know we do not know this exact function if you knew this exact function then there is no problem to solve we just use that function and you can predict how much oil and all of us can become billionaires so that is not the case we do not know what this function is so then what do we do in machine learn we make an assumption ok we make an assumption that there is some function which takes x to y and this function is governed by some parameters and this is our approximation of how the real world works and now under this assumption we want to predict the parameters of this model given the data now let us take a very simple case where we could assume that y is equal to wx plus b i am taking this in the scalar single dimensional case now how would you estimate the values of w and b oh come on if i give you two data points you can estimate the value or should i write it that would jog your memory right this is how we all learn right so m and c you can estimate if i give you two data points so that is the simplest case now we will make similar assumptions but more complex functions and just as we could estimate m and c from the data we would expect to estimate ws also from the data so that is what the machine learning setup is so let us see"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/19_3.wav", "duration": 122.0, "text": "so the model when we talk about a machine learning model it is our approximation of the relation between x and y and we are free to make any such approximation so i could say that this is what i think is the relation between y and x and which is governed by some parameters w do you know what is this function have you seen this before no not sigmoid which model is this logistic regression ok but i could also have made a different assumption i could have made this assumption what do i get linear regression ok please note that this error on the slide ok and i could make some other assumption i could assume that y is actually a quadratic function of x i am free to make any assumptions the only thing i need to ensure is there is some parameter involved what is wrong with making this assumption if this is valid is this also valid if not why there are no parameters so no not for any x we will get the we will it will depend still depend on the value of x if i plug in different values of x i will still get a different output there is nothing to learn what do i do with all the data that i have there is absolutely nothing i can use it to learn i have just said that y is equal to one over one plus e raised to minus x i can ignore all the data that you had given me whenever you give me a new x i will just plug it into this formula and tell you the answer and that is bound to be wrong because i have not adjusted this formula now once i put in the ws it gives me this degree of freedom where i can now adjust the formula i can learn the ws in such a way that my predicted y\u2019s are very close to the actual y\u2019s so that is why we need always need a parametric form of course there is nonparametric learning also but i am just saying in this supervised setup we are thinking of models whether you have parameters so you have the data you have the model the model always has some parameters"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/19_4.wav", "duration": 53.0, "text": "in all of the above cases w is a parameter right either the small w which is a vector or the capital w which is a matrix right so notice that this is a matrix this is one cross n n cross n and n cross one now how do we learn these parameters that is the question that we need to answer how do we learn these parameters we are convinced about two things that we never know the true function so we come up with an approximate function and we have to insert some parameters in that function so far good now i have to be able to learn these parameters now for learning these parameters we have something known as an learning algorithm so did you see any learning algorithm so far perceptron learning algorithm right so you already saw the perceptron learning algorithm and it was able to learn the weights for a perceptron"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/19_5.wav", "duration": 121.0, "text": "there are various such algorithms today we are going to learn one such algorithm which is gradient descent now any kind of learning what is it driven by learning is driven by errors objective function and so the analogy which i like to give is suppose you are trying to learn trigonometry you have a chapter that is your training data the chapter has a lot of formulae that is your training data now what is your objective there are two objectives actually i will tell you the easy objective the training time objective is that once you read to the chapter a few times at least whatever formulae are given in the chapter you should be able to produce the correct output for that so if i ask you what is sine square theta plus cos square theta you should be able to answers them and you should be able to give me the correct answer so in other words you are trying to minimize the error on the training data whatever training data you have which is the chapter content you want to make zero errors in anything which is given in the chapter that is your training error of course there is also something as known as a test error because after you have learned the chapter i will give you an independent set of exercises which might contain questions which are not seen in the textbook earlier so you would have seen sin square theta plus cos square theta but now i could ask you some other formula which you should be able to give me answers if you have learned properly right so now right now we are just talking about the training error that means getting all the formula in the chapter correctly and our chapter is actually the training data which is given to you this is what we are reading so this always going to be driven by an objective function and our goal is just as we wanted to minimize the errors that we make on the formula given in the chapter we want to minimize the errors on the training data is this set up absolutely clear to everyone anyone who does not understand this has any doubts so this is something this is the same framework that we will use again in lecture eighteen nineteen twenty and so on to explain some more complex models so you have to absolutely make sure that you understand this it is not very difficult but just make sure you understand this fine so let us concrete at this a bit more"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/19_6.wav", "duration": 164.0, "text": "and we will consider our movie example and try to fit that into this framework so what is our training data there they are given movie comma like dislike and when i say movie i am just using a shortcut it is actually all the details of the movie genre actor director critics rating and so on that is our input and our output is the like dislike value what is a model that i chose what is a model that i chose i do not know what is my true relation between when i like a movie or not but i made this approximation that this is how y depends on x and i made sure i introduced some parameters there i could have chosen some other functions also but i chose this now the parameter is w this should be bold w the learning algorithm that we are going to use is gradient descent which we will be seeing soon and what is an objective function here can you tell me a formula so we have been talking about it in terms of english that i should be able to get predictions which are as close to the true prediction can you put it into a formula y i minus y i hat where hat is the prediction this is the prediction so that is y i minus y i hat that should be minimized is that fine whole square of that so why do you square it so that is correct so for all the training points n training points i want to minimize the square difference between y i the true prediction and the prediction sorry the true value and the predicted value is that fine and why do i use squares differentiable is one the other thing the positive errors and the negative errors should not cancel so it would be happen that on some movies i make a positive error of five right that means the actual label should have been five and i gave one on some movies i make a negative error of five and these would cancel each other and i will get the false impression that i am making zero errors but once i square the values the negative values also become positive so this cannot happen right so that is why we always use the squared error function and also this is differentiable which is more important now the learning algorithm should try to minimize this particular quantity ok so this is a typical machine learning setup almost any supervised learning problem that you see you could cast it in this framework change the y hat function appropriately change the parameters appropriately maybe use a different learning algorithm depending on the problem that you are trying to tackle and you should be able to fit it into the same thing is that fine ok at least for this course everything that we do we will largely be able to fit it into this framework"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/2_0.wav", "duration": 24.0, "text": "we will start talking about artificial intelligence and this is titled as from the spring to the winter of ai so i am going to talk about when was this boom in ai started or when is that people started thinking and talking about ai seriously and what eventually happened to the initial boom and so"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/2_1.wav", "duration": 87.0, "text": "so let us start with one thousand, nine hundred and forty-three whereas i saying that there was a lot of interest in understanding how does a human brain work and then come up with a computational or a mathematical model of that so mcculloch and pitts one of them was a neuroscientist and the other one was a logician no computer scientists or anything at that point of time and they came up with this extremely simplified model that just as a brain takes a input from lot of factors so now suppose you want to decide whether you want to go out for a movie or not so you would probably think about do you really have any exams coming up that could be our factor x1 you could think about is a weather good to go out is it raining would it be difficult to go out at this point would there be a lot of traffic is it a very popular movie and hence tickets may not be available and so on so being kind of presses all this information you might also look at things like the reviews of the movie or the imdb rating of the movie and so on and based on all these complex inputs it applies some function and then takes a decision yes or no that i want to probably go for a movie so this is an overly simplified model of how the brain works is and what this model says is that you take inputs from various sources and based on that you come up with the binary decision right so this is what they proposed in one thousand, nine hundred and forty-three so now we have come to an artificial neuron so this is not a biological neuron this is how you would implement it as a machine right so that was in one thousand, nine hundred and forty-three"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/2_2.wav", "duration": 95.0, "text": "then along and then this kind of led to a lot of boom in our interest in artificial intelligence and so on and i guess around one thousand, nine hundred and fifty-six in a conference the term artificial intelligence was a formally coined and within a one or two years from there frank rosenberg came up with this perceptron model of doing computations or what perceptron model of what an artificial neuron could be and we will talk about this in detail later on the course and not tell you what these things are as of now just think of the a new model was proposed and this is what he had to say about this model right so he said that the perceptron may eventually be able to learn make decisions and translate languages do you find anything odd about this statement yeah so learn and make decisions make sense but why translate languages why is so specific why such a specific interest in languages so that you have to connect back to history so this is also the period of the cold war and there was always always a lot of interest there was lot of research and translation was actually fuelled by the world war and evens that happened after that where these countries which were at loggerheads with each other they wanted to understand what the other country is doing but they did not speak each other\u2019s language that is why there was a lot of interest from espionage point of view or from spying and so on to be able to translate languages and hence that specific require and lot of this research would have been funded from agencies which are interested in these things right and the defence or war or something"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/2_3.wav", "duration": 109.0, "text": "so and this work was largely done for the navy and this is an this is an extract from the article written in new york times way back in one thousand, nine hundred and fifty-seven or fifty-eight where it was mentioned that the embryo often this perceptron is an embryo of an electronic computer that the navy expects will be able to walk talk see write reproduce itself and be conscious of it is existence so i am not quoting something from two thousand and seventeen or eighteen this is way back in one thousand, nine hundred and fifty-seven fifty-eight why i am that is why i like the history part of it so recently there is a lot of boom or a lot of hype around ai that ai will take over a lot of things will take our jobs it might eventually we might be colonized by ai agents and so on so i just want to emphasize that i do not know whether that will happen or not but this is not something new we have been talking about the promise of ai as far back since one thousand, nine hundred and fifty-seven one thousand, nine hundred and fifty-eight right this not something new that people are talking about now it is always been there and to what extent this promise will be fulfilled is yet to be seen and of course as compared to one hundred and ninety-five thousand, seven hundred and fifty-eight we have made a lot of progress in other fields which have enabled ai to be much more successful than it was earlier for example we have much better compute power now we have lots of data now and all thanks to the internet and other things that you can actually crawl tons and tons of data and then try to learn something from a data or try to make the machine learn something from it so we have made a lot of progress in other aspects where which ai is now at a position where it can really make a difference but just wanted to say that these are not things which i have not been said in the past it has always been the it has always been considered to be very promising and perhaps a bit hyped also so that is about one hundred and ninety-five thousand, seven hundred and fifty-eight"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/2_4.wav", "duration": 61.0, "text": "then now what we talk about what is all the for the past eight to ten years at least when we talk about ai talking about deep learning and that is what this course is about largely about deep learning i am not saying that other and what deep learning is largely about if i want to tell you in a very layman nutshell term is it is about a large number of artificial neurons connected to each other in layers and functioning towards achieving certain goal so this is like a schematic of what a deep neural network or a feed forward neural network would look like now this is again not something new which is up in the last eight to ten years although people have started discussing it a lot in the last eight to ten years look at it way back in one hundred and ninety-six thousand, five hundred and sixty-eight opposed something which looked very much like a modern deep neural network or a modern feed forward neural network and in many circles he is considered to be one of the founding fathers of modern deep learning"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/2_5.wav", "duration": 4.0, "text": "so that is about that"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/2_6.wav", "duration": 16.0, "text": "right from one thousand, nine hundred and forty-three to one thousand, nine hundred and sixty-eight it was mainly about the springtime for ai and what i mean by that that everyone was showing interest in that the government was funding a lot of research in ai and people really thought that ai could deliver a lot of things on a lot of fronts"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/2_7.wav", "duration": 52.0, "text": "for various applications health care defence and so on and then around one thousand, nine hundred and sixty-nine an interesting paper came out by these two gentlemen minsky and papert which essentially outlined some limitations of the perceptron model and we will talk about these limitations later on in the course in the second or third lecture but for now i will not get into a details of that but what it is said that it is possible that a perceptron cannot handle some very simple functions also so you are trying to make the perceptron learn some very complex functions because the way we decide how to watch a movie is a very complex function of the inputs that we considered but even a simple function like xor or is something which a perceptron cannot be used to model that is what this paper essentially showed and this led to severe criticism for ai and then people started losing interest in ai and lot of government funding actually subsided after one thousand, nine hundred and sixty-nine"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/2_8.wav", "duration": 24.0, "text": "all the way to one thousand, nine hundred and eighty-six actually this was the ai winter of connectionism so there was very little interest in connectionist ai so there are two types of ai one is symbolic ai and the other is connectionist ai so whatever we are going to study in this course about neural networks and all that probably falls in connectionist ai paradigm and there was no interest in this and people i mean hard to get funding and so on for these seventeen to eighteen years"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/2_9.wav", "duration": 30.0, "text": "and that was largely triggered by this study that was done by minsky and papert and interestingly they were also often misquoted and what they had actually said in that papers so they had said a single perceptron cannot do it they in fact said that a multi layer network of perceptrons can do it but no one focused on the second part that a multilayer network of perceptron people started pushing the idea that a perceptron cannot do it and hence we should not be investigating it and so on right so that is what happened for a long time and this known as the winter the first winter"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/2_10.wav", "duration": 86.0, "text": "then around one thousand, nine hundred and eighty-six actually came this algorithm which is known as back propagation again this is an algorithm which we are going to cover in a lot of detail in the course in the 4th or 5th lecture and this algorithm actually enables to train a deep neural network right so deep network of neurons is something that you can train using this algorithm now this algorithm was actually popularized by at rumelhart and others in one thousand, nine hundred and eighty-six but it is not completely discovered by them this was also around in various other fields so it was there in i think in systems analysis or something like that it was being used for other purposes in a different context and so on and rumelhart other and others in one thousand, nine hundred and eighty-six were the first to kind of popularize it in the context of deep neural networks and this was a very important discovery because even today all the neural network so most of them are trained using back propagation right and of course there have been several other advances but the core remains the same that you use back propagation to train a deep neural network right so something this was discovered almost thirty years back is still primarily used for training deep neural networks that is why this was a very important paper or breakthrough at that time"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/2_11.wav", "duration": 45.0, "text": "and around the same time so again interestingly so back propagation is used in conjunction with something known as gradient descent which was again discovered way back in one thousand, eight hundred and forty-seven by cauchy and he was interested in using this to compute the orbit of heavenly bodies that is something that people care about at that time today of course we use it for various other purposes one of them being discovering cats and videos or even for medical imaging or for describing whether certain have of cancer is being depicted in a xray or things like that there is a lot of other purposes for which deep neural networks enhance and hence back propagation gradient descent and other things are being used for it but again these are not very modern discoveries these are dated way back thirty years and even gradient descent is almost one hundred and fifty years and so on so that is what i wanted to emphasize"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/2_12.wav", "duration": 149.74, "text": "and around the same time in one thousand, nine hundred and ninety or one thousand, nine hundred and eighty-nine there is this another interesting theorem which was proved which is known as the universal approximation theorem and this is again something that we will cover in the course in the third lecture or something like where we will talk about the power of a deep neural network so again the importance of this or why this theorem was important will become clear later and when we cover it in detail but for now it is important to understand that what this theorem said is that if you have a deep neural network you could basically model all types of functions continuous functions to any desired precision so what it means in very layman terms is that if the way you make decisions using a bunch of inputs is a very very complex function of the input then you can have a neural network which will be able to learn this function right in many laymen terms that is what it means and if i have to hype it up a bit or i have to say it in a very enthused and excited manner i would say that basically it says that deed neural networks can be used for solving all kinds of machine learning problems and that is roughly what it says but with a pinch of salt and a lot of caveats but that is what it means at least in the context of this course so this is all around one thousand, nine hundred and eighty-nine and despite this happening some important discoveries towards the late end of 80\u2019s which was back propagation universal approximation theorem people were still not being able to use deep neural networks for really solving large practical problems and a few challenges there was of course the compute power at that time was not at a level where it could support deep neural networks we do not have enough data for training deep neural networks and also in terms of techniques while back propagation is a sound technique it is to fail when you have really deep neural network so when people try it training a very deep neural network they found that the training does not really converge the system does not really learn anything and so on and there were certain issues with using back propagation off the shelf at that time because of which it was not very successful so again despite these slight boom around eighty-six to ninety where some important discoveries were made and even follow up in ninety-two ninety-three and so on there is still not a real big hype around deep neural networks or artificial neural networks and at time again a slump a slow winter right up till two thousand and six"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/20_0.wav", "duration": 16.0, "text": "in this module we will try to learn these parameters and initially we will try to learn them by guesswork and i will show that that is actually infeasible that is why we need a more principled approach"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/20_1.wav", "duration": 21.0, "text": "so we will keep the supervised machine learning setup in mind and now we will focus on this model and discuss an algorithm for learning the parameters which are w and b given some data using a giving appropriate function objective function so that is what we are going to focus on"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/20_2.wav", "duration": 78.0, "text": "now sigma here stands for the sigmoid function the logistic function in this case when this sigma is actually the logistic function and now i am going to simplify this further so that it helps us to do a better analysis i am just going to consider the case where i am just in one input and the bias ok and also following the normal terminology in the literature this w naught from now on i am going to call it b because that is the normal convention b stands for bias so i have two parameters w and b which i need to estimate ok and this is my model for the movie example and the other change which i am going to make is instead of deciding whether i like or dislike which is one zero the setup that i am going to work with is that i am giving the critics rating and i want to predict the imdb rating so i am given a real value and i also want to predict a real value for no particular reason this just makes life easier for me for explaining a few things but the same thing or the same algorithm would also hold if you add a binary output right and you will see that later on in the course so here is a setup clear we just have two parameters w and b and we are going to assume that y belongs to real numbers it is a imdb rating and x also belongs to real number it is a critics rating"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/20_3.wav", "duration": 32.0, "text": "now let us see what we are given as training is a set of points we are given some n training pairs and now we understand what this means that means for a lot of movie i am giving the critics rating and i am also given the true imdb rating for them of course in the two variable case this does not make much sense but just bear with me and now the training objective is such that whatever my function predicts which is a function of w x and b that should be very close to the true output that i know this is the function that i want to optimize now let me ask you this"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/20_4.wav", "duration": 92.0, "text": "i am trying to tell you that i am going to give you an algorithm for training this network suppose i have trained this with two data points five comma two and twenty-five comma nine right at the end of training i will give you some values of w and b let us call them w star and b star these are the final values of w which i have given w and b what do you expect from these values what do you expect at the end of training if i say now the network has learned what do you expect you are still going to the test case i am just talking about the training still we expect such that what happens if i plug in at the end of training if i plug in the value five here what should happen nine so this is what you expect at the end of training if you plug in the value five it should be very close to two the output and if you plug in the value twenty-five it should be very close to nine this is exactly what you expect and this is what training means ok fine in other words we hope to find a sigmoid function such that these two points lie on that function can you imagine a geometric picture for this what would happen actually how many if we can imagine it ok how many of you get it now this is what will happen right so you will get a sigmoid function such that these two points lie on that fair ok and that exactly means that when i plug in this value i will get this value and when i plug in this value i will get this value right so that is what it means"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/20_5.wav", "duration": 1.0, "text": "so let us see this in more detail"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/20_6.wav", "duration": 77.0, "text": "and now what we will do is our quest is for this w star and b star i will try to find this manually i will do some random guesswork and try to find this because i do not have any clear principle algorithm for finding it as of now so i will just use some guesswork so i will give my initial guesswork as w equal to five b equal to zero for no reason i just picked up some values right and this is what the function that i got what does this mean this function an error so the sigmoid formula should be here we should have this sigmoid formula here so is this a good are you happy with the solution if i give you are you happy with this solution is this good bad ugly has to be something bad we will not call it ugly ok so why is it bad it is not passing through those points i will ask you a question how bad is it can you assign a number to it we are always good at qualitative stuff but quantitatively can you tell me a number how bad is this can you tell me a way of finding how bad this is i already told you in detail how to find that how bad it is the loss function right"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/20_7.wav", "duration": 5.0, "text": "we have the loss function let us see that again and see if we can find out how bad this is"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/20_8.wav", "duration": 42.0, "text": "so this is what my loss function is ok and i have two data points i will just expand it out fine now i will plug in the values i know this is nine and i will compute the value of f twenty-five i will plug in this and i will plug in this ok and this is what i get so this is how bad it is what did we actually expect it to be in the good case zero so this is not zero this is seventy-three so now we have a quantitative handle on how bad this is ok so let us keep this in mind and let us try to continue guessing so we want the loss function to be asked close to zero as possible we are not there yet"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/20_9.wav", "duration": 88.0, "text": "so then i make a different guess i say let me try minus ten zero what happened now is it now good bad ugly now let us call it ugly right so it is worse and how do i know it is worse because i plugged it in to the loss function and i got a value which is greater than the value at which i was so i clearly know this is bad so now this is how my mind is working right oh i as far as w was positive things looked at least i was close to zero in the first decimal now when i made it negative that does not look good so let me just keep it positive and keep increasing it right so i saw ninety-four and i also tweaked the b of it i have done complete random guesswork right now what happened good bad ugly better ok now what will you do what would your next case would be make w even more positive perhaps that would help and be even more negative and so on i can continue in this manner and actually get close very close to the solution so i can do this guesswork and find these values but it is still an educated guess right i am not guessing in the dark this is what is helping me drive towards those guesses and i am just looking at these values and making an educated guess right and that is the educated guess which i took that probably making w even more positive would help but this is still brute force in a sense right this is not something that you would want to do when you have one hundred one thousand parameters and so on right and one million data points and so on"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/20_10.wav", "duration": 11.0, "text": "so let us look at something which is better than our guesswork algorithm ah so we are not there yet actually on the next slide i am still going to talk about the guesswork algorithm"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/20_11.wav", "duration": 151.0, "text": "and eventually we will get to something which is better than the guesswork that ok so since we have only two points and two parameters what i can do is i can take all possible values of w and b right that is what i was trying i was picking up some values of w and b why just pick some values of w and b i will pick all possible values of w comma b right and i will fix the range i cannot fix pick it from minus infinity to infinity but i will pick a range i will say from minus six to six let me try all values of w comma b compute the loss and plot it right let me tell something about this error function because this is going to stay with us for quite some time so what you see here is something like a flying carpet this is colour coded red is bad red are the places where the error is high blue is good blue are the places where the error is low darker the shade of blue lower the error darker the shade of red higher the error so in particular if i look at this point what has happened is i have taken the corresponding value of w comma b right which is say minus four comma minus one right something like that i have plugged that value into my loss function and i got this as the loss function this has the loss value and that is what i have plotted for all values between minus six to plus six and minus six to plus six for w and b so everyone understands how i have constructed this error surface now this of course becomes and now what i can do is once i see this error surface i know how good this is the point where i need to be this is the darkest ah shade and this is where the error is the lowest so i can just pick a w comma b value which lies there this is fine for this toy example where you just have two parameters but this becomes untractable once you have more data points and many more parameters and that is what happens in most real world applications right so this is not a feasible way of going about things right and here again note that i have only taken the range from minus six to six i do not even know what will happen if i have to look at all values of w comma b right maybe there was something outside here right which was even more lower error or something right so i do not really know that so i cannot really use this so i need something better than this plotting the error everywhere and finding it order that is pure brute force or surrogate to this was the guesswork algorithm but which is again something we cannot do for if you have large number of parameters so everyone gets this that this is a way of finding the solution but this is not feasible right that is the only point i am trying to make"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/20_12.wav", "duration": 9.0, "text": "and we look at the geometric interpretation of what was actually happening in the case of the guesswork algorithm with respect to the error surface"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/20_13.wav", "duration": 49.504, "text": "so i had chosen some values of w comma b the first value that i chose actually gave me an error of if you remember it was some seventy-three or something like that right so that is the point then i decided to take a very random guess and my error actually increased so you see that i am actually climbing up on this error surface i have gone from a slightly darker shade of blue to a lighter shade of blue right and then i corrected myself and then kept moving in a direction where i was going towards the darker and darker shades of blue so what i was actually doing is i was trying to traverse the error surface and land up in the good regions which were the dark blue regions now what i want to do is i want an algorithm which will allow me to do this in a principled manner which is neither brute force nor guesswork so that is what we learn in that module"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/21_0.wav", "duration": 12.0, "text": "in this module we will talk about gradient descent"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/21_1.wav", "duration": 8.0, "text": "so what we want to do is find a more efficient and principled way of navigating the error surface"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/21_2.wav", "duration": 5.0, "text": "and the goal is to find a better way of doing this"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/21_3.wav", "duration": 33.0, "text": "so let us start by setting up things we will define some notations and some parameters and so on and from there on we will try to come to the algorithm ok so my parameters in this case were w comma b what i am going to do is i am going to put them into an array or a vector right and call that vector as theta so theta is the vector of parameters and theta belongs to r r what r2 right there are two parameters here so it is a two dimensional vector"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/21_4.wav", "duration": 680.0, "text": "now what i want is again what i will do is i do not know what the value of w comma b is so i started with a random guess so that is always going to be my starting point i will always start with a random guess and from there on move on to good values now once i have started with a random guess i want you to tell me some changes that i can make to w and b so that i land up in better situations right that means i land up in situations where the error is less is that fine so that change in w and b i am going to call it as delta w and delta b and that again is a vector which is storing these two values so this is the picture right i want to take theta and i want to add a small change to it so this is my theta this vector is actually theta right this is the theta vector i want to add a small change to it which is again a vector this is delta w comma delta b such that i will get a new value for theta new so theta new would be what actually theta new is equal to w new comma b new is that fine that is what theta new means"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/21_5.wav", "duration": 406.0, "text": "if this condition holds everyone agrees with that right so i have found a good direction to move in if this condition holds now this condition actually implies that this condition should hold right this is l theta plus eta u right so if i just do minus here i get this right so this quantity which should be less than equal to zero implies that this quantity should be less than equal to zero and remember eta is a positive constant ok why cannot it be negative why because you wanted to take a small step in that direction if we make it negative we will do what we will reverse the direction we do not want that as of now right so eta is that for a positive quantity so that means this quantity should be less than zero is it fine with everyone"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/21_6.wav", "duration": 48.0, "text": "so now we have a more principled way of moving in the w b plane what do i mean by that remember this was our w b plane this was our error this is something what our error surface looked like it was this flying carpet i was randomly moving on the w b plane earlier right and trying to guess what the errors or trying to compute the error and then settle for a particular value now i have a more principled way of moving in the w b plane i know what is the next step based on the current step i just need to move in the direction opposite to the gradient so let us try to so this is what it tells me for one step but i need to keep doing this till what is that golden word student refer time one thousand, nine hundred and fifty-eight convergence right i have to keep doing this till convergence ok"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/21_7.wav", "duration": 58.0, "text": "so let us create an algorithm out of this rule i will start a time step zero i will do this for some max iterations instead of saying till convergence i will do it for some iterations at every iteration i will this is how i will update my weights i will take the current weights subtract the gradient from that and get the new weights i mean not subtract the gradient subtract this quantity and get the new weights so now is everything clear is the gradient descent algorithm done can you do it for the toy network which i had is there something still missing student refer time two thousand and thirty-eight eta is fine we will take a small value one or something actually not told you what these are right i means to write it you know these are derivatives but what is this actually ok so let us see that now so that is what we are going to see next"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/21_8.wav", "duration": 50.0, "text": "so now we want to find out we are in the car quest is for this delta sorry the partial derivative with respect to w and partial derivative with respect to b that is the thing which we had plugged in the formula but we do not know what that is right so we need to find that out so now for simplicity let us assume there is only one point of it which is x comma y so earlier we had this x1 y1 and x2 y2 now i am just assuming there is only one point which is x comma y"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/21_9.wav", "duration": 127.0, "text": "so now what is a loss function earlier i had this summation over i equal to one to two but i have just one x comma y so i will just use that this is what my loss function and what are the quantities that i am interested in finding one is this the partial derivative of this loss function with respect to w"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/21_10.wav", "duration": 26.0, "text": "so there is only one point then this is what the partial derivative with respect to w is going to be of the loss function right if there were two points what would happen if there were two points my loss function was this is a sum of two elements and i am taking some derivative of a sum i will get a sum of derivatives right"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/21_11.wav", "duration": 386.91, "text": "so how many of you will not cringe if i say this is the answer anyone who has a problem with this you get this how many if you do not get this how many of you get this good fine now can you do a similar thing for b can you tell me the answer without actually deriving it student refer time two thousand, four hundred and forty-one i can perfectly understand what you are saying student refer time two thousand, four hundred and forty-eight x would not be there right because this last x that you see here came because w into x was there but b we are not multiplying x so what we will get is this you can go home and check"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/22_0.wav", "duration": 3.0, "text": "before we move on to the next modulate some small corrections from yesterday\u2019s class"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/22_1.wav", "duration": 30.0, "text": "so one was this partial derivative it should have been dou w square so we already taken one derivative with respect to w and now you are taking another derivative it is the gradient of the gradient and similarly should this should have been dou b square and this should have been dou w dou b"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/22_2.wav", "duration": 194.0, "text": "the other small thing which i wanted to say was so when i was executing this algorithm right so i forgot to mention that just notice what is happening is the black dot that you see the black dots that you see right and which are very close to each other actually because you are just making small movements those are the changes in the w comma b values and the red dots are the corresponding loss to that w comma b values right just to clarify so that is why you see a movement on the w b plane which is this movement and as you keep changing that your loss function changes and it becomes better and better right that means it goes closer to zero"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/22_3.wav", "duration": 29.0, "text": "so this was one thousand, nine hundred and eighty-nine ok what is the significance of this why do we care about such arbitrary functions and what does this theorem telling us actually it is of course telling us something about the representation power of a multilayer network of sigmoid neurons but why is this important so we will see that"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/22_4.wav", "duration": 94.0, "text": "so this the remainder of the lecture i have borrowed ideas from this url you should actually read this it is a very interesting book it is available online for free very illustrative so please take a look at it ok"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/22_5.wav", "duration": 31.0, "text": "now we make an observation that such an arbitrary function can actually be approximated by a lot of something that we call as tower functions these are all single i mean pulse functions which you have many of these and you could have an approximation right and you can see that this approximation is bad at many places but still it is an approximation it largely gives you the same shape as the original curve what would happen if i increase the number of such tower functions"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/22_6.wav", "duration": 34.0, "text": "student refer time six hundred and twenty-nine the approximation would improve right if i keep increasing it the approximation would go more and more better right so now just try to keep things in mind whether i write in the theorem right you can make it arbitrarily close to the actual value that means you can keep doing something so that your approximation becomes better and better and you already see something of that sort this is still in the sense of a figure we need to relate this back to a neural network but you see that as i am increasing these tower functions i become approx arbitrarily close to the actual function"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/22_7.wav", "duration": 30.0, "text": "now this is what is actually happening right i have multiple such tower functions i am adding them up all of them are shifted in time so this tower function is actually this one this tower function is actually this one and so on right and i have not drawn the remaining ones i am taking all of these tower functions adding them up and getting my original function right and the more such tower functions have the better is the approximation"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/22_8.wav", "duration": 97.0, "text": "now you make a few observations right all these tower functions are actually the same what is the only difference they just shifted and their magnitude changes right but they are all tower function right so let us think of this that if i know how to make a rectangle then i can make any rectangle right i just need to change the size of the rectangle and maybe shift it or oriented differently or something right so they are all similar i just need to learn how to draw a tower right that is what my quest is now if i take the original input salinity pass it through multiple such blocks each block is capable of making a tower function and each of these would give me one of these towers that i am looking for and i am looking for so many of these right if i have as many such tower makers then i could get these towers i could just add them up and then get the original function back and the more these i have the better is my approximation right so i am taking as input the salinity and trying to predict the oil does this make sense still we have not figured out a neural network way of doing this we are still building intuitions of how to do this now our job now is to figure out what goes in this black box that is the tower maker and how does it connect to neural networks if you figure that out then our story is complete then we know that a neural network can actually do this and that precisely proves the statement which i had made that it can it can represent arbitrary functions so we will figure this out over the next few slides"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/22_9.wav", "duration": 173.0, "text": "now if you take the logistic function and set w to w to a very high value what will we get just try to think about it the answer is already written but i want you to imagine it w covers what student refer time nine hundred and thirty-one the slope right as i make w very high what will happen is i will get the so let us try changing the value of w ok i just increase the value of w and see what happens to the sigmoid curve"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/22_10.wav", "duration": 62.0, "text": "now can we come up with a neural network to represent this operation i want a sigmoid neuron i was working with a sigmoid neuron with some arbitrary weights right so that i recover that step function can you imagine now given x i want this tower function and that is exactly what one of the blocks was right so what i am asking you is oh god so i am asking you to give me a neural network for this can you think of it can you try imagining it two neurons in the hidden layer how many of you agree with that ok can you can you take some more time to imagine what it would be and i have already ok right"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/22_11.wav", "duration": 219.0, "text": "so this w one b one if i set it appropriately i will get this step function if this w two b two i set it appropriately i will get this step function now i needed to subtract one from the other right so i will do plus one minus one this is just a simple addition and i will get this is that fine everyone agrees with this this is just a adder right this is just an aggregator everyone gets this so now i have given you the tower maker if you put enough of these tower makers and learn the w\u2019s appropriately what will you get that function that we were needed so you can approximate it arbitrarily to any precision that you want as long as you keep increasing the number of these units right so these units actually give you one tower more of these units that if you have actually this much this is the input ring the more such tower makers that you have the more is the bars that you will get and then you can approximate everyone gets the intuition behind this fine ok this all is always good in one dimension"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/22_12.wav", "duration": 2.0, "text": "so now i want to show that even in 2dimensions i could come up with arbitrary i could come up with a neural network which could actually approximate this and again what will i look for a tower maker right i just want something which can make towers and approximate it"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/22_13.wav", "duration": 41.0, "text": "so this is what a 2dimensional sigmoid looks like slightly incorrect because i have what i have done is i have actually said w two to zero so if you actually i would want you to do this go back and plot this for w one equal to three and w two equal to three just go back and plot this and see what you get you will not get such a smooth such a nice looking s but you will still get something which looks like looks like a snakes hood right so in still get that s shaped function it just that it would be bent at some points and it be thinner at some points and broader at the other points so just go back and see and then you will realize what is happening right"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/22_14.wav", "duration": 103.0, "text": "so here again what we want to figure out is from the single sigmoid i was able to take you to a tower function right from a 2dimensional sigmoid what does a tower mean here and how do i take you to the tower so that is what i want to do so i have said w two equal to zero and i will it will become obvious why i have done that so just understand what the figure is doing right so this if you just look at this is like the cross cut right so you are looking at the front view of this figure and that is just the sigmoid function without the w two right and now since i have said w two equal to zero no matter what i set x two to the same function will get repeated throughout that axis do you get that so that is why this entire function is just getting repeated throughout this axis and then you just get a similar s shape function everyone gets that how many of you do not get that how many of you get that so this if you look at the front view this is the sigmoid of one variable but since i have said w two to zero no matter what i change x two to the function is going to remain the same so it will just get copied throughout the x two axis is that fine with you now what will happen if i increase w two sorry w one same thing right it will just keep shifting till it becomes almost like a 2d step function ok now what will happen if i increase b shift i can do the same thing here also same logic applies here also ok"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/22_15.wav", "duration": 46.0, "text": "now what is the next step that i am going to do take two of these which are shifted by some point and then subtract what will i get everyone had this figure in mind so just see right so this portion both are zero so zero minus zero would be zero this portion this is one but this is zero so that would be one minus zero and again in this portion both of them are one so one minus one would be zero so you will get this kind of function would you like to live in such a tower i am very serious yes or no no why it is open from two sides right you cannot live in this tower so you want something which is a closed tower right so how will you do that give me an intuition we will do the reverse thing what will be set to zero w one ok"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/22_16.wav", "duration": 26.0, "text": "and this is how it would look the orientation would change and again so notice that this is your sigmoid function and since i have set x one to zero no matter what i change along the x one axis the same function gets copied and you get a nice looking a sigmoid function now again i will do the same thing i will increase the w i will get a close to a step function i will increase the b i will move along this axis"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/22_17.wav", "duration": 250.0, "text": "next step take two of these subtract get what another tower function this is also not a tower that you like to stay in so what do i do now add them sure add this tower to the other tower"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/22_18.wav", "duration": 35.0, "text": "i lead multiple such towers and i can approximate this i could put a tower here here here and so on i could have these multiple towers and here of course all my towers would be of zero height right in this region right so now i can cover the entire 2d space with a lot of tower functions and approximate this exactly that is a very weird statement approximate this exactly i mean approximate this to arbitrary precision everyone gets this do you see why we constructed these tower functions and now we can put them inside this cone and approximate it"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/22_19.wav", "duration": 323.0, "text": "now all this is fine i was making some towers there so can you now give me a complete neural network which does this i want you to imagine that remember you are taking what i am asking you to do is this x one x two give me this such that i get this two dimensional tower i do not know how to draw it something like this maybe whatever so i want this 2dimensional tower what is this network of perceptrons going to look like just go back to all the operations that we did and try to imagine in your mind no we will not use perceptron because we can always use a sigmoid neuron instead of a perceptron with the high w i do not expect you to answer this i just want you to imagine right we just try with a there is something known as a pen there is something on a paper ok so here is the solution"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/22_20.wav", "duration": 24.0, "text": "and that was for the tower function now i could have actually directly done this right so i wanted to approximate these functions so i could have placed a lot of these kinds of things here and approximated it right so that instead of that very high slope sigmoid function i could just use a normal sigmoid function also ok and again there is a error here but i hope you get the picture it is just that you feed both the inputs to them"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/22_21.wav", "duration": 51.0, "text": "so for one dimensional input we needed two neurons to construct a tower for two dimensional input how many neurons did we need i am just counting these because these are simple aggregators right and this is one constant at the end so how many did we need actually o of two n i mean o of i mean so for n how many would we need let us try to work that out ok so i will ask you that in the quiz how many do we need for n dimensions"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/22_22.wav", "duration": 196.669, "text": "and this is the data which i had given you which was there were some points some values of x and y sorry this should be x one and x two it is where this is pressure and salinity or salinity tendency and this is the output which is oil now there was this is what the function actually looks like now what would have happened if i had used a single sigmoid neuron to try to approximate this function try to represent this function and sigmoid neuron in two dimensions right so the two dimensional sigma what would have happened can you give me one solution for this remember earlier i had said that perceptron cannot handle data which is not linearly separable but then i anyways used it for data which was not linearly separable and we got some line such that we got some errors the red points and the blue points are not clearly separated so i am asking you for a similar thing here i force you to use a sigmoid neuron what would you give me"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/23_0.wav", "duration": 173.0, "text": "so welcome to lecture four of cs7015 the course on deep learning today we will talk about feed forward neural networks and back propagation so quick recap of the story so far it so we started with mp neurons we saw there were some problems with the mp neurons they could handle only boolean inputs and boolean outputs and threshold needed to be hard coded so from there we moved on to perceptrons which allowed for real inputs real outputs and sorry real inputs and binary outputs and we also learned an algorithm for learning these weights and parameters right so we need there was no need to hand code these parameters anymore but then we found that for a single perceptron there is a limitation it cannot it can only deal with functions which are linearly separable so then we went on to a multi layer network of perceptrons and we proved by illustration that it can handle any arbitrary boolean function whether linearly separable or not the catch is that you will need a large number of neurons in the hidden layer right then we also observed that perceptrons have this harsh thresholding logic so which makes the decisions very unnatural it is forty-nine it is negative fifty-one is positive so you wanted something more smooth so the smoothest approximation to this step function which is the perceptron function was a sigmoid function sigmoid is a family of functions and we saw one such function which was logistic function and then we saw that it is very smooth now it is continuous and differentiable now for the sigmoid neuron on a single sigmoid neuron we saw a learning algorithm which was gradient descent and we proved principally that it will always go in the direction where the loss decreases right so that is what is the basis for gradient descent and then we graduated from a single neuron to a network of neurons and made a case that such a network of neurons with enough neurons in the hidden layer can approximate any arbitrary function right ok so i have told you that it can approximate any arbitrary function what does that mean and what is the thing in the network that does all this all the tower functions and the tower functions depend on weights and biases so there in that illustrative proof again we were adjusting the weights and biases by hand right we knew that we wanted these very tiny tower functions and we were doing it now from there where should we go student refer time two hundred and thirty-nine we need an algorithm to learn these weights and biases right so that is what back propagation is so today i am going to formalize these feed forward neural networks we just did it by illustration the other day i will introduce you to the terminology and see what the input outputs are and so on and then we will look at an algorithm for learning the weights in this feed forward neural network"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/23_1.wav", "duration": 200.0, "text": "let us begin so this a lot of this material is inspired by the video lectures by hugo larochelle on back propagation he has a course on neural networks it is available on youtube you can check it ok so let us first begin by introducing feed forward neural network right"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/23_2.wav", "duration": 219.0, "text": "now what about the output layer n cross k and the biases k k dimensional ok so this is what the network looks like but now i have to give you some function so i have just i have shown you a diagram but what does it mean mathematically because remember that we are always interested in writing something of the form y is equal to function of x right and that is not well defined yet"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/23_3.wav", "duration": 402.0, "text": "it could be logistic tanh linear anything right so we will see some of these functions later on ok now the activation at layer i sorry they are supposed to be activation at the output layer the activation at the output layer is given by the final function which is f of x is equal to o of a of so let us see so this is a three in our case l was equal to three because we had l minus one hidden layers and the lth layer was the output layer right so this is a l so this is what i have computed here that light green part of the figure that you see right now based on that i want to produce an output so that is someone had asked me a question that why do we always choose sigmoid because sigmoid will clamp the output to zero to one what if i want to predict the amount of oil which will not be between zero to one right that is why for the output we will use a special function that will call the output function and later on i will show you that it depends on the task at hand so it is going to change with the task that we are going to do right so we are just going to say that the final output which is h of l is equal to some function of the pre activation at that layer is this terminology clear to everyone how is each function operating is that clear to everyone"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/23_4.wav", "duration": 90.669, "text": "and the algorithm that we are going to see today for learning these parameters is called gradient descent but we will use it with back propagation where back propagation will help us to compute gradients it is ok it does not it does not make sense at this point that is what the lecture is supposed to be about right so and what is an objective function student refer time one thousand, seven hundred and seven loss function so i could just go with this loss function right ok there is an error here i thought we corrected this there is a summation so actually these are vectors right so this does not make sense so you should have summation j equal to one to k yij minus yij does that make sense so this is the vector y hat ok for the i th example it will be called as y hat high i which will have k elements right so y hat i one y hat i two up to y hat i k right so that is what my predictions are and i will have the corresponding true vector also i am trying to take the difference between them which is going to be an element wise difference everyone understands the error in the slide how many of you do not get it how many of you get it if you do not get it please raise your hands it is a minor thing i can correct it and how does deep neural networks fit into these this paradigm"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/24_0.wav", "duration": 16.0, "text": "now we will move on to the next module where we want to learn the parameters of feed forward neural networks and we first start with some intuition and then mathematical details"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/24_1.wav", "duration": 7.0, "text": "so we have introduced feed forward neural networks and we are now interested in finding an algorithm which can allow us to learn the weights of this network"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/24_2.wav", "duration": 128.0, "text": "so recall our gradient descent algorithm this is how it looked ok i had initialized those two parameters w naught b naught and then i was iteratively doing this in a loop at every step i was moving in a direction opposite to the gradient at that step now can i write this a bit more compactly we can write using vectors"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/24_3.wav", "duration": 27.0, "text": "so we can still use the same algorithm except that del this grad of hat of so now i could just say that theta two hat i mean initialized all parameters and theta naught right compute the gradient with respect to all of them and then do this update right i could just instead of putting them in matrices i could just think of them as a large vector just had initially i had just had w comma b now this vector is even more large in fact i will show you actually how it is"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/24_4.wav", "duration": 111.0, "text": "so this is the grad with respect to theta looks very nasty now this is how nasty looks right so you have this weight matrix w one you have the derivatives with respect to first element of w one all the way up to the last element last element so with respect to all the n cross n elements of w one what is the next entry going to be w two hundred and eleven to student refer time three hundred and thirty-two w2nn next after wl11 ok and then after this ok student refer time three hundred and forty-one what is remaining biases right so you have b11 to b1n this slight error here but intentionally this actual is k because k is not equal to n right the last layer has only k parameters whereas so that it looks ok is this clear so is this are all the partial derivative that we need right you do not need to worry about taking a partial derivative with respect to our matrix it just boils down to taking the partial derivative with respect to all elements of the matrix so earlier you just had two parameters now you have these n cross n plus n cross n upto l right so l into n cross n plus l into n that many number of parameters is what you have you get the calculation right or rather you have l minus one layers each of which has n cross n parameters right and l minus one layers which also have the biases so these are the w\u2019s these are the b\u2019s then the output layer one layer which has n cross k parameters and k cross one bias so these are all the number of parameters that you have and this is exactly what this size of this matrix is right it has all these parameters and you need to compute the partial derivative with respect to each of these parameters"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/24_5.wav", "duration": 56.0, "text": "so this is what grad theta is composed of it is composed of the partial derivatives with respect to all the parameters of your network ok so now if someone gives you each of these quantities same oracle give you each of these quantities then can you apply gradient descent right you can use the exactly the same algorithm that you are using earlier just the sizes of earlier vectors changes how many of you are convinced that now you can use that gradient descent there is not a trick question how many of you convinced how many of you not convinced assuming that someone has given you these quantities right i know that it is hard to compute we will see how to compute that but let us assume someone has given you this then you can use gradient descent that is what the case i made in the previous slide right that you could initialize with all the parameters compute the gradients with respect to all the parameters and just do this update fine so now we need to answer two questions first is this is the key question"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/24_6.wav", "duration": 31.263, "text": "because we are taking derivative of what loss functions so we need to know what the loss functions that is the crucial question right and then we are taking derivatives with respect to all these elements so whatever i was told you that assume that oracle gives you now you have to do the hard work and actually find it out right so if you can answer these two questions then we are done we have an algorithm for learning the parameters of feed forward neural networks we all agree that if you have these two elements then we have done so here i will end this module"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/25_0.wav", "duration": 9.0, "text": "we go on to the next module where we will be talking about output functions and loss functions"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/25_1.wav", "duration": 987.0, "text": "the question that we are going to focus on is how to choose the loss function but i will show you that it is tightly coupled with the choice of the output function also remember that we had said that we have a special o function as the output function i have not told you what that o is and now that is what we are going to define"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/25_2.wav", "duration": 82.0, "text": "so now so this was for whatever we have done so far right till this point this was for regression right now i wanted to enter into classification for which i have built this set up of how to take the difference between two distributions so now let us consider this problem where we have this situation and which is a classification situation that you are given four possible classes out of which one is the correct class and this is the true data given to you this is the true distribution all the probability mass is focused on one of these classes now we want to given an image classify this into one of k classes if you could again use a squared error loss but since we are dealing with probability distributions here we want to use something special so before we get to what the special is going to be what do i first need to tell you in the earlier case my output was not bounded was it also dependent was there any condition on if the imdb rating is something the critics rating should be something else or the rotten tomatoes rating should be something else no now in this case is there a tightly coupled behavior between the outputs why because they should sum to one we are trying to predict a probability distribution so the sum should one right so i need an output function which ensures this you get this setup"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/25_3.wav", "duration": 136.0, "text": "now we should ensure that y hat is also a probability distribution whatever we are predicting is also a distribution so now can i use a sigmoid function yes it will give me values between zero to one and probabilities are between zero to one but the sum would not be y so sigmoid is ruled out"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/25_6.wav", "duration": 1526.467, "text": "so now let us look at the summary so if your outputs are real values what is your output activation going to be linear what is the loss function going to be squared error if your output is a distribution what is the output function going to be softmax what is this loss function squared error cross entropy right now this grid light actually takes care of a wide range of problems that you will see right think of any examples that have been giving you so far movie prediction or sentiment prediction or image classification or anything all of that you can fit into this frame of it and so if you know these two loss functions how to deal with them then you can deal with a large class of problems that you are going to deal and for the rest of this lecture which will happen tomorrow we are going to focus on this at this particular output function and this particular loss function how do we compute i have a loss function what i am going to compute now the gradient with respect to all the parameters so this is what we are going to focus on right so we have seen the loss function in detail we have seen that the loss function is tightly coupled with the output function now we are all set but given this loss function how do we start computing gradients of this loss function"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/26_0.wav", "duration": 70.0, "text": "this lecture is on backpropagation and feed forward neural networks so we introduced a feed forward neural networks we saw the input layer hidden layer and the output layers and we saw that the output layer actually the output function depends on the task at hand and we considered two main tasks one was classification the other was a regression for regression it made sense to use a linear layer at the output because we did not want the outputs to be bounded they could be any range and for the classification problem we realized that we want a special kind of output because we are looking for a probability distribution over the output and for that we use the softmax function and in both cases we used a different kind of a loss for the regression problem the squared error loss made sense because we predict some values and we want to see how far we are from those values but for the other case the classification we realize that it is a distribution so maybe we could use something which allows us to capture the difference between the true distribution and the predicted distribution"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/26_1.wav", "duration": 51.0, "text": "and therefore we had this figure emerging which was depending on the output whether it is real values or probabilities you will have different types of output activation functions and different types of losses and of these combinations today we are going to focus on softmax and cross entropy and our aim is to actually find these gradients remember there are many of those we have seen this large matrix which had many such partial derivatives and we want to find that entire matrix i hopefully do it in a way that it is not a repetitive we could compute a large number of partial derivatives at one go so before we look at the mathematical details we just get an intuition for backpropagation"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/26_2.wav", "duration": 59.0, "text": "and then we will get into the gory details of how to actually compute these gradients and partial derivatives so this is the portion that we are in we are intended to ask these two questions and this is where we are"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/26_3.wav", "duration": 210.0, "text": "now to learn sorry you want to learn this way to learn this weight we know that we can use gradient descent we are all convinced that this gradient descent algorithm which i have shown here as long as we put all these variables or all these parameters that we have into theta we can just run the gradient descent algorithm and compute them the only thing that we will need is this partial derivative with respect to all the weights in the network and in particular with respect to this weight that i am interested at"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/26_4.wav", "duration": 7.0, "text": "so let us now understand this in the terms of the wide complex network that we are using"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/26_5.wav", "duration": 84.0, "text": "so what actually is happening is that we are at a certain stage that means we have some values of ws and b\u2019s ok at the initial stage we just have these w knots and b knots but let us assume that we have done some training and we are at a certain level we are at wt at time step t and bt at time step t right for all the weights inverse now we feed it a training example we do this entire compute computation what do we get at the end we get y hat which is a function of this x that we have fed it but we also know this true y we know the true value we know y hat so we can compute the loss function so we compute the loss and to our surprise we see that the loss is not zero we are getting a non zero loss that means the network has not yet learnt properly right the weights and biases are still not in the right configuration that we want them to be in right so now what do we do we go on this path of investigation we want to find at who in this network is messing up things there is someone who is causing this problem because of which i am not getting the desired output and we are on our quest is to now find out who this guy is who is responsible for this so what would you do where would you start the output layer"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/26_6.wav", "duration": 310.471, "text": "because the output layer is the guy who give you the output right so go and talk to him and we say that hey what is wrong with you why are you not producing the desired output right now what is the output layer going to tell you in very civil language i will say i cannot do anything boss i mean i was just given some weights and inputs from the previous layer and those weights and inputs were messed up so there is nothing which i can do go and talk to them so who will it directors do it will say that i am just as good as wl hl minus one and bl because these are the guys that i completely depend on if these guys were ok then i would have been fine so we then go and talk to these guys that what is wrong with you"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/27_1.wav", "duration": 28.0, "text": "so this is the output and when i say i want to compute the gradient with respect to output unit what do you actually mean what is the quantity that i am looking for i will help you out actually what i meant by output unit is this entire thing right so i actually meant al\u2019s ok but it is it is a fair answer and even y hat is a fair answer ok in fact am going to start with y hat and then go to al so i will have to start with this guy and then come to this guy"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/27_2.wav", "duration": 324.0, "text": "so this is the loss this is y hat which is equal to y one hat y two hat up to yk hat so these are the k values that we have here and we are looking at cross entropy that means we are looking at the classification problem right so we have got a distribution over the k classes that is what y hat looks like and we know that one of these guys is the right class maybe say y two so the loss function is minus log of y hat two because two is the correct class in this toy example that i am considering ok so the loss function i am just repeating the definition right that is how the loss function is"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/27_4.wav", "duration": 67.0, "text": "so what if i what do i have so far i have this quantity what does till which part of the diagram am i currently the dash green part dark green part i am till here i need to go till the light green party that is collectively the output unit ok although i have divided into two halves but when i say output unit i mean that output neuron right complete neuron so what i am actually interested in is these quantities or more specifically ok this is what i am interested in what is this one of those guys right this al is actually al1 up to alk right so this is one of those guys so this is going to be the gradient or this is going to be the derivative a partial derivative sorry ok now what do how do we proceed from here"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/27_5.wav", "duration": 87.0, "text": "now i will again have to compute this you already know that good but before that i want you to answer one question right so y hat l what is y hat l it is the output corresponding to the correct class does it depend on an arbitrary al i so in the previous thing we saw that only when i is equal to l there is a connection in this case is there a connection always or only when i is equal to l student refer time eight hundred and two always why softmax so student refer time eight hundred and four denominator has all the ali\u2019s right so this is there it is y hat l in the numerator of course it only has this unit which corresponds to the l th probably did not choose my variables very well so l th component of a capital l right and but in the denominator you have the entire sum which means that every output guy here each of these dark green guys depends on each of the dash green guys light green guys good so that is at least settled that we always the we can always compute this partial derivative we do not need an if else here there is nothing like l is equal to i then what will happen it will always have this partial derivative"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/27_6.wav", "duration": 92.0, "text": "so we will now derive the full expression for this so this is what we are interested in is this fine so this is a function of the form so you are taking how do i say this so this is log of a function so first you will take the derivative with respect to log and then push the partial derivative inside right so that would be minus one by y hat l and then the derivative with respect to y hat l now what is y hat l the softmax function right so it is the l\u2019th entry of the softmax function applied to that output vector what is the output vector al right so it is the l\u2019th entry of the softmax or l\u2019th entry of the function applied to the output vector so this was our al what is our output right so now one of these guys here is the l th guy and one of these guys here is the l\u2019th guy right so what you do is you take this you apply the softmax function to it which again gives you a vector and now you are interested in the l\u2019th component of that vector that is what this quantity means it should be clear now"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/27_7.wav", "duration": 319.0, "text": "now i will just do some simple math stuff here and we should be able to derive this is it fine am just replaced by the actual softmax formula this is a derivative of the form u by v right what is the formula for that yeah it perfectly right yeah so this is what it would be right i mean it is you all know this i am not going to spend time on this so now am just going to substitute the values here yeah it is getting a bit nasty but it is not very difficult right so so this so this is our g of x so am taking the derivative of that then this is this one over h of x you can just figure it out right anyway it everyone just read this for a few seconds and let me know if this is not clear this is g this is h in this formula right have just substituted the gs and hs in this now what is this quantity going to be it is derivative of the form e raise to x right so it is e raise to x always student refer time one thousand, one hundred and thirty-three if i is equal to l right so now we have this dependence because we are looking at a numerator but the numerator only depends on the l th entry right so now you are trying to take the derivative of the l th entry with respect to some arbitrary i th entry so only if l is equal to i you will get the derivative right"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/27_8.wav", "duration": 53.308, "text": "y hat oh hey we should change all this y hat is equal to f of x right but i just want it to be consistent as y hat so is this fine this is a simplification fine right so we have come a long way right you have finish this part ok we have got the gradients with respect to the output units ok this much part is a clear to everyone moduler bit of the math which you can go back and look at it this entire derivation is fine but you get the concept right that we start with one unit from there grow the gradient then keep going applying the chain rule so we started with the dark green guys and then went to the light green guys now we have the derivative with respect to the entire light green vector and that is what we had started off with that we wanted the gradient with respect to the output units"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/28_0.wav", "duration": 6.0, "text": "now we will go to the gradient with respect to the hidden units"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/28_1.wav", "duration": 17.0, "text": "so this portion so you already see there is a repetition here and i do not need to treat each hidden unit separately i can just have a formula for the hidden unit and then i could compute it for all the hidden units so that is what our aim is so let us do some simple stuff first and then you will come back to it"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/28_2.wav", "duration": 115.0, "text": "so suppose you have a variable x you compute two functions from that one is x square the other is x cube i will call this as y one and i will call this as y two and i take y one and y two and compute a z which is say a log of y one by y two now what i am interested in is this what is the answer for this how do you get this this is a fair question to ask y one y two are functions of x z is a function of y one y two hence z is a function of x so i can compute this derivative and i can ask for this derivative how would you compute it if i cannot really do this right so if this path did not exist then it is trivial it is just the chain rule along one path but now you have two paths so what will happen add them right so can you tell me a formula for that so let me know if this makes sense to you ok does this make sense now let me complicate this a bit just let me just do it as y three now student refer time two hundred and fifteen what will happen student refer time two hundred and sixteen that is all right so you see that if there are multiple paths you can just add up the chain rule across all these paths right that is what chain will across multiple paths does"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/28_3.wav", "duration": 597.0, "text": "so with this we will go back to this figure so now i am interested in i am interested in going to the hidden layers again i will do this to bit calculation where i first asked for this guy and then i will ask for the light blue guy right and am going to look at one unit at a time now what is the what am i interested in the derivative of the loss function with respect to say d h two two right the second unit of the second hidden layer"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/28_4.wav", "duration": 313.0, "text": "so this is what it will look like ok now consider these two vectors one is this vector what does this vector look like this is a collection of all the partial derivatives so this is just a collection of all the partial derivatives nothing new we have already seen this now what is this vector actually in fact i have started with the matrix and i am saying look at this vector what does this mean this i plus one is just the layer in which the matrix is right so that index we do not really care about for a matrix what we care about is the i comma j index ok now what does this dot comma j mean all the i\u2019s belonging to j that means the dash column j\u2019th column everyone gets this this is all the i\u2019s or all the entries belonging to the j\u2019th column so it is effectively just the j\u2019th column so it is one comma j two comma j up to k comma j right so these are two valid vectors now tell me what is this quantity going to be this is the dash between two vectors dot product dot product between two vectors is a student refer time one thousand, three hundred and forty-three is a summation over element wise thing ok i have said enough now try to connect this is a very simple maths the column that you will ever get in your life try to connect this to something which is already there in the slide how many of you think the answer is this this into this plus this into this plus this into this and just write it as a formula you will get this everyone sees that ok so now i have a compact way of writing one of these entries"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/28_5.wav", "duration": 92.0, "text": "so that is again very simple again what will i do i will compute it with respect to ok what is this this is the guy that i am interested in the generic i not the l\u2019th one right the generic i this is what the vector looks like the gradient vector looks like i want each of these guys ok now i will take one of those and i will write it as this ok what am i doing am saying that i already have the entries up to here ok at a very general level even here i could have said the same thing remember that i had said that the output layer you can always write as hl right so even at the output layer i could say this chain rule always holds how many of you agree with that i want to go from the loss function to one of the lighter blue guys so am saying that i can go through the intermediary dark blue guys that is all i am saying i have just compressed this entire path into up to the dark blue guy remember i had said earlier that i will be compressing this chains now how many of these quantities do you know the first one is what we computed on the previous refer time one thousand, eight hundred and fifty-two the second one looks very difficult sorry so h ij is nothing but sigmoid of a ij or any nonlinearity of the a ij so i can just write this derivative as i will just write it as sigma prime ok"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/28_6.wav", "duration": 80.75, "text": "or g prime is this fine now i have it with respect to one unit what will i do go to the gradient fit it all these values now simplify this what is this a vector right what is this another vector there is a one to one correspondence between them so you have two vectors and you are doing a one to one multiplication what is this student refer time one thousand, nine hundred and forty-three how many of you say dot product dot product is always a what is the output here student vector can it be a dot product can it be a dot product no please empathic no ok so what is it going to be an element wise multiplication and this is how you denote that ok so what is this called you had a multiproduct right so this is every element of one vector multiplied by the corresponding element of the other vector ok so now again the entire vector we can compute at one row right i am not i am when i am teaching this i am telling you how to compute one element and then go to the gradient but when you are going to implement this we are just going to compute the gradient at one go"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/29_1.wav", "duration": 108.0, "text": "before we move on to the next module a quick summary of what we have done so far so we introduced feed forward neural networks and we wanted to learn the parameters right from the last layer to the first layer and we figured out that what we can do is that we can just use the gradient descent algorithm as it is except that we have this small problem that we have so many parameters now and located at differ different points in the network right some at the initial layer some at the final year and you want to compute the derivatives or the partial derivatives with respect to all of these if you can do that put them all in this large matrix then we can just use gradient descent as it is so that is what we figured out and then we wanted to find out the gradients with respect to or the partial derivatives with respect to all these parameters so then we realize that this can be done using chain rule because there is a path from your output which is the loss function to any of these weights so we just need to follow that path and apply this smart this chain rule smartly and just sum up the derivatives across all the paths that lead to that weight so in that process we started from the output layer we just treated it a bit special because the output function is special and this is the last layer so we just first computed the gradient with respect to the output layers then we figured out how to compute the gradients with respect to any of the hidden layers and now if you are at a particular hidden layer now the weights that feed into this layer we could or we have not reached there so now the next thing that we need to do is that we have computed the gradients with respect to any of these hidden layers and now we want to find the gradients with respect to the parameters which is the weights and the biases so it is the do you all remember this or it is all long history or the story is back right fine so now we are at the last point which is computing gradients with respect to parameters"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/29_3.wav", "duration": 119.0, "text": "so let us do it right so you have ak1 ak2 ak3 that is your ak vector ok you have bk1 bk2 bk3 plus wk1 one yeah i know again this is one of those silly things but if everyone does not raise their hands and compelled to do this so h k minus one one hk minus one two hk minus one three ok so let us take one of these guys right so a k one can you tell me the formula for that student refer time seven hundred and thirty plus first row ok one two this one three now can you tell me this quantity so what is i here one ok so i want this by w k i j right so i is one so i can take any of the j so let me take j equal to two so what is it going to be this will go off this is constant this is constant only this term remains and the derivative is hk minus one two which is j right so that is what the formula says so i have a formula for one of these guys ok and that is a generic formula so always remember if you cannot figure out what it is just write it down in scalar terms just add up all the terms and you will get the formula right so now this is what the chain rule is going to be"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/29_4.wav", "duration": 163.0, "text": "so this is what it is going to be this is one element of that tensor this is how that entire thing is going to look i have just flattened it out and put it here"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/29_5.wav", "duration": 54.191, "text": "so fine so finally we come to the biases this is what one entry looks like this is exactly the sum which i had written out now i take the derivative with respect to b k i of the loss function so i could write it into as this chain rule where the first quantity is something i already know i have computed the gradient with respect to the pre activation layers what about the second quantity anonymous roar is what i was expecting student one one ok fine we can now write the gradient with respect to the bias what would it be what is this what is this it is just the gradient with respect to the pre activation layer right simple so now we are done with all the gradients that we were interested in"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/3_0.wav", "duration": 5.0, "text": "when this deep revival happened so in two thousand and six a very important study was or a very important contribution was made by hinton and salakhutdinov"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/3_1.wav", "duration": 86.0, "text": "sorry if i have not pronounced it properly and they found that a method for training very deep neural network effectively now again the details of these are not important we will be doing that in the course at some point but what is the important take away here is that while from one thousand, nine hundred and eighty-nine to two thousand and six we knew that there is an algorithm for training deep neural networks and they can potentially be used for solving a wide range of problems because that is what the universal approximation theorem said but the problem was that in practice we were not being able to use it for much it was not easy to train these networks but now with this technique there was revived interest and hope that now actually can train very deep neural networks for lot of practical problems this sparked off the interest again and then people started looking at all such of thing right that even this particular study which was done in two thousand and six will actually be very simple to something done way back in nine thousand, one hundred and ninety-three and which again showed that you can train a very deep neural network but again due to several factors may be at that time due to the computational requirements or the data requirements or whatever i am not too sure about that it did not become so popular then but by two thousand and six probably the stage was much better for these kind of networks or techniques to succeed so then it became popular in two thousand and six"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/3_2.wav", "duration": 77.0, "text": "then this two thousand and six to two thousand and nine people started gaining more and more insights into the effectiveness of this discovery made by hinton and others which is unsupervised pre training right that is what i spoke about on the previous slide unsupervised pre training and they started getting more and more insights into how you can make deep neural networks really work so they came up with various techniques some of which we are going to study in this course so this was about how do you initialise the network better what is the better optimization algorithm to use what is the better regularization algorithm to use and so on so there were many things which were started coming out at this period two thousand and six to two thousand and nine and by two thousand and nine everyone started taking note of this and again deep neural networks of artificial neural networks started becoming popular that is when people realised that all this all the negative things that were tied to it that you are not able to train it well and so on have slowly people have started finding solutions to get by those and maybe we should start again focusing on the potential of deep neural networks and see if they can be used for large scale practical application so this two thousand and six to two thousand and nine was again a slow boom period were people were again trying to do a lot of work to popularize deep neural networks and get rid of some of the problems which existed in training them"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/3_3.wav", "duration": 25.0, "text": "now from two thousand and nine onwards there was this series of success is which kind of caught everyone which made everyone to stand up and take notice right that this is really working for a lot of practical applications starting with handwriting recognition so around two thousand and nine these guys won handwriting recognition competition in arabic and they did way better than the competitor systems using a deep neural network and then this was a success"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/3_4.wav", "duration": 22.0, "text": "so this was an handwriting recognition and then there was speech so this shown that various existing systems the error rate of these system could be seriously be significantly reduced by using deep neural networks or plugging in a deep neural network component to existing systems right so this was handwriting and then speech"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/3_5.wav", "duration": 53.0, "text": "then again some kind of pattern recognition which was on handwritten digit recognition for mnist this is a very popular data set which had been around since ninety-eight and a new record was set on this data so this is the highest accuracy that was achieved on this data set around that time in two thousand and ten sorry and this is also the time when gpus entered the same so before that all of the stuff was being done on cpus but then people realised that very deep neural networks require a lot of computation and lot of this computation can happen very quickly on gpus as opposed to cpus so people started using gpus for training and that drastically reduced the training and inference time so that was again something which sparked a lot of interest right because even though these were successful they were taking a lot of time to train but now the gpus could even take care of that and this success continued"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/3_6.wav", "duration": 15.0, "text": "so people started gaining or getting success in other fields like visual pattern recognition so this was a competition on recognising traffic sign boards and here again a deep neural network did way better than its other competitors"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/3_7.wav", "duration": 153.508, "text": "and then the most popular or one thing which made neural networks really popular was this image net challenge which was around since two thousand and eight or two thousand and nine and before two thousand and twelve when this alexnet was one of the participating systems in this competition most of the systems were non neural network based systems and this competition was basically about classifying a given image into one of thousand classes so this could be an image of a bird or a dog or a human or car truck and so on say you have to identify the right class of the main object in the image so in two thousand and twelve this alexnet which was a deep neural network or a convolutional neural network based system was able to actually outperform all the other systems by a margin of sixty-seven percent so the error for this system was sixteen percent and this is a deep neural network because it had eight layers the next year this was improved further and something known as zf network propose which was again eight layers but it did better than alexnet the next year even a deeper network with nineteen layers was proposed which did significantly better than alexnet then google entered the scene and they proposed something which is twenty-two layers and again reduced the error then microsoft joined in and they proposed something which had one hundred and fifty-two layers and the error that you see here is actually better than what humans do so even if a human was asked to label this image because of certain law certain noise in the image and so on even a human is bound to make more errors than thirty-six per cent that means even if you show hundred images to humans he or she is bound to may go wrong or more than three or four of these images right there is this system was able to get an error of thirty-six per cent over the large test set so this two thousand and twelve to two thousand and sixteen period were there was this continuous success on the image net challenge as well as successes in other fields like natural language processing handwriting recognition speech and so on so this is the period where now everyone started talking about deep learning and lot of company started investing in it a lot of traditional systems which were not deep neural network based was now started people started converting them to deep neural network based system so translation system speed systems image classification object detection and so on there were lot of success in all these fields using deep neural networks and this particular thing that we are talking about which is image net and the success in this was driven by something known as convolutional neural networks"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/30_0.wav", "duration": 13.0, "text": "so we move on to the next module and now we will write pseudo code to for back propagation"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/30_1.wav", "duration": 40.0, "text": "so we have all the pieces of the puzzle we have the gradients with respect to the output layer that was the special layer because the output activation function is different they are the gradients with respect to all the hidden layers that means i have the gradients with respect to the activations as well as the pre activations so in the h\u2019s as well as the a\u2019s and i also have the gradients with respect to the weights and the biases and this is all index agnostic right that means i am just using k as the index everywhere i have a generic formula which applies at any layer for the weights as well as the activations and the pre activations right ok now we can put all this together into a full learning algorithm so let us see what the pseudo code looks like"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/30_2.wav", "duration": 66.0, "text": "so we have this t equal to zero well run this for some max iterations we initialize all the parameters to some quantity will randomly initialize them ok now for these max iterations can you tell me what is the first thing that i will do so there will be two functions here ok tell me what those two functions would be student forward forward propagation and then backward propagation right so you do a forward propagation and you compute all these activations pre activations output layer loss everything and then you do this backward propagation where you feed all these things which you have computed these are the quantities which you have computed you will pass this to your backward propagation algorithm it would not look so nasty as this it will not take so many parameters you could write it smartly and then you will just do the parameter update so what will the back propagation give you actually all the gradients all the partial derivatives right and then once you have the partial derivatives you know how to compute the update law so now let us look at these two functions more carefully the forward propagation and the backward propagation"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/30_3.wav", "duration": 36.0, "text": "so forward propagation is simple for all the hidden layers that means from layer one to layer l minus one what will i do give me the code a k is equal to good then ok and what it what is h of zero you are starting the loop from one right so you will need h of zero that is x and then you will have a special treatment for the output layer and your final output will be whatever output function you use ok this makes sense you can write this in python you will have to write this in python"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/30_4.wav", "duration": 163.328, "text": "now we have computed all the h\u2019s and the a\u2019s what have we computed all the a\u2019s all the h\u2019s and all and the y right now you want to do back propagation so back propagation the loop will be from i equal to one to n minus one good so the first thing i will compute is the gradient with respect to the output layer see even here the output layer was outside the loop the same thing would happen here also in the back propagation also first you will compute the gradient with respect to the output layer and this is the formula if you remember from last class right that is the formula which i have substitute here and note that f of x is known to you because you computed that in the forward pass and e of y one hot vector which with a correct label said to one and you know what the correct label is because we have given you the refer time three hundred and fourteen data right ok then what would the loop be l to one or l minus one let us see first you compute the gradients with respect to parameters it is l so because we are using k minus one then you compute the gradients with respect to the layer below computes gradients with respect to the pre activation right this is exactly how you will proceed this is clear to everyone the same three components that we have used you might be a bit confused about the ordering in which we have put them because we computed the gradients with respect to pre activation first and then the weights but once you go back you will realize because it is the way we have indexed it because this is already outside so this has already been computed so you can already compute the gradients with respect to the weights of the outermost layer is that fine so this is straightforward you can go back and check this ok now anything remaining or you have everything can you just take a minute and see if you can visualize the python code and we will just assume that you are done the assignment you can read you will have multiple these vectors and matrices and so on and you are just doing a lot of matrix operations using refer time four hundred and six or refer time four hundred and eight or whatever you prefer right now what is missing here input is missing ok input we have given right the ominous data set has been given is there something that yours i have still not shown you how to compute oh i did not update the parameters here is it no the parameter update will happen in the outer loop right so those forward prop back prop and then update the parameters right so the main algorithm was forward prop back prop update the parameters when we saw forward prob an obvious seeing backward prop so what is missing one thousand iterations something in the last line before end of course do you know how to compute this"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/31_0.wav", "duration": 19.0, "text": "we have that activation function and we were taking the derivative of the activation with respect to pre activation and i just pushed it under the rug by saying we will write it as g dash so i need to show you what g dash is"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/31_1.wav", "duration": 53.406, "text": "what how to compute g dash so this is suppose g is the logistic function ok so that means what is z actually it is one of those a\u2019s right so this is the activation that you are going to feed it right and then you are taking the element wise sorry z is actually the pre activation that you feed it and then g is the activation function so i will do element wise activation function now what is the derivative of this so i will just i will not do this derivation it is there and you end up with a very neat formula which is g of z into one minus g of z so now that bit is also taken care of is there any more spoon feeding that i can do you are ready for the assignment now i will do one more bit you will also have used a tanh function so this is the derivative of the tanh function it again boils down to a very neat formula which is one minus g of zd whole square so we will end this lecture"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/32_0.wav", "duration": 41.0, "text": "so for the next module we need something known as cross entropy so we will just try to make some develop some intuitions for cross entropy and get to the formula for that and then i will tell you how it relates to the problems that we deal with ok so first let us start with something simple that what is it that we are trying to do ok so with that i will give you an example and i will ask you a few questions and then from there we will slightly try to go towards cross entropy so now suppose you have an urn which has thousands of balls and these balls are of three different colors which are red black and white"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/32_1.wav", "duration": 757.0, "text": "so you have an urn which has three different types of and there are many such balls which you have put in it and since you have put in it you know how many red balls are there how many blue balls are there and how many white balls are there so for you it is very easy to compute the probability of each of these things so that is say our probability is twenty-five thirty-five and four now talking more formally what is happening here is that you have a random variable x which can take on the values red blue or white right and this is the probability of each of those or the random variable x taking any of these values ok so this is the setup now i am your friend and you tell me that you can peep into the zone you cannot actually count take out all the balls and count them and estimate the probability we can just take a look into this and try to give me an estimate of what these actually what are these probability values that means what is the value so what is the probability that x is equal to red or x equal to white or x equal to blue so i just take a look at it turn it around a bit and try to get some feel ok i see a lot of red balls but a fewer blue balls or white balls and so on and based on that i make my best estimate right so i will just say that maybe these probabilities are thirty-five forty-five and two right so this is actually the true distribution i will call it as p right because this is the correct one and what i have estimated i will call it as q and remember now p has you can think of p as a vector which has these three values p one p two p three because there are three possible events here and similarly q has three values q one q two and q three so in this case i clearly know that i am wrong or when i give you these values you know that you are wrong so you tell me that whatever you have estimated is wrong then i obviously ask you tell me how wrong was i so how would you give me that number that is the thing that we are interested in so the general problem that we are interested in is that there is a true probability distribution and there is an estimated probability distribution and we want to find out how bad was the estimation now can you tell me a simple way of computing this it may not be correct but still it makes sense student squared error you can just take the squared error so what you are essentially telling me is that you could just treat these two as any other vector right and you could take the squared error difference between these quantities so what you are telling me is this where i goes from one to three ok so this is one valid way of doing this but then we are ignoring the fact that this is a distribution and hence it has certain properties that the sum of the elements is one and so on all of them are positive and things like that so we are ignoring those kind of things we are completely ignoring the fact that we are not dealing with a normal vector but a spatial vector which happens to be a distribution so now we want to find out a more principled way of computing the difference between two distributions and in practice why are we interested in this because we will always have a true distribution and a predicted distribution so that is what we want to do we have some way of computing it but you want a better way of computing it now let me make a case for why do we care about such differences right so let me take a simple case of a classification problem and to motivate that i will start from a different example and then i will come to the classification problem suppose there is a tournament going on and there were four teams which leads the semifinals let us call them a b c d ok now you were following the tournament up to the semifinals and after that you didn\u2019t watch the tournament and you do not know who eventually won well the tournament is over and someone has won it i actually watched the tournament and i know that b has won it now can i express this in terms of a probability distribution right so first let us look at what is the random variable here what is a random variable here the team which won right so that is my random variable and it can take one of these four values now i know that team b won because i saw the tournament and i have seen that they won so now how can i write this as a distribution what is the distribution comprised of it comprised of these probabilities assigned to each of these events and there are four such events here so how do i write this distribution so what you are telling me is i could write it as zero one zero zero so essentially they are telling me that all the probability mass is focused on one of these outcomes because that is the certain outcome that is already happened no one can change it so that is the outcome for this tournament so i know that the probability of that even is event is one and everything else is zero so in other words the probability that the random variable x takes on the value b is one and everything else is zero so what i am trying to tell you is that even for a certain event you could still write it in terms of a distribution where all the mass is focused on that event now again i will bring the same setup that i did not watch the tournament after the semifinals so now you ask me give me your prediction what which team would win or this is the prediction which i made before just after the semifinals or just before the semifinals that i think one of these teams is going to win the tournament and the chance of each of them winning is something like this so i know the teams i follow this sport and i probably know that ok b has a very strong team and they have a very good record in the past few months and so on so maybe they have a higher probability of winning so these are the numbers which i assign now again i have made an estimate was my estimate perfect when would it have been perfect if i had predicted with certainty won that b is going to win but i was not willing to bet everything on b so i said there is a very high chance it will win but there is still a chance that there could be some surprises now how wrong was i now again tell me can you tell me what is p and what is q here this is the true distribution and this is my predicted distribution and what am i interested in again the difference between them how wrong did i go and what again what is a simple way of doing this again square errors so again this is what my formula would look like so this is fine in this toy case but why do we care about in real life examples that we are going to deal with in machine learning so in watching learning will deal with a lot of problems which are classification problems and in classification problems you would again have this setup where you have a label the good thing of the label as a random variable and it could take off one of many values so i will again assume that it could take suppose you are trying to take a picture of fruits and you are trying to classify them and i could again think that i have four fruits say apple banana cherry and dragon fruit ok and this random variable can take one of these four values depending on the image that i am seeing ok now i have been given some training data so for every training data i have been given an image and i have been given the correct label so for that training data what is this distribution suppose i have been given the image of a banana what does this distribution look like zero one zero zero right again i have seen it so i know it is certainly a banana so i do not have any confusion all the probability mass is focused on that now the same image we are going to show to one of our models ok and it is going to make a prediction and will again ask it to give us a distribution the model will give us values perhaps like this ok so this is the models prediction again the model has given us a distribution and we have a true distribution and we are interested in knowing how wrong the model was so that student correct the refer time nine hundred and twenty-six we can correct the parameters of the model so this is our dash function loss function right so a loss function is some notion of difference between p and q right and so far we have been dealing with a very simplistic notion of this difference which is just the squared error loss ok and we want to do something better than this right so what i have told you is that you could always have a true distribution always have a predicted distribution and you would be interested in finding the difference between them that is the one first part the second part is that even when you are given something with certainty you could still write it as a distribution such that all the mass is focused on that event which was which has happened right which was the label was banana in this case and then you could still predict this from your model and now you are interested in knowing how wrong you are model wind because that is the loss function that you will use and then you will try to update your parameters with respect to this loss function means that is the setup that we are interested in so that is so i made a case for why we need to find differences between two distributions how to do it in a more principled manner we have not seen that yet we will get to that ok so before i get that i also need to tell you something about expectations so let us written to as sports example where there were four teams and say based on pundits and that sport they have said that these are the probabilities of winning and now you are into betting and you bet place your bets on these teams and you place our bets in a way that suppose team events then you end up winning ten k rupees if team b wins then probably will end up winning five k rupees and if team c wins probably ten k and if one of the other team wins maybe will end up losing money or something like that now you want to know what is your expected reward so now let us see what is happening here this was a random variable which could take on one of these four values these are the probabilities of the random variable taking that value taking on the value a or taking on the value b c and d ok this is your value or the gain or the profit associated with the random variable taking one of these values so you have a random variable you have a probability associated with every value of the random variable and you have some gain or value associated with every value of the random variable now how do you calculate the expected gain or expected profit which is this there is a thirty percent chance that you will earn ten k there is a forty percent chance that you will earn five k there is a twenty percent chance that you will earn ten k and ten percent chance that you lose thirty k so the way you will compute it is that and this is the simple expectation formula which is the probability of now the event here belongs to abcd right this is one of the four teams that will win probability of that event happening in to the value associated with that event happen this is a fair computation you get the intuition that this is how you will compute the net reward that you have so this is how you compute the expected value with respect to a particular distribution so this is the background that we need now i will just go on to the next slide and now we will talk about entropy first perhaps information content be first then entropy and then cross sector ok so now what is information content"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/32_2.wav", "duration": 528.0, "text": "so now again let us take the same case that we have a random variable which can take on values a b c d now let us what we are trying to say is that if i know a certain thing what is the information that i have gained so you and i are talking you tell me something and i want to see whether my information was enhanced whether my knowledge was enhanced that is how we will quantify information content so if you are talking to me and you tell me that my name is mitesh the zero information content for me right because i already know that there is no surprise in that ok but if you talk to me and you tell me that today there is going to be a lunar eclipse then there is a possibility there is some information content gain for me right because that is not a event which happens every day if you just tell me you will see the moon today and you live in a region where it is not typically cloudy and there is no information gain there right so what do you see here when is the information gained high when the event which happens is a very surprising event and how do you say supplies in terms of probability student refer time one thousand, four hundred and twenty-nine it is a very low probability event right so if there is again this tournament and say d was the weakest team in the tournament and a was the strongest team in the tournament if you come and tell me that d won then i would be really surprised that some information which i had gained but if you tell me that a won then probably i already knew it at the back of my mind because a is clearly the strongest team in the tournament and there is no information gained for me so one thing that we are trying to establish that the information content i see ok the information content of an event is inversely proportional to the probability of the event there is a that is a fair intuition fine now i want am still talking in terms of vague things i am saying it is inversely proportional but i still need an exact function so that i can compute it so i want something i want a function where i plug in the probability of an event and i get the information content of the event right now i do not have that function i am just building some intuition towards that function ok but this is one requirement that i want the function to satisfy this is something that all of us agree with ok now think of two events which are independent a and b ok so a is the event whether the ac is on here or not and b is a event which tells maybe so let us consider two different random variables so x is the random variable which can take on values zero and one sorry so x is again this random variable which can take on these four values abcd whether who won in the tournament and y is this another random variable which can take on the value on and off depending on whether the a c\u2019s on in this room or not what can you tell about these two random variables they are independent random variables so this is on or off and this is which team won the tournament now i come and tell you something about the random variable y and i come and tell you something about the random variable x ok so now i want you to tell me this what is the information content of x and y i tell you something about x and i tell you something about y and these two events are in these two random variables are independent then what can you tell me about the information content what is the condition that you would want you gain some information by knowing things about x and you gain some information by knowing things about y so what can you tell me it should be the sum right because these two are independent events so whatever information i am getting from this random variable and this random variable which together enhancing my information right it is not cancelling out anything or is there is no common intersection there right if the two events were not independent then i would not expect this to hold because knowing something about the first event only tells me something about the second event right because they are dependent so then that case the information gained would not be additive ok so now let us see i already made a case that this function which tells me the information gain is actually proportional to the probability ok so that means this is what the input is going to be right and then what is the other condition that i want this is a fair thing right i just replaced information content by a function and i know that the function should depend on the probability because that is what we have established here so we know that the function depends on the probability we still do not know what this f is exactly but i am trying to impose some conditions on f one condition of f f is that this condition should hold ok now let us look at this condition which i have underlined this is f of is this fine because it two events are independent you can write them as the joint probability as p of x into p of y this is clear to everyone right you seem to be a bit lost arvind clear ok now what is happening here i have a function f of a into b and that is actually equal to f of a plus f of b what family of functions do you know which has this characteristic log right that is why log is a good choice for this that is why information content is going to be the log of the probability but i wanted to be inversely proportional right so it will be log of one by the probability ok so that is why information content of this thing is so you see this how did we arrive at this log formula and this log can just be to any base it does not matter so all of you get how we arrive at the formula for information contained now just give me a minute i need to think of what is the next thing that i have to say ok and so we have found out the information content of one of these events happening which was the x taking on the value a now let us think of this random variable x so here actually i should have said x equal to a probability of x equal to a ok it makes sense because the random variable is x and the event is x taking on the value a how much information content is in that so if i know that x was a how much will i be surprised by it ok now let us take this event this random variable x which can take on values a b c and d as i said with each value there is a probability associated with it such that this sums to one now i did not need to draw this diagram ok i should refer time two thousand, one hundred and one so x is a random variable which can take these four values which each of these values i have a probability associated ok so these are the values these are the probability values now what do i also have i have the information content associated with each of these right and the information content actually tells me the surprise of that evening now if i ask you what is the entropy of this random variable x so remember i had this case where i was betting i am with every poor outcome i had a value associated with it i had the same situation here with every outcome have a probability and i also have a value associated with this and the value is the information content now if i ask you what is the entropy or the expected information content of this random variable then how will you compute that i am asking you for an expectation"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/32_3.wav", "duration": 80.0, "text": "so i will compute summation i belonging to a b c d p of x equal to i information can take what is the formula for that student minus refer time two thousand, two hundred and twenty-nine minus i will just take the minus outside ok so this quantity is called the entropy of the random variable right it is the expected information content in the random variable now if you see what would be the expect entropy of a random variable if it is corresponding to a certain event that means say the sun rises always in the east right so what is going to be the entropy of that zero why you will have one of the sums in that summation as one log one right and every other sum would be zero into log of something so zero into anything is going to be zero even though that quantity is not defined zero into anything is going to be zero so the total entropy is going to be zero ok so this is entropy now what is it that we are actually interested in cross entropy so we have not gone there yet ok so we need to perhaps add one more slide so far everything is clear ok so now we are interested in something known as cross entropy"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/32_4.wav", "duration": 23.0, "text": "so there again the situation is that there is something which is the true distribution and something which is the predicted distribution now actually before going there so let me just erase this off how many of you have thought that entropy is related to the number of bits that you need to transmit something do you know why that connection exists no now again let us think of this that you are trying to transmit a message"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/32_5.wav", "duration": 444.0, "text": "and that message is again a random variable which can take on four values a b c d so think of these as four commands that we are trying to send to someone right and then based on that command someone will take some action now in the digital case how will you transmit this encode it to bits so what is the encoding that you will use zero zero yeah we will come to that zero one one zero one one so how many bits are you actually using for every message two bits ok for every bit so maybe this is a this is b this is c and this is d so for every message you are using two bits let us see actually what when you are doing this what are you actually assuming so actually assuming that all of these are equally likely if all of these are equally likely can you tell me the information content of any of them it is going to be minus log of one by four ok that is actually equal to minus log and this is to the base two ok one by four is two raise to minus two that is equal to two so the information content is actually equal to the number of bits that you are going to use to transmit that message now let us see if this is just in this special case or in a different case also suppose this could take eight values how many bits would you use three bits right so you will have zero zero zero zero zero one ok and this would be a to h now what are we actually assuming here each of these is equally likely what is the probability one by eight what is the information content two raise to minus three that is equal to three so the number of bits that you actually use to transmit something this can you can talk of it in terms of the information content of that now suppose i want to transmit this over the long distance so i need to bit be a bit efficient in terms of number of bits that i use right so now in this one of these cases suppose it is of the following form right that let us look at the case where x can take one of four values and say let me just put the right values so i will say one by two one by four one by eight one by eight ok now what is the information content of each of these one two three three and this is the message that i am going to send so what am i doing here i am using a different number of bits depending on the probability of that event why does this make sense why is this a smart thing to do if you want to transmit something which you are going to transmit a lot of times you better use less number of bits for that and this is exactly what is happening here a was having the highest probability and you are using the lowest number of bits for that now what is the expected number of bits that i will use up if it is a i will use one if it is b i will use two if it is c three and d three so what is the expected number of bits that i will use again i have the same situation right i want you to cast it into the same situation i have the probability values and with each of these guys i have a cost or a value associated what is the cost one bit two bit three bit three bit so what is the expectation now can someone compute the expectation one hundred and seventy-five actually let me just write it down it would be again i belonging to a b c d p of x equal to i into the number of bits that you will use so that is just equal to log of log to the base two of p of x equal to i minus one what does this quantity actually this is the entropy we just saw this a this is the entropy of the random variable and what is it telling us actually that the entropy is one hundred and seventy-five so what is the meaning of this actually so on average you will be needing one hundred and seventy-five bits whereas if you are assuming everything is equally likely on average you are using two bits right so you see that on average you are making some savings here right so that is what the entropy tells you if you know what the probability of these events is then you better use that to decide the number of bits that you are going to use to send each of these so now let us complicate this a bit more now we have the entropy now let us complicate it a bit more so there is some true distribution which exists there is some true distribution from which these messages are coming right but you do not know what that true distributions we never know the true distribution that is the entire problem that we have been dealing with in machine learning so what you will do is we will somehow try to predict this distribution and this then the and the recipe that you will use is the same as that i used for the example where i had an urn right so there are these thousands of 10000\u2019s of messages which has going to keep coming on you do not have access to the entire stream but you have seen some thousand of those messages just as i had peeped into the urn and i had seen some balls and i had made an estimate that i think based on these messages that i have seen so far i think these are the actual probabilities so the true probabilities are say p one p two p three and p four corresponding to a b c and d i do not know what this two properties are but i can estimate them looking at some samples or basically using my domain knowledge right maybe i would know that if one of these messages is stopped and i am actually trying to talk to a computer or a computer program that maybe stop is something which are used very rarely only at the end of the program or something so you have some either some domain knowledge or based on some samples i can estimate the value of this probability and i just try to relate it to the exact example of urns where you had these 10000\u2019s of balls but you could not see all of them you sampled some and estimated a probability here again there is a continuous flow of message you cannot have access to all of these because they are going to continue but i have seen some of those and based on that you estimate these probabilities now based on this estimation how many bits so now this is the estimation that we have now based on this you will decide the number of bits that you will use for each of these messages right because you have some estimate so you want to be smart you do not want to keep two bits for all of them so you will just say that i will use log qi bits for the i\u2019th message"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/32_6.wav", "duration": 753.509, "text": "this is fair thing because i know that the information content is proportional to the probability in fact it is exactly given by this formula minus log of qi so based on my estimated probability i am going to do this ok and this is the number of bits that i have reserved now do you see a problem with this this is my estimation but the data is actually going to come from the true distribution it is not going to follow the distribution q it is going to follow the distribution p so now what is actually happened is this right this is the situation that we are dealing with we have p which was a true distribution that is the rate at which the data will come but with each of these events the value that we have associated is now related to q because q is what i have access to i do not have access to p i just have access to q so i have associated a value based on q does this make sense i should have actually used log p one bit\u2019s log p two bits and log p three bits but i do not know what p one p two p three are i just estimated them based on some samples so that is q one q two q three and these are the number of bits that i am using now if i have to compute the expectation how will i do it i have to use p because that is the true distribution from which the data is coming so what would the expectation now look like everyone gets this the actual probabilities are this but because i am poor at estimating them i ended up associating these values which could be wrong right because i would have overestimated the probability of one of these messages and hence i have reserved lesser bits for that or underestimated the probability of one of these events and hence reserved more bits for that or vice versa i could have assigned a wrong number of bits to them right p no so do we have access to p in the sense so someone knows that right i mean there is a again in the same case as in the label case right we have access to the true p there and we are estimating a q when we are given these images for the training data we know that the distribution is zero one zero zero if the image is b for banana student refer time three thousand, three hundred and forty-nine then it is validated right so now this is what is this quantity called this is called the cross entropy ok you get why it is called the cross entropy because now you have two different distributions involved here ok you have the q distribution based on which you made your decisions you assign values to these events based on the q distribution but the true distribution is the p distribution so the actual number of bits that you use up on average is going to be based on the true probability they try to understand that now what will happen is for event a you have assigned a certain number of bits now how many bits will get used up it depends on the actual probability of p if that message is repeated many times then that is how this summation would be computed so this is called the cross entropy but now why is this the difference between two distributions that is what we wanted given two distributions we wanted to be able to find the difference between them now am telling you that cross entropy is a way of finding that difference why is it so so what would you want this difference to what is the property that you would want this difference to have if p is equal to q then if p is equal to q then student refer time three thousand, five hundred and eight not zero maybe it should take the lowest possible value right so this function right this is actually telling you loss of p comma q right this is what this is and we are calling it as the cross entropy this function you take it is minimum value when p is equal to q right because now at that point you are not really making any loss that is the best you could have done does this function take it is minimum value when p is equal to q yes why how is that obvious but why there could be something else which is lower than the actual entropy right why how you have to we are trying to minimize something so you have to give me answer so yeah so let us do that ok so how many of you it is obvious that q is the answer i mean the answer is p is equal to q it is not ok now this is the part which i am a bit worried about but i will just do it anyways so let me see how do i put this ok so remember that we had a p and we had a q and we want to find a q such that this quantity is minimized that is what our objective is so we want to minimize this with respect to qi ok now how do you find the minimize suppose i have this problem how do i find the minimum value how do i find the value of x which minimizes this take the derivative and set it to zero ok and then in this case i will get x equal to zero is that value can i do the same thing here and suppose it was this so now this is a function of two variables again i could do the same thing i could take the partial derivatives and set them to zero and i will get the minimum value now here this is actually a function of how many variables k in general right so q one q two q three up to qk ok now can you try doing the same thing can you can you take the derivative and set it to zero this is again a sum right it is very similar to this situation it is actually let me just write it down it is p one log q one plus p two log q two up to p k log qk now i want to take the derivative with respect to one of these guys say q two what would it be p two by q two is equal to what will i do that is the derivative p two by q two i will set it to zero do i get anything what is it that i am doing wrong here there is something that i am deliberately doing wrong is this an unconstrained optimization problem there is a constraint on the variables what is the constraint so why my true optimization problem is minimize with respect to q i\u2019s such that summation q i\u2019s equal to one do you know an easy way of dealing with these problems how many of you know the lagrange multiplier how will i use it here what will my objective function become then summation of qi minus one lambda then minus ok how many of you understand the intuition behind this that is a good answer now let us let me try to explain why this makes sense right this is the constraint that we have to operate within this constraint what i have done is i have taken the so now if the constraint is not satisfied what will happen to this quantity if the constraint is not satisfied that means my summation is not equal to one that is what means whether the constraint is not satisfied what will happen to this quantity it will be a nonzero quantity right fine then what will happen to my overall objective and i think we have made a mistake this should be plus i should add it right should be plus no it does not oh the lambda can be ok sorry so let me assume this is plus so what i am trying to do is that this is my objective function which i am trying to minimize i have added another quantity to it if this quantity is not equal to zero then i will not be the absolute minimum i will be at the minimum plus something right but if this quantity if the constraint is satisfied then this quantity will go to zero then am actually at the minimum of the function do you get this right so this is the function that i want to minimize i have added some quantity to it now that quantity is actually related to the constraint that i do not want to violate if i violate the constraint this is going to be non negative right so whatever minimum value i achieved i will be slightly higher than that because some nonnegative value has got added to it ok is that fine but if the constraint is satisfied then i can achieve the minimum value so that is roughly the intuition behind using this lagrangian multiplier it is a very crude intuition but there is of course a lot of math behind that but i am just giving you the intuition behind this which one student refer time four thousand, one hundred and thirty-nine yeah that is what you could adjust the lambda and ensure that it is not negatively ok so now now can you do the same thing can you equate this to zero can you take the derivative and equate to zero what will you get now this term will give you p i by q two as before oh sorry p two by q two as before plus lambda times yeah plus lambda times one ok fine so equal to zero so then what will you end up getting p two is equal to i think it is something wrong here now this should be minus p two by k so p two is equal to lambda times q two ok and then further actually you can show that lambda is going to be equal to one how can you show that your constant is fine so do you see how we will get lambda equal to one so what does it actually tell you then p two is equal to q two that means all in fact you can show that all p i\u2019s are equal to q i\u2019s that means the distribution p is equal to distribution q so this cross entropy term will be minimized when your true distribution or when your plated distribution is the same as the true distribution and hence it captures the difference between the two ok and that is exactly what we were interested in we were interested in a quantity which can allow us to capture the difference between the true difference between a true distribution and the predicted distribution so we have arrived with that quantity and that quantity is cross entropy so therefore for all our classification problems where we have this scenario that we are given the true distribution where all the masses focused on one of the labels and you are estimating a distribution where you could give non zero quantities to many of those and you want to find out how wrong your estimates were with respect to the true distribution you can use cross entropy as a measure for that right so now your loss function which you wanted to depend on the difference between p and q it can just be the cross entropy between p and q"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/33_0.wav", "duration": 68.0, "text": "welcome to lecture five of the course on deep learning and so today we look at some variants of gradient descent so we will just quickly do a recap of gradient descent and then look at some variants of it or some ways of improving it which is momentum based gradient descent nesterov of accelerated gradient descent stochastic gradient descent adagrad rmsprop and adam so just to set the context so we started with this gradient descent algorithm for a single sigmoid neuron and then we saw how to extend to network of neurons with back propagation so we realized that all we need is the gradients or the partial derivatives with respect to all the weights and biases once we compute that we can just use the gradient descent update rule now today what we are going to see is are there better update rules which lead to faster conversion or better performance in various ways so that is why we are going to look at all these different variants or methods of improving on gradient descent so that is the context"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/33_1.wav", "duration": 28.0, "text": "i will just quickly rush through so for most of the lecture i have borrowed ideas from the videos by ryan harris on visualize back propagation and some content is based on this course by andrej karpathy and others when i talk about some tips for learning rate and so on so you can just look at those also so we will just quickly rush through the first two modules which we have already done"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/33_2.wav", "duration": 6.0, "text": "which was we were interested in learning the weights and biases for this very toy network with just one input and one output and we started by doing something known as guesswork where we were just trying to adjust these weights and biases by hand"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/33_5.wav", "duration": 8.0, "text": "and we realized that its clearly not good and but we still try to do a very smart guess work where we were driven by this loss function which was telling us whether this guess the current guess is better than the previous guess or not and we just kept following our guess work and try to reach to some solution and for this toy network it was very easy to do that"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/33_7.wav", "duration": 21.0, "text": "and what we were actually doing is there is this error surface which exists which can be plotted for all possible values of w comma b and what we were trying to do with this guesswork is trying to find path over the error surface so that we enter into the better regions so red is bad blue is good the darker the shade of blue the better and this of course becomes intractable when you have many parameters and so on"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/33_8.wav", "duration": 10.0, "text": "so we wanted to have a better way of navigating the error surface so this is exactly what we were doing with the guesswork algorithm"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/33_9.wav", "duration": 7.0, "text": "so then this better way actually we realized that we could arrive at it from a very principled solution from starting from taylor series"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/33_10.wav", "duration": 3.0, "text": "and we went to this derivative where we finally came up with this rule that move in the direction opposite to the gradient"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/33_12.wav", "duration": 27.0, "text": "so that is the rule that we have been sticking to since then and we also along the way realize some of these things which we defined carefully which was what is what exactly this quantity means which is the partial derivative with respect to w evaluated at a particular weight comma bias configuration and because this is an iterative process you are at a certain value of weight and bias and you need to change it from there"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/33_13.wav", "duration": 242.0, "text": "and we then created an algorithm out of this and when we ran this we actually derived the full derivative and so on"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/33_14.wav", "duration": 8.0, "text": "now now you might say that this was only that special point again and i always get those questions so let us see what happens if you start from a different point"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/33_15.wav", "duration": 60.357, "text": "so now again the same gradient descent algorithm i am going to run but instead of starting at this point which was my random initialization i just happened to choose a very different random initialization which is here everyone sees that now let us see what happens what do you expect initially fast movement because the steep the slope is a bit steep now what would happen it will become slow because you have entered a gentle slope region and then again fast right so and then again it will become slow so see in this gentle region right the changes in w are so small that all your black points are actually indistinguishable from each other it is almost like a snakes body whereas in these steep slopes you can see a large change in the w you can see gaps between the values of w right so this is irrespective of where you start from gentle means slow movement steep means fast movement that is the basis"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/34_0.wav", "duration": 6.0, "text": "so we look at something known as contours"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/34_1.wav", "duration": 31.0, "text": "so now visualizing things in 3d can sometimes become a bit difficult especially for the person who is making the slides so we can can we do a 2d visualization of this traversal have i done this in the ml course no good can we do a 2d visualization of this traversal along the error surface so for that we need to understand something known as contours how many of you have looked at contour diagrams before how many of you know how to read them all of you know how to read them"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/34_2.wav", "duration": 173.0, "text": "so let us see now suppose this is what my error surface looks like and i have a single scalar variable so this is just a function of w for example and this is what my error surface looks like now what i am going to do is i am going to take horizontal slices on this error surface fine now can you tell me how this is going to look from the top sorry let me you should start answering before understand the question this is this error surface is actually so i was wrong in saying this is theta assume this is w comma b and you are just seeing the front view of the error surface what you are seeing here is just the front view this error surface is actually like a dementors hat so right so imagine that it is a hat place like this and you are just seeing the front view of this otherwise a top view does not make sense right so now i am going to slice this hat at two vertical positions and now you are looking at it from the top what are you going to see student ellipsis ellipsis everyone agrees with that"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/34_3.wav", "duration": 10.0, "text": "so i will just give you a couple of exercises and you have to tell me whether you understand this or not"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/34_4.wav", "duration": 260.0, "text": "so i have plotted a three d surface or two d i have what is this student refer time three hundred and fifty-four no student there is a contour there is a contour everything is not going to look like clean circles always right ok so this is a contour every line that you see here represents one cut along the vertical axis right that means the error is the same there now what you are seeing is a contour i want you to guess the three d surface from this you just guess it i mean just keep it to yourself fine the color is the same right blue is good red is bad so blue means the darker the shade of blue the lesser the value of the error the darker the shade of red the higher the value of the error ok i want you to imagine the three d surface if you can do that then i will be sure that you understand what how to read a contour how many if we can imagine this you can just say yes right i can never figure out whether you actually speak it so let me help you with the first one and then we will do a few more so let us start with the extremes right so let me see how to do this so this portion i also need to do it for the video ok so let me just do it here so this portion what do you think about the slope there very flattish why because this is the line that you see and the other line is not even in the figure right so it is basically very flat the slope is very gentle is it a low region or a high region high region fine ok now what is actually happening here what is the slope here student high very high that is why these two regions are very close to each other so from this high region what is happening suddenly there is a slope and you are going down and you know you are going down because you are reaching a blue region right ok now what is happening here student very flat very flat and this also flat but slightly upper than the lower guy is that fine now can you all imagine this ok and is this what you thought it is perfectly yes right is exactly what you thought ok just a minute so the orientation here has been changed a bit right so this portion actually corresponds to this portion are the two this is clear this portion corresponds to this portion right the just orientated fine so you start off this high plateau region which is here then you start going down go down and then you see a fold here right that is this fold so you went to a darker shade and then you came up to a slightly lighter shade the shades are ok guess the 3d surfaces how many if you want to play this forever now start with the extremes the bad guys the good guys the plateaus and the valleys and then see how do you go from the plateau to the valley ok tell me the corners first this plateau or valley student plateau plateau this plateau higher than this or lower than this student lower than this lower than this this student valley this towards the valley it is still between red and blue right it is not like right down there and what happens to all these guys all are very steep slows all converging down into the valley so can you perfectly imagine this and you will tell yes when i say when i show you the three d surface right again you need to reorient yourself so this corner here is this corner this corner here is this corner so we had these two plateaus at the top we had this slightly higher valley slightly lower valley and then all of them going into a very deep valley you see that everyone gets this how many if you have a problem with this if you have a problem with this you will just sleep off in the rest of the lecture so i want you all to understand this very carefully i do not mind repeating it how many of you understand this you understand the regions with gentle slope student yes the regions where you have a steep slope and you end up into that valley which is the valley here can you point it out fine ok so we will move ahead"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/34_5.wav", "duration": 13.0, "text": "so now we know what contour maps are and how to visualize them and so on right so now we will try to see the gradient a descent algorithm instead of running it on the 3d error surface we will try to run on this 2d contour map"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/34_6.wav", "duration": 135.872, "text": "so this is what i already showed you right i started from here and i showed you how it comes here or something like this right that was the gradient descent let me just erase this ok that is something like what the gradient descent algorithm now again you just need to reorient yourself so let us see this corner is this corner this corner is this corner and so on right so you get the reorientation right it just shifted now i am going to start my gradient descent algorithm from here from this point ok everyone see is that ok i am going to start from there and you have to help me and i am not going to just keep clicking you have to tell me what is going to happen so what will happen initially fast movement slow movement student slow movement slow movement right so i am running it one two three four five six seven eight it just keeps running very slowly now what will happen student fast fast ok now you see actually you can see the arrows these arrows are the quantity the magnitude of the movement right so earlier this movement was so small that you could not even see the arrows i have been drawing arrows right from the beginning but you could not see them at the beginning now you can see them right now what will happen student slow slow right so you see the exact same movement that i did on the three d surface now you can visualize it on the two d surface right and you can easily tell me where it will go fast where it will go slow right and where it will just keep moving very drag its feet and so on ok so this is where it starts dragging its feet and the same thing happened when we were in this region right so just you just make the connection that we are in the corresponding three d region there ok fine so we are moving very slow and it just keeps running so that is where we lend this module so we just revised gradient descent we saw that things are proportional to the gradient that is why gradient descent and the smaller the gradient the slower the movement the larger the gradient higher the movement gentle the slope student smaller smaller the gradient steeper the slope larger the gradient"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/35_0.wav", "duration": 9.0, "text": "in this module we will look at momentum based gradient descent"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/35_1.wav", "duration": 239.0, "text": "so what were the observations about gradient descent that it takes a lot of time to navigate regions having a gentle slope so what is the practical implication of this in practice why it what does this need to what does this mean right it takes more time so remember we had said this max iteration equal to one thousand now if you are initialization happens to be such that you are stuck in this large flat region then those one thousand iterations just keep moving around that flat region right you will not enter into one of the valleys and valleys is what you are interested in right because values is where you will have some minima for your function right so if you have a very gentle slope then for one thousand iterations you will keep moving around that gentle slope right that is why this has a practical implication now this was because the gradient in these regions were small can we do something better that is the question right so yes we can and we will take a look at momentum based gradient descent"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/35_2.wav", "duration": 159.0, "text": "so let us see what this means right so it basically means that in addition to the current step also look at the history there are three guys who earlier pointed you in the same direction so maybe this direction makes sense right so start accumulating that and move faster"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/35_3.wav", "duration": 125.0, "text": "so now this is the code for momentum based gradient descent i will just give you a minute to stare at the code and see if it makes sense so this much part is ok you are just computing the gradients with respect to all the points right and now we are keeping this running sum ok which is the previous gradients and the current gradient right and then you are just subtracting that running sum now this looking black curve that you see here that is gradient this this guy ok this black curve that you see here that is gradient descent when i have run it for around one hundred iterations now i am going to run momentum base gradient descent and each click is going to be one step ok and i want you to observe what happens ok so slowly a red curve will start appearing on the figure initially it will not be visible so do not worry there is nothing wrong with your eyesight one how many if you already see the red part i see it two three four five six no now you can see it as is nothing great about7 eight nine i want you to observe something here eleven twelve thirteen fourteen came back right so gradient descent i ran it four hundred iterations it was just stuck here right this was a point and i ran this for less than like around fifteen or twenty is what we counted right and so already entered into the valley so momentum base gradient descent is good you see that wicked smile on my face and you know it is a trick question so we are moving fast right"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/35_4.wav", "duration": 69.0, "text": "even in the regions where the slope was gentle right that is the beginning of the beginning of our trajectory right this was the gentle region even that i was very quickly able to navigate right within five to six steps i was away from that part right so even in the regions where the slope was gentle i was able to move fast but is moving fast always good so would there will be a situation where momentum would cause us to run fast ago same thing now instead of walking you are in a car you ask the person at the security whether i should go there he says yes go in the right direction you keep moving there someone else you keep accelerating what will happen eventually you will go fast phoenix market city then what will you do student take a take a u turn come back again while taking a u turn what will you do student refer time nine hundred and fifty-seven overshoot and come to the signal and then go back again right so you see this you will end up taking a lot of u turns so let us change the input data a bit and see what happens to momentum based gradient descent"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/35_5.wav", "duration": 213.0, "text": "so this is what my data looks like now so this is not what my data looks like this is what my error surface looks like so earlier we had this error surface something like a flying carpet now i have a very peculiar error surface this is again for the two parameter problem right w comma b that means i want to learn a sigmoid function where i have these two plateaus at the top the dark red regions that you see and then a very sharp valley can you tell me how i would have come up with this kind of an error surface what are the points that i would have chosen just hold on to that part so i have this kind of an error surface fine the error is high on either side of the valley now could momentum be detrimental in this case yes no maybe i do not care i do not care fine"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/35_6.wav", "duration": 270.263, "text": "so let us look at we will come back to three d now we look at a three d visualization and a very different interpretation of what is happening i really want you to understand what exactly is happening in this example which i had picked up right"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/36_0.wav", "duration": 6.0, "text": "let us look at nesterov accelerated gradient descent"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/36_1.wav", "duration": 25.0, "text": "so now we know that momentum based gradient descent is good at these gentle regions it moves really fast but we do not still do not like it because it has this problem of oscillations it has this problem that it overshoots its objective its goal and then it has to take a lot of u turns so can we do something about reducing this oscillation so the answer is always yes so let us look at nesterov accelerated gradient descent"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/36_2.wav", "duration": 53.0, "text": "so the idea here is very simple look before you leap ok now remember that this was the update rule for momentum based gradient descent ok and i will write it down again wt plus one is equal to wt minus gamma into update t minus one minus eta into the gradient at the current point so you see that actually i am taking two steps one is this step and then one more step and i could just this is one way of visualizing right that i move according to the history and then i move a bit more according to the current gradient so everyone sees that there is a two step movement happening here now can you think what could have been done look before you leap so we will see what we can do"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/36_3.wav", "duration": 78.0, "text": "so we know that we are going to move at least by this one and that is fixed we know that our history is telling us to move at least by this one and then we will move a bit more by the gradient so now can you think about it i am at least going to move this much what if i had some way of looking ahead and then do something at that point this is what you are saying of course i can verify it but i am sure it will become clear once i show the equations but i just want you to think about it a bit wait it is very simple it will become absolutely clear once i show you the answer but just think about it a bit so here is the answer it why not compute the gradients add this look ahead point right so you are again adding it in two steps minus the history and then minus the current gradient so take this value call it the look ahead point i know that i am going to move by this much so let me not compute the gradients at the current point let me move by this much then compute the gradients and see what happens at that point"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/36_4.wav", "duration": 103.0, "text": "so this is the equation right that first i move by that one step i had to make a two step movement so i will move by that one step right then i will compute the gradient at that position not at my current position right this was earlier gradient at point t now i have already moved a bit so i can compute the gradient there and then move in the direction of that gradient so you understood this that there is a two step movement right wt minus history minus the current gradient gradient computed at time step t ok now you know that you are already going to move by the history right so why not just move there and then compute a gradient at that point you are anyways made some movement you compute the gradient at that point and then decide which is the direction to move in right so that is what this look ahead value is i know it is still not clear to many of you and i am very confident it will become clear in the next five minutes we will show you one more visualization for this but this stay with stay with me for a while as long as you get the intuition i am fine i will move ahead and then i will explain it again in a different way this is fine ah that should become clear good that you asked that question ok so ask me again on the blank slide that i have and then i it should be complete so for right now let me just show you what will happen with the code and then i will again explain it with a different way"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/36_5.wav", "duration": 413.39, "text": "so this is what momentum based gradient descent it ok now let us see what nested or accelerated gradient descent will do again the code is simple you can just read it up and i have started executing you see this blue curve coming over there fine ok and now i keep running this now what will happen you see that all the u turns of the blue curve are inside the u turns of the red curve so the objective is being achieved at least empirically i have showed you that right its taking shorter u turns what is probably not clear to all of you is why is this happening is it clear to everyone why is this happening can everyone visualize that ok so let us see why this is happening i will give you an alternate explanation for this"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/37_0.wav", "duration": 10.0, "text": "now we look at stochastic and mini batch versions of these algorithms"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/37_1.wav", "duration": 5.0, "text": "so we will digress a bit actually we should have ended up somewhere else but i was just going to digress a bit"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/37_2.wav", "duration": 63.0, "text": "so this is the original gradient descent code that we had and i have highlighted something in this red box so notice that the algorithm actually goes over the entire data once before making an update it has going over this entire for loop which is over all the data points of course in this toy example i had only two data points but in i practice i will have many many data points i go over all the data points compute the derivatives and then make this one update student refer time fifty-seven because that is the right thing to do ok this was the exact formula that we painfully derived right that the gradient with respect to the loss function right which we had the summation i equal to one to n remember and the true derivative was a sum of the derivatives with respect to all the data points that is what we analytically derived and hence we are doing that it was that is the right thing to do not for any other purpose ok that is what it should always be right so that is the right thing to do because this is a true gradient and we actually derived it"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/37_3.wav", "duration": 68.0, "text": "and hence this was not an approximation so all the theoretical guarantees hold if i do this i know that now this is the true gradient or the true derivative and if i move in the direction opposite to the gradient everything falls in place because i proved it using taylor series but what is the flip side of this this is the right thing to do but what is the flip side if you have millions of point we will go over all these million points and make this one update now imagine the consequence when you are in a plateau region right even that momentum or whatever your movement in the plateau is going to be relatively smaller right you are going over these million points and making that tiny delta update right so imagine how much time it will take your algorithm to converge you get the problem so the algorithm will take a million calculations and then make one tiny update to your w ok this is going to be very slow can we do something better always right so let us take a look at stochastic gradient descent fine"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/37_4.wav", "duration": 43.0, "text": "so i have done a very subtle change to the code what is it do not tell me indentation but that is what i have done so you can tell me that so what is happening now for every data point i am making an update to my w values now the algorithm updates the parameters for every single data point if you have a million data points how many updates will be make in one pass over the data a million for every data point will make an update right so that slowness factor in what is known as batch gradient descent right batch gradient descent is when you look at the entire data and then make one update"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/37_5.wav", "duration": 218.0, "text": "what is the flip side what does this module titled stochastic gradient descent so what is the flip side these are not the true gradients the true gradient is summation over all the points now this is no longer the true grading this is just a point estimator this is just a approximation of the gradient right and stochastic because we are calculating the gradient based on a single data point right it is a sampling one data point and computing the gradient that this is what the entire population looks like right this is almost similar to tossing the coin once and saying that this is what the probability of heads is if it lands at heads then the probability is one otherwise its zero right you see the error you see the problem with that right as opposed to tossing the coin a thousand times and then deciding the probability is just tossing it once so this is always going to be a erroneous right this this is going to be bad so now there is no guarantee that each step will decrease the loss why because the guarantees were only when you are doing the right thing which was to compute the gradients over all the data points now there is no theoretical guarantees right because it is all stochastic now so it is possible that in a particular data point your loss might increase also the overall loss on the data with respect to that point it might decrease but the overall loss right so now let us see this algorithm in action and i want you to make certain observations about this so this is the code that i am going to run now so let us see"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/37_6.wav", "duration": 236.0, "text": "so we look at a mini batch version of this so what i am going to do is instead of so this code is actually for mini batch stochastic gradient descent it is a very minor alteration on the stochastic gradient descent i will just let you stare at it for a minute or so what i am doing here is i am instead of doing it for every point i am waiting for a certain number of points and then making the update right that is what i am doing here now for this i have kept k equal to two what does that mean i look at two points compute the derivatives with respect to them and then make an update for two points at a time what do you expect no what do you expect with respect to this code"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/37_7.wav", "duration": 9.0, "text": "so similarly we can have the stochastic versions of momentum based gradient descent and nesterov accelerated gradient descent"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/37_8.wav", "duration": 153.0, "text": "so these are just the codes it is very easy to see what is happening here again basically this is just an indentation right so if you look at the difference between the two codes i have just indented it inside that means i am making these updates for every data point right and same thing you could do for nesterov also"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/37_9.wav", "duration": 5.662, "text": "you see that black curve at the top and both of these are faster than them both of them all three have run for the same number of iterations after sixty steps you see what happens to stochastic gradient descent and what happens to nag and momentum basically gradient descent and of course you can have the mini batch versions of momentum and nag also"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/38_0.wav", "duration": 7.0, "text": "tips for adjusting the learning rate and the momentum"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/38_1.wav", "duration": 7.0, "text": "so before moving on to these slightly advanced optimization algorithms we will revisit the problem of learning rate in gradient descent"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/38_2.wav", "duration": 33.0, "text": "so one could have argued that we could have solved this problem of this slow movement on the gentle slope by increasing the learning rate remember that we have this eta and we deliberately chose to be conservative that we will take a small value for the eta but what if i just blow up the eta i could just take a very large eta what would happen it will overshoot right so what will happen is i will see what happens when i take eta equal to ten ok so so i will see what happens when i take eta equal to ten"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/38_3.wav", "duration": 494.0, "text": "so this is step1 step two step three its moving very fast on the regions where the slope is gentle but it also moves very fast much faster on the regions where the slope was already steep so when the gradient was actually high you ended up blowing it further by multiplying it with the eta which is ten so it is again going to have this effect that you will move much faster in the steeper regions and again you will see these oscillations because you will overshoot your objective does that make sense right so it is not that you can always choose a high eta and get away with it so what do you actually want what is your wish list regulate theta you want a adaptive eta right that it somehow figures out that i am on a gentle slope so i should move slowly i should move fast and i am now on a very fast loop so i should move slow so this having this one eta is not working for every point on the error surface right for everywhere on the error surface is that clear ok so ok so we will see such algorithms soon where we try to adjust this learning rate"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/38_4.wav", "duration": 218.693, "text": "now tips for the momentum can you make sense of this you just stare at it it looking just come back ok let us see what happens at t equal to zero this becomes zero student log one log one is zero this is two raise to minus one minus zero which is just two raise to minus one which is five so what is your mu t at t equal to five does that make sense is it fine with everyone or is it confusing no ok mu max is typically this let us assume mu max now what happens at time step two hundred and fifty this is two hundred and fifty by two hundred and fifty so this becomes one one plus one is two the best thing that you learn in this course log of two is one so this become two raise to student two raise to minus two minus two which is twenty-five so what is this student seventy-five seventy-five let us do one more i had t equal to seven hundred and fifty one minus one by eight so that is what is going to be right ok so then what is happening as my time steps are increasing what is happening to what is happening i am having more and more faith in the history or the current gradient what am i increasing actually i have made a mistake actually this is mu is gamma there is not we did not use mu anyway what you guys just went along so this is gamma actually right that was a momentum term that we had so as a number of time steps is increasing my gamma is increasing that means i am having more and more faith in my student refer time one thousand, one hundred and forty-nine no history learning rate is eta momentum is gamma so its gamma into update t minus one and eta into gradient at the current time step right and here gamma is actually equal to mu is there any more confusion that i can add so when i say gamma i mean mu and so that is how it is so as i am increasing the number of time steps i have more and more faith in the history that means i do not want to now get distracted by this one update which i am making right i want to go by the history and i am not increasing this gamma or mu indefinitely i am capping it by a max right max i will have this much faith which is nine hundred and ninety-nine in the history does that make sense this is again just a heuristic do not worry too much about it so that is how it is"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/39_0.wav", "duration": 154.0, "text": "so we were looking at these different variants of gradient descent we saw that gradient descent has this problem that it finds it difficult to navigate the gentle slopes so we came up with tricks on momentum based gradient descent and also nesterov accelerated gradient descent the trick in momentum was that if lot of your history is telling you to move in a direction then just continue to gain momentum in that direction so instead of just updating based on the current gradient you also update based on the history right and there we saw that this is always going to be a problem that you will end up taking uturns and we had this analogy of how you look for directions and you just overshoot your destination and have to come back and take a uturn and come back and so on so to prevent that we realize that the update done by momentum base gradient descent is two step update you actually the first step is based on the history and then another step based on the gradient at the current time step right so then instead of doing these two steps at one go why not just update based on the history see what the gradient that tells you and then we saw this nice figure i hope it was nice and where you saw that if you look ahead point then you will be immediately corrected with respect to your errors so that was about nag and momentum then we saw the stochastic versions of these algorithms where we realize that if we do the batch version then you go over a million points and then make only one update which could be very slow in cases where you have large data so we then decided to the stochastic version where we just update for every point that again had these oscillations because we were taking greedy decisions we were just relying on one point to tell us which was the right direction to go on and you saw that these esteem has become better as you increase the value of this k so k equal to one is the most stochastic version and then k equal to two you get the mini batch version and then you could just have different values of k so that you have more reliable estimates of the gradients and in the limit if you have the entire data then you are just doing the full batch gradient descent right this is the vanilla gradient descent anything else did we cover then we had some tips on the learning rate and the momentum these are again heuristic i gave you some ideas and you could try these in your back propagation assignment and see which one works better for you you could see you have any peculiar observations while implement the back propagation assignment so now there are a few more things left in this lecture so i will start with the line search first so this is one more thing before you move on to some more interesting algorithms which are the current state of the art and lot of deep learning solutions"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/39_1.wav", "duration": 365.97, "text": "so most people that you read would look at would have algorithms that we will see after ten minutes"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/4_0.wav", "duration": 47.0, "text": "so around one thousand, nine hundred and fifty-nine hubel and wiesel did this famous experiment they are still i think you could see some videos of it on youtube where there is this cat and there was a screen in front of it and on the screen there were these lines being displayed at different locations and in different orientations so slanted horizontal vertical and so on and there are some electrodes fitted to the cat and they were measuring trying to measure that which parts of brain actually respond to different visual stimuli let us say if you show it stimulus at a certain location does the different part of the brain fire and so on so and one of the things of outcomes of the study was that that different neurons in brain fire to only different types of stimuli it is not that all neurons in brain always fire to any kind of visual stimuli that you give to them"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/4_1.wav", "duration": 18.0, "text": "so this is essentially roughly the idea behind convolutional neural networks starting from something known as neocognitron which was proposed way back in one thousand, nine hundred and eighty you could think of it as a very primitive convolutional neural network i am sure that most of you have now read about or heard about convolutional neural networks but something very similar to it was proposed way back in one thousand, nine hundred and eighty"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/4_2.wav", "duration": 43.0, "text": "and what we know as the modern convolutional neural networks maybe i think yan li kun is someone who proposed them way back in one thousand, nine hundred and eighty-nine and he was interested in using them for the task of handwritten digit recognition and this was again in the context of postal delivery services so lot of pin codes get written or phone numbers get written on the postcards and there was a requirement to read them automatically so that they can be the letters or postcards can be separated into different categories according to the postcard according to the postal code and so on right so or the pin code so that is where this interest was there and one thousand, nine hundred and eighty-nine was when this convolutional neural networks were first proposed or used for this task"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/4_3.wav", "duration": 30.0, "text": "and then over the years several improvements were done to that and in one thousand, nine hundred and ninety-eight this now how famous data set the mnist data set which is used for teaching deep neural networks courses or even for initial experiments with various neural network based networks this is one of the popular data sets which is used in this field and this was again released way back in one thousand, nine hundred and ninety-eight and even today even for my course i use it for various assignments and so on"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/4_4.wav", "duration": 12.312, "text": "so it is interesting that an algorithm which was inspired by an experiment on cats is today used to detect cats in videos of course among other various other things is just i am just jokingly saying this"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/40_0.wav", "duration": 21.0, "text": "in this module we look at gradient descent with adaptive learning rate so first we will see motivation or intuition for why we need this and once you get the motivation i believe the rest should be straightforward"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/40_1.wav", "duration": 1048.0, "text": "so far what we have been doing is please pay attention on this slide i need to define some notations and you should not get confused with that so far we have been dealing with the situation where we had just one feature which was x and one weight corresponding to it which was w and one bias which corresponded always on input right now we are going to look at the situation where we have more than one inputs that means earlier we were basing our predictions only based on the director and now we are the director actor genre imdb ratings and so on so here x one x two x three x four these are four different features or four different inputs that i have and this is not x square just i know it is obvious but i am just making it clear right so this is x one x two x three x four ok it is not probably the best choice of notation but i will just stick to that so now each of these has a corresponding w one w two w three w four ok and this is how your decision looks like it is the dot product between the weight vector and the input vector ok this is how i am going to decide and that is a single sigmoid neuron again now given a single point xy do i need to again go through this computation sorry w p oh sorry ok i will just erase this so this w is actually the vector w so it includes w one w two w three w four and i am trying to take the derivative with one element of that vector do i need to show you how to compute this have you seen this before can you tell me i will show you the derivative with respect to w one can you tell me it will be a product of some terms can you tell me what is the last term going to be"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/40_2.wav", "duration": 115.0, "text": "now i just want to make sure that you are not so aggressive so what happens because of the aggressive killing is the frequent parameters they start receiving fewer updates now this is what rmsprop does i want you to stare at this for a minute assume that beta is going to be something which is greater than ninety or ninety-five or something and try to make sense of what is happening try to imagine what is vt is going to look like in terms of grad w zero grad w one and so on to start from v one and see what happens what was v one earlier and what it is going to be now ok but it still grows my magnitude when i am still adding stuff so how does it help me in not blowing of the denominators so yeah i think you most of you get so again this is the trick is basically you are using this exponentially exponential moving average so even at the first step earlier i was doing grad w t square now actually doing five into grad w t square oh sorry grad w one square right so that is what my v one is going to be now what is my v two going to be it is going to be ninety-five into five grad w one square plus grad w two square right so this quantity is even shrinking further and at each step this is going to keep a five ok and you see now at each step this is going to get multiplied by this quantity and shrink further so now i am not aggressively growing the denominator i am not considering the full gradient but only a fraction of it and in fact a very small multiple of it so i am still accumulating the history but i am not being very aggressive while doing that right so you understand this everyone gets this"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/40_3.wav", "duration": 325.0, "text": "so now let us see if we run what would happen any guesses ok so initially now this is i think a brown curve it is already there but you can see it so i will keep running it and at some point it will diverge from the green curve yeah do you see that now i have reached its destination right so at the point where the b learning rate the learning rate for b was getting killed in this case that does not happen because you have prevented the denominator from growing very large actually multiplied by its small values so that it does not grow very fast so adagrad got stuck when it was close to convergence because the learning rate was killed and it was no longer able to move in a direction of b but for rmsprop it overcomes this problem by not growing the denominator very aggressively ok now can you think of any further modifications there is everything that you learned so far and my everything yeah yeah i am not very sure why that i agree that i am also bit surprised that it completely overlaps with it i checked it and that is how it turns out to be and guessing it is an artifact of the artificial data that i have created so it is trying to say is actually making sense that it should not overlap so much right initially it should slightly be biased towards b and then probably that is what you are trying to say right but i told it just an artifact of this data that i have but what matters is from as going to say illusion but from the illustration is that it actually does not kill the learning rate"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/40_4.wav", "duration": 897.709, "text": "it is a similar set of equations for bt"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/41_1.wav", "duration": 293.0, "text": "so in this video we will try to look at an explanation for why we need bias correction in adam or in other words i want to explain why do i do this particular step why did i take m t and v t as it is but why did i do this particular step which i called as the bias correction step"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/41_2.wav", "duration": 22.0, "text": "so in general m t we can write it as one minus beta as i equal to one to t b beta t beta raised to t minus i into g i right so this three is here i have just replaced them by t s right you can just verify that this is from you can just generalize from the third entry to the t\u2019th entry"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/41_3.wav", "duration": 13.0, "text": "so now let us see we have the following expression we have simplified the expression for m t and written it more compactly but what we were eventually interested in the expected value of m t right we wanted to show that certain things holds for the expected value of m t"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/41_4.wav", "duration": 240.752, "text": "so you just take expectation on both sides so this is what we will get ok now one minus beta is of course a constant so i can move it outside the expectation so then i get an expectation of a sum now the expectation of a sum is the same as the sum of expectations so i can write it as a sum of expectations ok now again beta is a constant so i can take it outside the expect expectation so what i will be left with is beta raise to t minus i outside and expectation of g i right so this is actually expectation of g one when i equal to one then expectation of g two expectation of g three and so on now we will make an assumption that all these gi\u2019s that means the gradient at time step one the gradient at time step two the gradient as time step three and so on they all come from the same distribution ok we are going to make that assumption so let us try to understand the implication of that right so let us say this was a distribution from which g one came right suppose i am dealing with a scalar quantity and maybe this was the distribution from which g one came now g two could have come from a different distribution g three could have come from a different distribution and if that was the case then expectation of g one would be different from the expectation of g two and so on so what we have assumed to it will make things simple for us is that g one g two g three any g i comes from the same distribution and hence you can say that the expectation of all these gi\u2019s is going to be just the expectation of g that is this one single distribution from these which these entries come this of course a very strong assumption but we are going to live with this assumption"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/42_0.wav", "duration": 164.0, "text": "so this lecture actually is a bit of a digression and it is supposed to cover some of the basics that we need for various sections of the course so it is very important that you understand some concepts for linear algebra specifically eigenvalues eigenvectors and in particular today we will do principal component analysis and the reason that i do it is there is an very neat relation of pca and to autoencoders an autoencoder is something that well cover in the course it is a part of any deep neural network course and singular value decomposition is something that we using when we learn word vectors the word vector is again something very important i can just i can do the non svd version of it where i just talk about what word to wick is but that will not give you the same probably not the same interpretation as if you start from svd and then reach word vectors right so that is why i am covering these basics so how many of you know eigenvalues and eigenvectors very embarrassing question how many of you absolutely hate eigenvalues and eigenvectors so let us see if we can change that today i mean on the positive side"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/42_1.wav", "duration": 56.0, "text": "and that is exactly what eigen vectors do it right they refused to change their part they tell the matrix you can hit me as many times as you want probably you can increase my you could probably slow me down a bit or push me ahead or something but i am not going to stray off from your path right so that is what eigenvalue eigenvectors do so here is a matrix which is a villain and here is an eigenvector which is our hero and now when this matrix hits this eigenvector it refuses to stray from it is part right it says i will move forward i will move back whatever but i will not change my direction ok i will just stay honest to what i am and these vectors are called the eigenvectors i am more formally you can write it as ax is equal to lambda x right so that means the direction remains the same only the scale changes it will either get slowed down or it will get boosted up right so the magnitude would change but the direction remains the same"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/42_2.wav", "duration": 222.0, "text": "now what is so special about eigenvectors like why are why is it that they are always in the lime light i know the any course that you do invariably touch eigenvectors or eigenvalues at some point in that course right where be it machine learning image processing whatever you do you always speech everything that you do you will always have eigenvectors and eigenvalues why is it so well it is turns out that several properties of matrices can actually be explained away by looking at their eigenvalues so if i look at a matrix i would probably not be able to comment much on it but if you tell me something about the eigenvalues i can see a lot of things about of it and there is an entire field on this way this entire spectral graph theory which looks at properties of laplacian matrices and come in something on the properties of the graph and so on right and that is just an example which we do not care about but what we care about in this course there are a few things that we care about with respect to eigenvalues and eigenvector and that is what i am going to focus on right so that is what this lecture is going to be out and i will take two specific cases which are very important for us to understand certain concepts later on so i will start with the first one"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/42_3.wav", "duration": 586.222, "text": "and now this though a very toyish example can you relate it to many things in real life or many things that you will take in decision making right that you are so even if you are playing a game for example and even if you are playing atari games or something you are in a certain state based on some action that will take will move to a different state and so on right so these things happen in various real world applications right there is a certain state for example even in stock market prediction you are at a certain value of fish stock it might change to a different value right and these values you could just say them as high low or neutral that i am not going into the actual numbers today the stock value is high it does it possibility that it will transition to something low and so on right so these kind of state transition diagrams occur in various real world examples now this is a problem for the two restaurant owners right why is this a problem for the two restaurant owners they do not know how much food to make but every day the number of customers is changing right but is the number of customers actually changing will the system eventually reach a steady state will it is it obvious that it will reach a steady state or maybe it will not even reaches steady but the way i describe it i do not see why it should reach a steady state right you have some people here they go there come back go there and so on the only thing which i have assumed is that the transition matrix which was the matrix m is constant across all the time steps right so every day it is at the same priorities by which things are changed right so what is your guess if i were to ask you to take a guess ok let us see how many of you think and it is there is no correct answer here at this point so just tell me how many of you think it will reach a steady state how many of you think it will keep changing and why is the sum never equal to one ok so fine so it turns out that they will right and let us see how"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/43_0.wav", "duration": 17.0, "text": "now from here on we will go on to something even more basic we will start defining some basic definitions from linear algebra and these are again important for something that i need in the next lecture so let us start with this"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/43_1.wav", "duration": 6.0, "text": "i mean in the process we all just see why the eigenvectors are important for us in this course"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/43_2.wav", "duration": 62.0, "text": "so how many of you know what a basis is so a set of vectors belonging to r n is called a basis if they are linearly independent right and every vector in r n can be expressed as a linear combination of these vectors so a set of n vectors v1 to vn is linearly independent if no vector in the set can be expressed as a linear combination of the remaining n minus one vector so a more weird we are stating it that so that everyone get confuse is that if you take this linear combination the only solution to this is all the ci\u2019s is equal to zero and that make perfect sense right that is that same as that linear combination linear independence and all that thus is make sense to everyone ok so what does linear independence mean that any vector from this set cannot be expressed as the linear combination of the other set other vectors in the set and a more formal way of saying that is this everyone gets this what is linear independence"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/43_3.wav", "duration": 37.0, "text": "now let us consider some very stupid examples again the space r two and we consider these two vectors one zero and zero one are they linearly independent yes ok they cannot be expressed as a multiple of each other right now any vector ab belonging to r square can be expressed as a linear combination of these two vectors ok and x and y are linearly independent the only solution is c one x plus oh sorry c one x plus c two y is c one and y equal to zero what about if i move to r three one zero zero zero one zero and zero zero one so x y and z axis right are the unit vector"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/43_4.wav", "duration": 26.0, "text": "so in that x and y turns to be unit vectors in the direction of the coordinate axis and we are used to representing every point in r two as a linear combination of these two vector is that exactly what i what we do so when we say that i have a point two comma three i am actually telling you that the point is two one zero plus three zero one right i am expressing at are the linear combination of the coordinate axis"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/43_5.wav", "duration": 31.0, "text": "but now this nothing sacrosanct about x and y right i could have chosen just about any other axis so in particular we could have chosen this as our basis are these two vectors linearly independent can any vector and r two be expressed as a linear combination of these two vectors sure so i give you a vector a b how do you going to express it as a linear combination of these two vectors so you will do it this way right how will you find that values are the x one and x two so other linear system of linear equations right"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/43_6.wav", "duration": 20.0, "text": "so this is what you will do i know all are good in doing this and what do we actually do when we do this what is the algorithm that we use how do we solve this what is the algorithm that you use solving this student gaussian elimination gaussian elimination right in two variables of course we do not call it an algorithm that is what we did in eight standard or something but when we come to engineering we call it gaussian elimination right so the same algorithm"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/43_7.wav", "duration": 279.0, "text": "so in general given a set of linearly independent vectors we can express any vector that belonging to rn as a linear combination of these vectors right i can say z is equal to alpha one u one plus alpha two u two and so on given alpha one to alpha n are linearly independent ok so that means any vector in rn can be expressed using these vectors which form the basis of rn does that make sense that is why call the basis vector because anything else these are the fundamental vectors using these anything else can be expressed in that space it is that clear so this is how it will be how do i write this in matrix notation a there are lot of these and these thing i do not really understand what you mean by that yeah good so this is what you mean so that we writing same in matrix notation and now this is again a dash a system of linear equation there was a lot of space to fill and one dash good so system of linear equation and again you can solve them using student gaussian elimination gaussian elimination what is the complexity of gaussian elimination let us see options right n n square n cube fl n cube right the gaussian elimination the complexity is o n cube right and i am not doing all this just to the sake of time pass i have a point of make which i will make on the next slide right so now this was for any basis that means if you have any n linear independent vectors now i will consider a special basis where instead of n linearly independent vectors in addition these vectors are also orthogonal ok orthogonal vectors are linearly independent ok so a set of orthogonal vectors are linearly independent but the converse is not all this right"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/43_8.wav", "duration": 103.0, "text": "so an orthogonal basis is the more convenient basis that you can hope for that is the point which i wanted to have you are convinced about that"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/43_9.wav", "duration": 55.989, "text": "so that is how i connect the parts which was about the eigenvectors to the second part which was about basis and why would we want to do this and we already we had a coordinate axis that is the very good basis one zero zero zero zero one zero zero one and n dimension similarly so why should i want to use the different basis i have said that eigenvectors is a very convenient basis but why do i care about it i already have a very very convenient basis which is just these one or two vectors are along these directions right so why do i care about a different basis i understand that i that is there somewhere but something more than that that is one advantage which i will talk about what else more interesting ok in what sense i love the power which comes with my job right that you give a right answer and still i can embarrass you know so that is correct actually"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/44_0.wav", "duration": 34.0, "text": "lecture \u2013 six in this module we will study eigenvalue decomposition so the answer to that was actually which i was hoping all of you will give because all of you have done two prerequisite which is linear algebra and machine learning both of them teach you principal component analysis so i was hoping that you will give that answer now can you give that answer he already of course gave that answer is that make sense so we relate it to that so but before going to principle component analysis we look at eigen value decomposition"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/44_1.wav", "duration": 478.0, "text": "this is very straightforward so let u1 to un be the eigenvectors of a matrix a and let lambda one to lambda n be the corresponding eigenvalues now i am going to construct a matrix u such that the columns of u are these vectors u1 to un is that fine what u looks like and now i am going to do this product i am taking a the product of the matrix a with the product of with the matrix u where u is this right it is the all the eigen vectors tagged one after the other is this fine the next step i am just pushing the matrix inside if you know the four different ways of multiplying a matrix you will know that this is correct or else for now just thing that you can just push the matrix inside now what is this i can replace them by the lambda one u one lambda two because a u one is equal to lambda one u one by definition ok now can you write this again as a product of two matrices one is of course the matrix u and the other is student diagonal diagonal so the diagonal matrix will come first or the matrix u will come first how many if you say u will come first how many if you say the diagonal matrix will come first the sum is never one ok so it is going to be like this ok and you can write this as u lambda so u is again the vector the matrix containing the eigenvectors of a and lambda is a diagonal matrix where every diagonally element is a corresponding eigen value"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/44_2.wav", "duration": 4.0, "text": "so there is a proof for that i will not go over the proof you can take a look at it at your own leisure"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/44_3.wav", "duration": 28.48, "text": "so what has been the story so far the story has been that the eigenvectors corresponding to different eigen values are linearly independent if you are dealing with the square symmetric matrix which is something that we will deal with soon then things are even more convenient because the eigen vectors are actually orthogonal ok and they form a very convenient basis and now we are going to put this to use when we talk about principal component"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/45_0.wav", "duration": 15.0, "text": "so in this module we will talk about principle component analysis and it is different interpretations in this model we will look at one interpretation and then in the rest of the module some other interpretations"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/45_1.wav", "duration": 5.0, "text": "so the story i add is going to be this we will talk about pca and it is interpretations ok"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/45_2.wav", "duration": 35.0, "text": "so now let us try to motivate pca first consider the following data ok in what dimension is this data student two dimension two dimensions it is r two ok and each point here is represented as it is x coordinate and using it is x coordinate and it is y coordinate ok now it means that were using x and y as the basis right that is clear that is the standard way that you would do any data point you will just represent using that basis now what if we choose a different basis let me give you one basis and then let me ask you some questions on this"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/45_3.wav", "duration": 740.0, "text": "suppose we chose this basis so in the previous modules we made a case for the x and y coordinate axis there is nothing sacrosanct about it you could use any basis the only condition on the basis that the vector should be linearly independent and in fact if they are orthogonal it is even better right so now i have given you a different basis now what do you make any observation here so they have all the points here have a very small component along the u two axis right so now this so far this point right if i consider at this point then this is the component along the u one axis so that is it is u one coordinate as akin to the x coordinate and this is it is u two coordinate akin to the y coordinate is a are the arrows clear here so that means there u two coordinate is very small and it is also very small for all the data points right so it is almost as if there is some noise there it is all within some epsilon now so it seems that the data which were actually represented in r two can actually be represented in r one by getting rid of this noisy dimension right so if you had chosen a different basis you realize that with just one dimension you could have captured everything that was there in the data and the other dimension was just adding noise it was redundant there is hardly any information there"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/45_4.wav", "duration": 46.0, "text": "so now let us see what this means for one of the dimensions this is my data point xi which i want to transform ok for one of the dimensions i just had to take the dot product with that dimension and this will give me how many values one value that means the coordinate along p one i want to do it for all the n of them i can write it as this vector matrix multiplication right what is the dimension of this n cross one how many if you get that ok so this oh not many why student refer time one thousand, three hundred and fifty-five one cross n fine that is fine yeah how many of you get this ok fine yeah so this will give me all the n alphas is that clear for this data point so it will give me alpha i one to alpha i is it"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/45_5.wav", "duration": 58.0, "text": "now i want to do this for the entire data right so i have done it for x one i also want it to be done for x two and all the way up to x m for each of these i would have such an operation where i have a vector multiplied by this matrix if i just stack all these vectors i get back my matrix x and the whole operation i can write as x into p ok is that clear to everyone ok what is the dimension of x into p student m cross n m cross student n n right so for all the m data points i have alpha 1to alpha n is that clear anyone who does not understand this so x hat is the matrix of the transformed points is that clear i have now the new coordinates instead of the original coordinates according to the coordinate axis i have the new coordinates in this matrix"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/45_6.wav", "duration": 72.0, "text": "now i will just go through some very simple theorems or rather results and i will not prove them you can prove them on your own or other proof is there in the slides we can look at it later on right so if x is a matrix such that it columns have zero mean and if x hat is equal to xp then the columns of x hat will also have zero mean is this obvious to most of you not really is it how many of you think it is obvious ok then let me just go over the proof so for any matrix a one transpose a right so that means you have this vector this is a vector or a matrix yeah this is a vector right so i have a vector of n one so one this is nothing but a vector of n 1s so what is this product actually going to give me it will give me a vector containing n elements what is each element student sum of that column sum of that column right is this fine ok this is very obvious to see from if i have this suppose i have two three one and three six seven ok and then of course the corresponding"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/45_7.wav", "duration": 45.0, "text": "so if i do this multiplication i will get a two dimensional output which would be just seven and sixteen right so that is just the sum of that column student refer time one thousand, six hundred and thirty-three"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/45_8.wav", "duration": 484.62, "text": "now if x is a matrix whose columns are zero mean then a matrix sigma which i am going to call as a covariance matrix which is given by this is actually the covariance matrix how many of you agree with this how many of you have seen the covariance matrix before so all of you agree that this is the covariance matrix if you do not please raise your hands if you do not you will not understand the rest of the stuff now you have to be given the right incentives so let us see be the covariance matrix of x now what is the covariance matrix actually first of all tell me that if i say that i have an n cross n matrix x"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/46_0.wav", "duration": 7.0, "text": "so that is what we look at in the second interpretation of pca right"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/46_1.wav", "duration": 172.0, "text": "so again we have the same setup that given n are linearly independent for n orthogonal vectors we can represent x i exactly as a linear combination of these vectors what do i mean by exactly perfect ok if you actually describe the whole things in words ok so that is exactly what i mean right so you are going to write x i as alpha one i into p one plus alpha two i into p two and so on and when you do the summation on the lhs on the rhs you just get back the lhs when you do the summation on the right hand side you get back the left hand side so that means it can exactly be represented when you use all the n eigenvectors now if i start chopping of stuff what will happen student refer time one hundred and four it will just be an approximation ok now we this is what i meant and this is this the equation holds that means this is exact and we know how to find the alpha is because p js are conveniently orthonormal so we know how to find that easily ok now what if we consider only the top k dimensions what is going to happen there is going to be some error in the reconstruction i am not capturing all the information in my original data but there is some error which i am not being able to capture and i made a conscious decision that that error is not important i am willing to let it go hence i want to represent the data using fewer dimensions ok so this is exactly what you do in pca when you take the top k dimensions is this fine ok so now we want to select pi\u2019s such that we minimize the reconstructed error ok and this is again erratic actually we should try to write it as x i minus x since these are vectors and the square of vectors would just meet this right"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/46_2.wav", "duration": 503.0, "text": "so now what is x i actually the real point right the correct point which can be obtained by the full reconstruction if you consider all the n dimensions what is x i hat just an approximation where you are considering only the k dimensions remember that each of these quantities is a vector fine ok now what is happening here let me just try to say this so let me just do this way so this is your original x and you are actually writing it as a linear combination of your p\u2019s somewhere you will have alpha k pk and then all the way up to p n so this is p k alpha n ok now what is this full thing this is x and what is this x hat ok you see the picture what is the equation trying to tell you ok now what is the difference between these two then these guys right if i want to take difference between x and x hat everyone gets that it is the remaining term say that means alpha k plus one into p k plus one up to alpha n into p n is that clear"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/46_3.wav", "duration": 125.0, "text": "so what we have here is something of this form ok"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/46_4.wav", "duration": 6.0, "text": "now so the key idea here is this right minimize the error in reconstructing x i after projecting the data onto the new basis"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/46_5.wav", "duration": 173.635, "text": "so let us take an example and we will work with our toy example again"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/47_0.wav", "duration": 8.0, "text": "now you go to the third interpretation where we will try to say something about the variance"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/47_1.wav", "duration": 22.0, "text": "so we started off with the following the wish list that we wanted low covariance and we wanted high variance so far we have paid attention to the covariance because everything was revolving around this covariance matrix in both the solutions but what about variance have we achieved the goal with respect to high variance"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/47_2.wav", "duration": 164.0, "text": "so let us see so what is the i\u2019th dimension of the transformed data it is this you take your data and project it onto the i\u2019th dimension right so x hat is equal to x into pi now what is the variance along this dimension how do you compute the variance so this is my projected data and let me just call it x hat i so this is the i\u2019th column after projection is that fine everyone is ok with this now for this i\u2019th column i want to compute the variance how will i do that remember that the data is zero mean what is the formula actually it is going to be x hat i minus mu i into x hat i minus mu i right but mu i is zero so it just turns out to be the dot product dot product of x i hat with itself ok and of course divided by m is this fine"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/47_3.wav", "duration": 7.406, "text": "so this is the quick summary the covariance between the new dimensions you can leave actually those you can just read it later on"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/48_1.wav", "duration": 89.229, "text": "a quick summary we have seen three different interpretations of pca and eigenvectors played a very crucial role in that and the other thing which played a crucial role was the covariance matrix of the original data and with these three different interpretations what we realize is that the solution that we get or the transform data that we get projecting the original data on to the on to a basis consisting of eigenvectors ensures that there is high variance across the new dimensions and we can ignore of the bottom top n sorry bottom n minus k dimensions along with these variance is not high this also ensures that the error in reconstructing the data by ignoring this dimensions is minimized right it is a lowest possible error and it also ensures that the covariance between your retained dimensions is zero because we are able to diagonalize the covariance matrix of the transformed data so that is what we had so now if you think of it right just to connect it two things that we need later on for auto encoder right we are trying to learn a new representation for the data right and we are trying to also compress the data and we want this compression to be such that it is as lossless as possible right we are going from n dimensions to k dimensions and still we want to retain the essence of the data and do not want to lose out much of the information in the data ok so that is essentially what pca is doing now let us see this in practice"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/49_0.wav", "duration": 16.0, "text": "so we will in this module we will look at practical example where pca is used and i just like to give you a flavor of why all this is important right why do we need to throw away some dimensions and then how does it practically help"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/49_1.wav", "duration": 138.0, "text": "so consider that we are given a large number of human images right so this is like some faces data set a database that says one of the intelligent agency someone is maintaining one of the government agency or may be aadhar data bases or something like that ok now each image here is one hundred cross one hundred that means it is ten k dimensions right it is a very high dimensional data ok and your job is to actually store this on to do some database for a large amount of the population right because you are collecting these images from various people so now we would like to represent and store this data using much fewer dimensions right and you would be really ambitious that if you want to store that more than fifty to two hundred dimensions right so you see the compression that i am looking at you have ten k which is a big storage problem for me and i want to just bringing out to fifty to two hundred but i have know that this is crucial data right i do not want to store information which is not able to distinguish these faces i was still be able to reconstruct the faces from this information right do well i mean minimum error reconstruction from this and that is exactly what pcas are allowing us to do right so now we construct a matrix of m cross ten k what is m student refer time one hundred and forty-six the numbers of samples you have the numbers of data points that we have and each of this is of dimensions ten k ok so this is what matrix what do we call this matrix oh it is already given right it is the x matrix the data matrix that we always have now each row of the matrix corresponds to one image and each image is represented using ten k dimensions just to reiterate now let us see so now what would you do this is the original data i want a dimensionally reduced data right you want store this ah is the mike working you want this data to be represented by a fewer dimensions so what is your solution do pca so what will you do x transpose x right and i did not get my slide refer time two hundred and forty-three"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/49_2.wav", "duration": 536.882, "text": "so we retain the top one hundred dimensions corresponding to the top one hundred eigenvectors of x transpose x right so basically we do a pca find the one hundred find all the eigenvectors of x transpose x and then just retain the top one hundred of those now what is the dimension of each of these eigenvectors should be straight forward take your time it is early morning student refer time three hundred and ten ten k right so now can you think of a physical interpretation of this so what are you trying to do you are trying to store faces and now you have come up with these dimensions no sorry we have come up with these basis vector which is eigen vectors and each of them is also ten k which is as same as dimensions of your faces can you think of a physical interpretation of what is happening here none of went you through the slide except perhaps you or i do not know just think about it so what you are trying to do is you are trying to represent any possible face in your database right using a linear combination of some vectors ok now these vector should have some interpretations right it should be connected to faces and somewhere otherwise how will you construct a face from taking a linear combination or some random vectors do you get the point so can you think of each of these ten k dimensional vectors which is the same as the dimension of your original data as a face and try to plot it can you try to do that at least it make sense ten k dimensional ok that is the same what you are image size was i could just arrange these ten k dimension as one hundred cross one hundred and try to plot it ok so let us see if you do that what happens ok we convert each eigen vector into one hundred cross one hundred matrix and treat it as an image and let us see what we get this is what we get so this is the top sixteen eigen vectors that i have plotted now can you tell me a physical interpretation of this this is the basis for constructing any face in your data base right that what you are trying to say all the faces that you have in your database or in the world you can combine them by looking at the these elementary face structures right which are your basis and then you could scale them up by using these alphas you will be multiply them with the certain alpha right and when you combine them you will get the base any face that you had in your original database does a physical interpretation make sense how many of you get this"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/5_0.wav", "duration": 95.996, "text": "so in parallelly while there was lot of success happening from two thousand and twelve to two thousand and sixteen or even two thousand and ten to two thousand and sixteen in parallel there will also a lot of research to find better optimization algorithms which could lead to better convergence better accuracies and again some of the older ideas which were proposed way back in one thousand, nine hundred and eighty-three now this is again something that we will do in the course so most of the things that i am talking about we are going to cover in the course so we are going to talk about the imagenet challenge we are going to talk about all those networks the winning networks that i had listed there alex net zf net google net and so on we are going to talk about nesterov gradient descent which is listed on the slide and many other better optimization methods which were proposed starting from two thousand and eleven so there was this parallel resource happening while people were getting a lot of success using traditional neural networks they are also interested in making them better and robust and lead for lead to faster convergence and better accuracies and so on so this led to a lot of interest in coming up with better optimization algorithms and there was a series of these proposed starting from two thousand and eleven so adagrad is again something that we will do in the course rms prop adam eve and many more so many new algorithms i have been proposed and in parallel a lot of other regularization techniques or weight initialization strategies have also been proposed for example batch normalization or xavier initialization and so on so these are all things which were aimed at making neural networks perform even better or faster and even reach better solutions or better accuracies and so on this all that we are going to see in the course at some point or the other"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/50_1.wav", "duration": 153.0, "text": "so with this we will move on to the last topic in the yeah so that is something that you will have to so the way i would do it right is that you keep aside some one hundred images from your data as validation data now once you have learned these eigenvectors try to compute the reconstruction error for these one hundred images and just vary it do one hundred one thousand ten thousand written as many dimensions as you can and see at what point is a reconstruction error ok for you right and this is assuming that you have some notion of what is a reasonable reconstruction error so we all know that the minimum is zero but if you have five then maybe for face database it might be but if it is a database where you are trying to look at mechanical parts so suppose you are looking at motors and rotors from a machine assembly now there you want to be able to distinguish minor detects defects on this and a detect could a defect could actually just be one single or two pixels getting different from the original image right so there the reconstruction loss would be much needs to be much more robust you get the point so it depends on your application so you will have to take some validation data either have a domain expert to tell you what is reasonable or go by the number that you get right and this is the validation error that i get so everyone understands the question and perhaps the answers ok so we now go to the last module student refer time one hundred and forty yeah if you can student refer time one hundred and forty-one yes you can now project any face into this database a so that is the eigen basis that you have got you have got the basis vectors now any data you can project onto this basis student refer time one hundred and fifty-four now so if you are trying to learn these eigenvectors by say using one hundred images all of which belonging to a particular demographic say all caucasian images right and now at the runtime you have an asian image then you will have obviously have some error right but you have large even of data say if you have if you are constructing this from million images then it should generalize that is i mean just as for any machine learning algorithm the training it from small data and you bring out some outlier at test time it is not going to work right but if you have reasonable data it should generalize any other questions to calculate the eigenvectors x is m cross ten m cross ten k yes now we move on to the last topic for the basic portion and the next class we will do auto encoders will be back to deep neural networks so singular value decomposition right"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/50_2.wav", "duration": 400.0, "text": "so this is actually the stuff that i need an important theorem from here at multiple two places in the course so now before doing the right let us get some more perspective on what eigenvectors do and why are they actually important"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/50_3.wav", "duration": 101.0, "text": "so now let us try to look at a geometric interpretation of this"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/50_4.wav", "duration": 27.0, "text": "and this is again something from linear algebra which i expect you to know is that all possible vectors in rn only a subspace belonging to rk can actually act as input to a x to produce a nonzero output so i am talking about a null space column space and things like that right so this should be clear if it is not it is it is not very important at for us right now and hence we have only k dimensions"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/50_5.wav", "duration": 172.0, "text": "so let us look at a different way of writing this so you have this a v one is equal to sigma one u one av two is equal to sigma two u two so i can again do the same trick that i put all the v\u2019s into one matrix where vi\u2019s are the columns of this matrix and i will put all the us into another matrix where ui\u2019s are the column of this matrix is that fine everyone ok so far and then i can write it as this matrix operation same thing that we did when we are doing eigenvalue decomposition right so we had written it as a into u is equal to u into sigma right because there we had the condition that ax is equal to lambda x now we have a u is equal to sigma v or rather the other way around so av is equal to did i missed up did i no right student refer time one thousand, two hundred and twenty-nine sorry student refer time one thousand, two hundred and thirty-two fine yeah so av is equal to sigma into u so is this fine no but when you do the diagonal operation you will get it as u into sigma y the same way as a x equal to lambda x but when you write it is a into u is equal to lambda comes later on"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/50_6.wav", "duration": 658.882, "text": "suppose v u and sigma exist then we can write this right so a is u sigma v so a transpose would be the transpose of that now can you work with me what is the next step student refer time one thousand, four hundred and forty-seven ok next student refer time one thousand, four hundred and fifty-one this is u sigma v transpose so then this would be i think the next step is no the next step is also wrong that fine ok fine i just had some error with the transpose ok what will happen now what will disappear from here student refer time one thousand, five hundred and twenty-six u transpose u that is i right u transpose the inverse of u"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/51_0.wav", "duration": 26.0, "text": "welcome to lecture seven of the course on deep learning cs seven thousand and fifteen in this lecture we are going to talk about auto encoders and we will focus on their relation with pca then talk about regularization in auto encoders wherein we will look at denoising auto encoders sparse auto encoders and contractive auto encoders so let us begin with the introduction to auto encoders what they are"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/51_1.wav", "duration": 32.0, "text": "so this is what a typical auto encoder looks like and as you can see this is very much like a feed forward neural network you have an input which is x i so you are given some training data you are given some i samples x i to x n so this is your training matrix x which we have seen in the previous lectures so this is one of those training inputs x i and then you have a hidden layer and then an output layer so let us look at what is the configuration of the hidden layer and what does the output layer actually try to do"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/51_2.wav", "duration": 209.0, "text": "so it is a very special type of a feed forward neural network what it does is it encodes with input x i to a hidden representation h ok and it uses an encoded function to do this so this is what the encoded function does it first does a linear transformation so w is a matrix and x i is a vector and you again have the bias b as a vector right so let us look at these dimensions right so let us try to fix some dimensions so suppose x i belongs to r n that is what we have been considering throughout the course so far and let us say h belongs to r d so it is a d dimensional representation so in that case what would w be yeah so w would be r n cross or the d cross n right so it will multiply with the n cross one vector which is x i and give you a d cross one output right and similarly the b would also be d cross one and then on top of that you have this non linearity g which will be operating at element wise just as we had seen earlier so it could be any of the sigmoid functions the logistic or tanh and so on so the end result is you have taken an input x i and encoded into a hidden represent h by using a linear transformation first and then a nonlinear transformation right so i refer to w x plus b as a linear transformation because it is a matrix multiplication now once you have constructed this hidden representation"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/51_3.wav", "duration": 45.0, "text": "so the model will be trained to minimize the difference between x i and x i hat so you want to make sure that after passing through this bottleneck which is the hidden representation you are able to reconstruct x i and the reconstructed output is very close to the original input right so can you see an analogy with pca where you are trying to find this hidden representation or this most important elements of the original input x i so there we had used this linear transformation where we are taking the original input x and transformed it to a new basis and we had used that basis for representing the original input right so something similar is happening here we are using this hidden representation h to represent our original input"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/51_4.wav", "duration": 156.0, "text": "now let us consider a few cases the first cases when the dimension of h is less than the dimension of x i in this case as i was trying to say earlier if we are still able to reconstruct x i hat perfectly from h then what does it say about h it tells us that h is a loss free encoding of x i it captures all the important characteristics of x i write just repeating what i had said on the previous slide and now you can see an analogy with pca because h has all the important characteristics required from the original input data so it has probably got rid of all the noise or all the low variance dimensions or the correlated dimensions and so on and this is just the compact representation which is as good as the original representation and from there you can reconstruct the original representation and such an auto encoder where the dimension of the hidden representation is less than the dimension of your original input is known as an under complete auto encoder"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/51_5.wav", "duration": 277.0, "text": "so this looks very trivial and this is what it could do right just copy the input to the first the n bits"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/51_6.wav", "duration": 146.0, "text": "so first let us start with the choice of f f and g so we will consider two case two cases one case when your inputs are binary and the second case when your inputs are actually real numbers right so the first we will look at the binary case so now just some notation clarification so remember our original data was this matrix x which was m cross n that means you had x one x two up to x n and each of these was r n so now when i am referring to the entire row or entire data instance i will use bold x i as i have circled here and i want to refer to one of the elements of this guy then i will use this notation x i j same as what i have written here so what i am saying is that each of these x i j\u2018s actually is a binary variable"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/51_7.wav", "duration": 50.0, "text": "now let us consider the other case where your inputs are real valued that means when you reconstruct something you should again produce real values that means your function f should take whatever is the input given to it and map it to some real numbers right so that is what we want from this function f earlier in the binary case we wanted it to map it to binary numbers right so that is the difference that we have now so in this case which of the following would be appropriate the second one right because tan h does not make sense because it will just produce minus one to one but you want to produce any possible real number because some of these are actually higher than one greater than one linear would be fine because it will produce any real number logistic is again not fine because it will produce numbers between zero to one"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/51_8.wav", "duration": 125.0, "text": "so the logistic and tan h as i said would clamp the output to certain ranges so that is not appropriate hence you should choose the linear function and again in this case also g is typically chosen as the sigmoid function fine ok so the next thing that we look at is the choice of the loss function"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/51_9.wav", "duration": 409.0, "text": "and the matrix or the vector way of writing this is the following so we have x i so what i am looking at here is i have gotten rid of this summation and i am just written it in vector form so let me just explain what this means so this is what x i would look like right so this would be x i one x i two up to x i n ok this is the vector and then you have the x i hat vector which is going to be x i one hat x i two hat up to x i n hat so taking the difference between these two vectors that is what this term is so what you will get is essentially x i one hat minus x i one up to x i n hat minus x i n right and then you are taking the dot product of this vector with itself which will essentially give you this summation right so the dot product of this vector with itself is actually going to be this summation it is going to be the sum of the squares of the elements of this vector and that is exactly what we wanted"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/51_10.wav", "duration": 155.0, "text": "so let me just go to the next slide so in particular everything that we had done for this portion of the network right which is actually dou a two all the way up to dou w right so if ok so let me write it like this i want dou l by dou w so i can write it compactly as dou l by dou a two and then dou a two by dou w right so this portion is not going to change because i am not change any of the functions here i have just assumed sigmoid or logistic or the same kind of network the only thing i have changed is something at the output layer so i will just need to recomputed this and the rest of it can be reused right so that is the intuition which i wanted to give you"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/51_11.wav", "duration": 251.0, "text": "and i am just so we have similar stuff in the past so you can actually easily work this out so this will actually turn out to be the following vector which is to times x i hat minus x i right so this is very simple i have just computed this and all i need to do is go back and change my back propagation code and change this derivative of the loss function with respect to the output clear and the rest of the code i can just reuse it as it is so now similarly so we have both of these ready"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/51_12.wav", "duration": 1230.702, "text": "so let us see what i mean by the cross entropy loss so remember that you have n outputs right that is why this summation let us not worry too much about what is written inside for the time being i will explain that but that is the i just want to explain the summation first so what you are saying is that for each of these green guys at the output you are going to make some loss and you just want to some over that loss that is what we are trying to see now ideally you could have just written it as just done what you had done before and written this entire replace this entire box by this squared error loss and that would have been just fine right of course there should have also have been this summation i equal to one to m here because you are going over all the m training instances and for each of the m training instances you are trying to minimize this loss so this two summations followed by this squared error loss would just have been fine"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/52_0.wav", "duration": 10.0, "text": "link between pca and auto encoders so we will move to the next module where i would like to show you a link between pca and auto encoders"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/52_1.wav", "duration": 164.0, "text": "so this is what i am trying to show you that under certain conditions pca is or rather an auto encoder is equivalent to a pca and the conditions are if you use a linear encoder if you use a linear decoder if you use a squared error loss function and if you normalize the inputs to this so for the time being just ignore the last bullet let us look at the other three bullets using squared error loss functions so remember i gave you different choices right you could have used the cross entropy or the squared error loss but i am going to prove this equivalence only under the condition when we have the squared error loss what do i mean the u encoder is a linear encoder g is a linear function we are not using a sigmoid or any logistic or anything like that and linear decoder again the same thing we are not using the sigmoid or soft max or anything at the output it is a linear function under these conditions i will show that or i will try to show you that pcas equal auto encoders equal to pca what does this mean actually now what do i mean by it is equivalent what do i have to show you actually how many of you understand what i am trying to prove how many of you can mathematically define it ok so we will try to make this clear over the next fifteen minutes"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/52_2.wav", "duration": 322.0, "text": "so first we will show that if we use the linear encoder decoder and a squared error loss function then the optimal solution to the following objective function what does this objective function student squared error squared error loss is obtained when we use a linear encoder do you understand the implication of this what does being stated here ok so i have fixed the decoder i have said that the decoder is going to be a decoder i have fixed the encoder or i have fixed the loss function this is going to be a squared error loss function this is given to me now under these conditions i am trying to minimize this loss function ok then i am telling you that the only solution to this is that the function dash should be a linear function which function the function g should be a linear function you cannot choose sigmoid or logistic or anything else right the optimal solution will occur when g is a linear function everyone gets what is being stated here"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/52_3.wav", "duration": 48.0, "text": "so that means h w star should be equivalent to this that we know from the svd theorem that the optimal solution is going to be given by svd so if i just compare terms ok then i could write that one solution is this that h h is equal to u into sigma and w star is equal to v transpose i could have chosen the other solution also where h is equal to v or sorry u and w star is equal to sigma v ok but i will work with this particular solution you see this i am just matching variables right it is said that a b is equal to c d e so i am saying that a is equal to c d and b is equal to e now we will work with this so and we will try to show something so let us see what we are trying to show"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/52_4.wav", "duration": 38.0, "text": "now first thing that we will show is that h is actually a linear encoding so what does this mean you first always understand what has been tried to prove right i am saying that i am going to show that h is a linear encoding of x then what is it that i am trying to show i am trying to show that h is equal to a linear encoding of x when h is of the form w x and not something of the form w sigmoid of w x or something like that or any other nonlinearity for that matter is the statement clear that is what i am trying to show when i say h is a linear encoding i mean that h is obtained by a linear transformation of x"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/52_5.wav", "duration": 436.353, "text": "now h as we defined on the previous slide is equal to this now if i already had an x here then i was done but i do not have any x there yet so i want to a get to a form where i can show that h is equal to w in to x so i will just do some simple trickery and arrive try to do arrive at that form"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/53_0.wav", "duration": 12.0, "text": "then we will go to the next module where we will talk about regularization in auto encoders and we will talk about a motivation for doing that"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/53_1.wav", "duration": 442.0, "text": "so poor generalization so why do we need a regularization people have done the machine learning course or any equivalent course why do we need regularization to avoid student or enable or enable generalization right now in the case of an over complete auto encoder what is likely overfitting is likely why is it so what does what do you mean when you see generalization actually can you talk in terms of training time test time and so on so generalization is essentially that your are training so remember that at training time you are trying to solve an optimization problem where you are looking only at the training data so it is quite likely that you will drive the error to zero for the training data that means you have learnt perfectly everything for the training data right but now it is also possible that when i give you a new test instance which you had not seen during training that means you had not seen instance while doing the optimization that means this instance did not contribute to your loss function then it is very lightly that when i gave this instance then you would get a non zero loss or a loss much higher then what you get for your training data does that make sense that is what over fitting is and it leads to less generalization your model should have generalize to unseen data but it cannot do this one typical situation where over or where generalization happens is if you have a dash number of parameters now what did i ask actually student generalization no ok if a case where a over fitting would happen is when you have a dash number of parameters student large number of large number of parameters right now do you see why i am saying this what is there on the slide an over complete auto encoder what would it have student a large number a large number of parameters so what could it do student overfitting over fitting what do we do to avoid over fitting student regularization regularization so that is why we need regularization i have still no told you why do we need an over complete auto encoder ok still that is an random variable i still need to decide but can this happen in an under complete auto encoder also it can right because under complete auto encoder just says that your k is less than n it does not say how much less it is right so it is it is still have and depending on a data that you are trying to model it could still have a large number of parameters"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/54_0.wav", "duration": 7.0, "text": "in this module we will learn about denoising autoencoders"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/54_1.wav", "duration": 327.0, "text": "so the idea behind the denoising autoencoder is very simple what you do is you have your original x i now for the minute for a minute just consider the discussion when your x is are binary inputs ok so each of these red guys can be between can be zero or one now what i do is before feeding it this input to my autoencoder the box is the autoencoder what i do is i do a corruption so the corruption is as follows with probability q i will set x ij that means one of these guys to zero right and with probability one minus q i will keep it as it is ok so with some probability q i am actually corrupting the data otherwise i am retaining the data as it is and then feeding that data to the autoencoder why would this work binary input case as i said just assume that the inputs are binary we will also see the other case why would this work what was our problem earlier that was completely able to reconstruct the training data right but at test time i had issues now what i have done to the training data corrupted it just think for a minute what will happen now i want someone to ask me a question in return oh that is the corruption that i am choosing or you could flip it is what you are saying yeah if it is zero change it to one so that is also fine that is the question i was expecting what is the loss function now what is the loss function x hat my i minus x tilde i or x hat i minus x i which choice makes sense student first tilde first let us the case take the case when i do x tilde i what happens in that case from this networks perspective it is still learning to memorize the training data right it just this is what it thinks as the training data and just trying to learn that transformation right so it is not really helping my case do you understand that i just corrupted the training data that is fine but from the networks point of view it still gets away by memorizing this data and that is not what i want so what should i do can anyone tell me the i mean can everyone tell me the answers student minimize minimize the error between student an x i an x i how many if you understand why that should help all of you gave the answer but only few of your raised your hands why so hard to deal with this inconsistency"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/54_2.wav", "duration": 32.0, "text": "it no longer makes sense for the network to just start copying the input data different kinds of noises means yeah so let me try to answer that right so what probably you are trying to say is that all my input images were three vertically written i added some noise and managed it but now at test time suddenly you show me a three of this kind like that will not work also that is what were your question was a different types mean different values of the noise twenty percent twenty-five percent and so on"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/54_3.wav", "duration": 358.0, "text": "so we will first see practical application in which autoencoders are used and then compare it to denoising at autoencoders so this the next few slides for those of you may care is also a small answer to the difference between machine learning and dp"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/54_4.wav", "duration": 9.0, "text": "now we will see a way of visualizing this and then we will make some observations from the visualizations so first let me tell you what the visualizations is"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/54_5.wav", "duration": 105.0, "text": "so i am returning to the autoencoder setup so i had this input and i had this h dimensional or k dimensional hidden layer now i can think of each of these neurons as something which gets activated for a particular type of input is that fine what do i mean by activated it is output would be student one remember this is a logistic neurons that we are talking about or even tanh neurons the output would be one so it is the maximum output that you could gain fine now so for example h one is equal to sigmoid of this when would this fire when where w one transpose x i is very high right when you are in that regime where the sigmoid flattens right this regime ok when it is very high so i want to be able to maximize w one transpose x i do you get this i want to be able to maximize this i want to find my w one transpose is fixed now because i have trained the autoencoder i have got these weights this is all post mortem right i have trained the autoencoder i have got these weights now i want to find an input which will cause this particular neuron to fire so what is my max what is my optimization problem maximize just help me out maximize w one transpose x let me just call it x and the optimization is with respect to x right because i want to find the x which maximizes this quantity my training is done i do not no longer care about changing ws my training has been done i am interested in finding x\u2019s which will maximally fire this"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/54_6.wav", "duration": 78.0, "text": "so and i am going to assume that all my inputs are normalized this just makes some analysis easier and remember that normalization is always ok you always do that so this is the optimization problem that i am interested in solving what is the solution to this how many if you can solve this no i want to find the x i student refer time one thousand, four hundred and twenty-nine now i have trained the autoencoder now i have known all these the one i am considering one column of the matrix w one i want to see what is the input that i should give so that i am sure that this neuron will get activated and i know that this neuron will get activated if i maximize this quantity right so i want to maximize that quantity and find an x such that it will get maximized i was just hoping that no one brings in eigenvectors w one is a column it is not a matrix just try to work it out what is this this is a dash between w and transpose and x i dot product when would the dot product be maximized when they are both in the same direction right that means you know the direction is going to be x i is equal to and what did i want the norm to be now do you get it fine"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/54_7.wav", "duration": 513.0, "text": "so the solution is going to be this is fine w one by the norm of w one so just remember that this quantity is going to get maximized when the dot product is maximized the dot product is maximized when both x i and w one transpose are in the same direction right so that means x i should be in the same direction as w one and i also wanted this constraint that x i should be the norm of x i should be one so i am just dividing w one by the norm of w one so i know now what is the input i should feed to the network so that one of these neurons fires now what i am going to do is i am going to plot the xi\u2019s which maximize each of these neurons i am going to consider some one hundred neurons in the hidden layer and i am trying to find out the input image which is going to maximize or which is going to cause each of these neurons to fire do you get what i am trying to do even though you do not get why i am doing it but do you get what i am trying to do ok so what am i going to do is this is a vector right so i am just going to try to plot this as an image of the appropriate dimension"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/54_8.wav", "duration": 3.0, "text": "and this is same thing that i have written here"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/54_9.wav", "duration": 37.0, "text": "now we saw one form of this function ok which was just flip the input if the output is just corrupt the input right you could also add a gaussian noise so you could take the input add a gaussian noise to it with zero mean and then again try to reconstruct the original input back is that fine so you could just use different noise functions to do this so we will now see such a denoising autoencoder where we have actually added a gaussian noise instead of the zero one noise or the corruption that we were doing"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/54_10.wav", "duration": 67.866, "text": "yeah so the purpose of this particular example that i am giving is to compare an autoencoder which is regularized by adding this gaussian noise with an autoencoder which is regularize by using weight decaying right the l2 regularization so l2 regularization is also known as weight decaying because you kind of decay the weights right you force the weights to be small so what they showed is that with denoising autoencoder using a gaussian noise you actually learn something known as edge detectors right so you see all of these are trying to detect edge again the same thing is happening i am plotting the images which will maximally cause a particular neuron to fire and it looks like all these neurons fire for different edge patterns in your original data so now they are capturing all the edges in the data and the combination of these edges should tell you what your final class is ok and this seems to work much better than the weight decay filter which is not really capturing any regular pattern ok so this is just an empirical evidence that an autoencoder with a gaussian noise seems to do better than autoencoder with the l2 regularization"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/55_0.wav", "duration": 7.0, "text": "so in this module we will talk about sparse autoencoders"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/55_1.wav", "duration": 306.0, "text": "just some concepts before we jump into the actual way of doing this so hidden neuron with sigmoid activation will have values between zero to one and you say that the neuron is activated when this output is close to one and it is not activated when its output is close to zero ok now a spare encoder tries to ensure the neuron is inactive most of the times what is that mean student close it is close to zero for student most of the most of the student refer time forty-seven inputs right so i am passing a lot of inputs to it it will try to ensure that it is close to zero for most of the inputs so in other words what does it trying you ensure i am looking for the word average the average activation of a neuron is close to zero does that make sense is that fine"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/55_3.wav", "duration": 7.0, "text": "so i will skip this we will fix these errors there are some summation and other terms missing here and the second part is actually correct which has been derived on the next slide"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/55_4.wav", "duration": 35.544, "text": "but i would not go over this this is there are the slides again go back and look at it how many of you are confident that you can do this on your own please raise your hands yeah because we have done enough of this in class right so you can you should be able to it no if you are not able to do it then i am not doing a good job at teaching you right so you should be able to do it now fine and we will fix these errors so ta\u2019s just remind me after the class so everyone gets the general idea you find a loss you find a constraint you define it with omega theta find out the derivative of that with respect to your parameters and just change your gradient descent upgrade tool accordingly"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/56_0.wav", "duration": 15.0, "text": "so with that we will move on to something known as contractive autoencoder so this is yet another type of auto encoders again with the same aim that you want to do some kind of a regularization"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/56_1.wav", "duration": 69.0, "text": "so it again tries to prevent and over complete auto encoder or even an under complete auto encoder for that point from learning the identity function so it does not allow you to simply copy the inputs to the outputs that is what it is trying to learn and it does so by adding the following the regularization term to last function and the way it does this is by defining the following regularization term ok what is this term ok let us see some things which we already know what is this frobenius norm of some matrix what is this matrix student jacobean jacobean what is the jacobean student refer time one hundred what are the two variables here that you see student h h and student x h is a scalar matrix vector student vector vector x student vector vector right so it is some function between two vectors ok and it is a matrix so take a guess how many entries would not you have if x is r n and h is r k student n cross k n cross k even if you do not know what the entries are you are able to guess that it is going to be a n cross k matrix right"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/56_2.wav", "duration": 70.0, "text": "now let us see what this n cross k matrix looks like ok"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/56_3.wav", "duration": 137.0, "text": "now tell me what is intuition behind this ok so when would this term so remember this term is added to the loss function and you are trying to minimize the loss function so that means you want this term to go to student refer time three hundred and one you want the frobenius norm to be student zero refer time three hundred and three zero right ideally of course that will not happen because there is always a tradeoff between l theta and omega theta if you make it zero then l theta would be very high right"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/56_4.wav", "duration": 51.0, "text": "so just i it is hard for me to do evaluate what you have said but just pay attention and see if that is correct you can judge it on your own right so that is the actually the idea right we have put these two contradictory conditions with each other right l theta says capture the important variances of the data omega theta says do not capture variations in the data watch the tradeoff capture only very important variations in the data do not capture the variations which are not important can you relate this to something that you have seen before student bias variance no the other answer there are only two answers bias variance and pca when i say the other answer student pca what am i trying to force it to do capture only the important variation it is if it is not clear right now we will come back to this ok"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/56_5.wav", "duration": 106.0, "text": "so let us try to understand with this with the help of an illustration right how many of you get the argument which i made on this slide ok most of all"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/56_6.wav", "duration": 13.0, "text": "and just a quick summary so we showed that under certain conditions auto encoders are equivalent to pca and we use this result very crucially there that svd theorem i will not state it"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/56_7.wav", "duration": 17.071, "text": "and then we looked at different types of regularizations for auto encoders where we looked at weight decaying that means the standard l2 norm we looked at the sparse auto encoder the contractive auto encoder and we also looked at these denoising auto encoders right so that is the summary of this lecture"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/57_0.wav", "duration": 49.0, "text": "so in this lecture we are going to talk about a bunch of regularization techniques for deep neural networks you might find some very familiar terms here for example l2 regularization perhaps something else also but i promise you that we will see a very different interpretation of this from what you have done in your earlier courses right so again as is the trend in this course i will start with some basic concepts i will take today\u2019s lecture to finish off the basic part which is the bias variance tradeoff and i will try to make it more informative then what you have done in your earlier courses and in the rest of the lecture which will happen on friday we will build upon these basics and then try to look at these as the regularization forms"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/57_1.wav", "duration": 23.0, "text": "so let us start so these are the sources which i have looked at so one of them is the chapter seven from deep learning book other is this very good lecture by ali ghodsis on regularization and of course this paper on dropout so let us start with bias and variance again some five hundred and ten minutes would be similar to what you have seen in the middle class but then i will go on to something different"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/57_2.wav", "duration": 49.0, "text": "so we will begin with a quick overview of bias variance and the tradeoff between them"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/57_3.wav", "duration": 459.0, "text": "so from now on we will behave as if we do not know that this is how it came it is a big secret and we now want to fit a curve to this that means i want to learn the function f hat of x ok which of course will have some parameters and what will be my goal is that now let us look at this again my goal would be if i feed at this point after the model is train the output should be as close to this point as possible that is our training criteria everyone gets this"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/57_4.wav", "duration": 32.004, "text": "so informally i can say the following simple model has a high bias low variance complex model has a low bias high variance and as always going to be a tradeoff between the bias and variance so why is there always a tradeoff between the bias and variance people have done ml course why is there a tradeoff how many of you know the mathematical answer to that you have not done this in the ml course no so it turns out that both bias and variance contribute to the mean square error and let us see how"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/58_0.wav", "duration": 10.0, "text": "so we would start the next module where we will talk about training error versus test error and before that we will see this bias variance tradeoff"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/58_1.wav", "duration": 178.0, "text": "so now what have we done so far in these complex models and the simple models we have trained them using the dash data training data and what are we interested in always a test data right i already know what was the oil amount of oil mined from the training data locations that i was given and i am not interested in predicting those i am less interested in learning those so that if you give me a new location i should be able to do the right prediction so i am always interested in the test data so now consider a new point which is not seen during the test data and there are several such points that you could see now if you use the model f hat x to predict the value of y then the mean square error is given by you get this it is just the expected value of this squared error that i will get so what is the randomness here y expected value because the x that i am going to feed at test time is going to vary for each of these different xs i will get a different error so hence that is a random variable do you get that so please focus on these things right i mean just do not take a formula for granted just see what is it trying to see so whenever you see an expectation over something always question what is a random variable here so what is the random variable here it is the squared error loss why is it random it is because it changed the input x you are going to try it over a multitude of test examples you will take one thousand text examples ten thousand text examples and so on right for each of this you will get a different squared error that is the randomness so you want to see what is the expected value of this or very loosely speaking the average value of this now it turns out that this now just try to remember that this is also some expectation and you had the terms f x and f x hat here this also had some expectation and term f x and f x hat and so on right if you do not remember the exact formula it is ok but you do remember there were some expectations inside and the terms f x and f x hat whether they are so this is just simple you are dealing with a minus b the whole square on the left hand side if you if you open it up rearrange some terms you will get this right so you can show that the mean average or the expected square error on the test data is actually the bias square plus the variance that is a small amount of irreducible error you can go back and work this out and actually the proof is given here on the link ok but i hope you get the intuition you have this a minus b the whole square if you open it up and rearrange the terms you should be able to get this now what does this tell you what happens if the bias is high the squared error is going to be high what happens is if the variance is high it is going to be high so that is why you do not want a very high bias you do not want a very high variance also you want this sweet spot in between where the bias and variance are just about optimal you get that that is why there is a tradeoff between bias and variance you cannot rely on simple models which have high bias you cannot rely on complex models which have high variance you want something in between"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/58_2.wav", "duration": 152.0, "text": "now the parameters of f hat x remember that they are trained using the training data which consists of these end points that you have at test time we are interested in evaluating the model on a validation set which was different from the training data this gives rise to the following two quantities one is the training error which you deal with at dash time training time that is the error that you are trying to minimize right but a test time you have a different error which is the test error and that is the error that you care about typically these two errors exhibit a certain trend do you know what the trend is now on the x axis i have model complexity and on the y axis i have error as a model complexity increases what would happen to the training error it will go to almost zero that is exactly what happened from the linear function to the polynomial function this is how it will behave as the model complexity increases as the model complexity increases what would happen to the validation error it will decrease up to a certain point right because you are still not over fitting on the training data your answers are still generalized so you had this degree one polynomial degree twenty-five polynomial if i take in something in between then probably this is where i would have ended up with the training error and that would not have been too bad for the test error you see this ok now you see i will mark two points two regions rather one of this corresponds to high bias the other one corresponds to high variance tell me which one is which do this i cannot understand so let me ask this is this is ok good so you see that there are these two extreme and we want somewhere to be in between ok at least you get the intuition behind this fine ok and you are looking for this sweets spot which is the perfect tradeoff between the bias and the variance right so now everyone gets why there is a tradeoff and how this relates to model complexity and therefore we are looking for the ideal model complexity how do we achieve the ideal model complexity well we cannot really ideal is ideal but we try to do this using dash what is the title of this lecture student regularization regularization i will try to use regularization to achieve this ok so let us formalize this a bit more and remember that this curve is actually because of this equation that you see right high bias you will be in this region i am actually inserting it ok fine ok"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/58_3.wav", "duration": 79.0, "text": "so the intuitions that we have developed so far is that if there are n training points and m test points then we have a train error which goes over the training points and we have a test error which goes over the m test points ok so i am just taking a total of n plus m points the first n is training the next last m is test now as the model complexity increases what happens to the training error it becomes very optimistic and gives you a very wrong picture of how close the predicted function is to the true function whether it makes you feel that you have done a perfect job this you have actually discovered the true function but that is not correct it is giving you a false picture of that therefore we should always look at the dash error student validation error validation error so now you see that why you always do this train validation and test split test is unseen you try to optimize on the training error ok but you should always tune for the validation error your optimization algorithm is going to take in the training error it is going to be very optimistic it is going to try to drive to zero but you should look at the validation error and try to see that you are not over fitting on the training data everyone gets this intuition"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/58_4.wav", "duration": 122.0, "text": "so now this is all intuition we will have to concretize this mathematically so that is what we will do now so that d be these training test points that we have we know that this relationship holds we do not know what f is but we know that this relationship holds so what am i trying to say here that we know that there is a true relation between y and x which is given by the function f but i am also willing to admit some noise that may not be a very neat function but a small noise might exist that is the epsilon i ok and i am going to assume that epsilon comes from a normal distribution with zero means so on average the noise is going to be zero but there is a small variance everyone gets this this is a true relation but i am willing to admit some noise in the relation ok fine and of course we do not know f we never know f right now going by our paradigm where we have these five components we use f hat to approximate f f hat will have some dash which will i try to learn from the training data what is this dash parameters right which will try to learn from the training data the training data t is a subset of your total data which is thus those endpoints right and we are interested in knowing this quantity this is what we are actually interested in can we compute this quantity how many of you say yes how many of you say no we cannot why cannot we compute it we do not know f so why cannot you raise your hands if you all can answer in chorus so we do not know what f is then how do we compute this quantity right but what do we actually know so now we are going to see something which is true expectation and something which is empirical estimate expectation how many of you know this what is the difference between the two most of you should but it is not confident about it ok so we do not know what fxi is the true thing but what do we know we are given some training data right we know these yi\u2019s for was training data and we know these yi hats for those training data"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/58_5.wav", "duration": 102.467, "text": "so this is something that we can estimate yes or no this is given to us so this expectation is going to be an empirical estimate right because we are going to look at some one thousand ten thousand twenty thousand training points and estimate this right it is an empirical estimate how many of you get that now i am just going to rewrite some of this so what i have done is i just defined that yi is equal to fxi plus epsilon i so i have just replaced yi by that ok is that fine now this is of the form a minus b the whole square so i am going to treat it as that and just open up the bracket so i will have a square minus two a b plus b square and now this is a sum or difference of expectation so i can push the expectation inside so this is what i get this is this fine ok now i am just going to rearrange the term so remember this was the quantity that we were actually interested in but this is the quantity that we had a handle over because these were the data points given to us so i will just rearrange the terms and i can write this which was my quantity of interest as this can you estimate everything on lhs on rhs this this what is this variance sigma square we assumed it came from zero sigma square distribution and this can estimate the answer is no for the same reason we do not know what f of x is ok"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/59_1.wav", "duration": 6.0, "text": "so we spoke about bias and variance and we saw that simple models have a high bias but low variance and complex models have a low bias high variance and so on and we saw it some illustrative examples that what that is what that means"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/59_2.wav", "duration": 8.0, "text": "and then the important thing to note was these two formal definitions of bias"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/59_3.wav", "duration": 10.0, "text": "and formal definition of variance which you all know anyways and then the important concept that we spoke about was the train error versus test error right"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/59_4.wav", "duration": 3.0, "text": "so this was the curve that we were interested in and one corner of this curve was related to high bias low variance and the other corner was related to low bias high variance right"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/59_5.wav", "duration": 27.0, "text": "so i am looking for something in the middle that is what our quest is in this lecture right and we want to find ways of falling somewhere in middle"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/59_6.wav", "duration": 57.0, "text": "and this led to the definition of two quantities of interest or training error and test errors so training error is computed from the training points these are the points that you actually look at while you are solving this optimization problem so the training always involves solving an optimization problem which is the objective that you want to optimize or maximize and the test error is something that you want to use it for at eventually so you all have these two quantities of interest that we design and we realize that the training error is more optimistic whether the test errors actually gives us the real picture of what we do and we tied those back to things that you have done previously in the machine learning or other courses that we always split the data into training valid and test training it on the training data do some validations on the validation data but never look at the test data that is for the final evaluation so that\u2019s the this is this intuition which i have been trying to build with these two curves is the explanation for why we do things that way"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/59_7.wav", "duration": 101.0, "text": "now we are interested in doing a more mathematically rigorous analysis of this intuition right so that is where we left off so what we are interested in so now i will just start from this point is that we are given some data which is m n m training points and n testing points and we know that there is a true function between the outputs and the inputs and we are also expecting or accepting some noise in this relation just as in any other relation so which means that y is related to xi but by some true function but there is also this noise and for simplicity we assumed as this noise comes from a normal distribution with zero mean and some small variance and as usual we never know f right but we are trying to approximate this f hat and we come up with some parametric form for f hat and then try to learn the parameters of f hat from the training subset of the data that is given to us so this is what we always do and we have already seen different variations of f hat one of them being the deep neural network and what we are actually interested in is this quantity the expected difference or square difference between the predictions made by our model and the true value of the output with respect to the true function right then we asked i asked you whether we can actually estimate this quantity and all of you said no why it is because you do not know what f of xi is right so we will see how to estimate this empirically"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/59_8.wav", "duration": 88.0, "text": "so then we started off with this information that we have we know what y i hat is because that is the prediction that we make and we know yi what yi is we do not know the function but we see the output of the function in the form of the training data points given to us or any data points given to us so we wrote this by making this particular substitution where we notice that yi that we see is actually the true function plus some noise and then we did some trickery and try to simplify this and then we just realize that this is the term that we are interested in so we moved it to the other side of the equation and came up with this neat left hand side or neat right hand side that we need to analyze now so far everything is clear this is where we ended the last class right you just went to it very quickly but i assume everything is clear at this point ok fine so we are left with a bunch of expectations right and we have i am assuming we have no clue how to estimate this right i mean so and remember that when you are dealing with expectations as always this true expectation and then there is this empirical estimation right so what we are going to move towards so these all equations when i write e here capital e here i am talking about the true expectation now we will see how to approximate the true expectation with an empirical expectation and then based on that we will make some observations"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/59_9.wav", "duration": 2.0, "text": "so that is what we will do now"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/59_10.wav", "duration": 128.0, "text": "so we will just take a small d two and i will just tell you what expectations are or what empirically expectation is how to compute them so suppose we have observed the goals scored in k matches there is some k football matches that we have seen and we have seen that the goals scored were the following now if i asked q what is the expected value of the goal now the number of goals for what will you do take the average of this this is what you will do so what is it that you are doing here you are taking a dash estimate of the expectation empirical estimate you are making some observations these are the observations given to you these are the k matches watch as much as many football matches as you want after the semester ends and then notice the number of goals that were scored in them and then you can compute this expectation right and this is how you do empirically so there is something that we do on a regular basis but i just want you to realize that what you are doing is actually an implicit estimate of the true expectation now can you relate this to the quantity that we are interested in we are interested in computing a certain expectation which is this can you take an analogy and tell me how you would do this the hint is we have done this a million times in the course already fine so this is how we will do it and have actually done this a million times in the course so when you compute this we are actually doing an empirical estimate of the data so let us just take a minute to understand this we are given some data we are interested in this to expectation which we cannot compute so we will take this data we will assume there is enough of this we are given m samples which are enough and from that we will make an empirical estimate and just as in the case of these goal scored right as you see more and more matches you will have a better understanding of how many goals can be scored when two particular teams are playing in the same analogy goes here as you see more and more data your estimate would become better but that is how you will do the estimation so now we will come back to so now do not get surprised when i am going to replace all these e\u2019s by this all the e\u2019s that we had in our original equation i am going to replace them by these summations ok fine"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/59_11.wav", "duration": 132.0, "text": "so this was our original equation that we had derived and we were interested in this left hand side quantity which is a sum of some terms on the right hand side so now this expectation i told you that we can estimate it from data but which data training data or test data both so we will try to estimate it from both and see if there is any difference which arises when you estimate it from one data and the other data ok so the first thing that i am going to do is i am going to use test observations to estimate this so can you tell me what are my summations going to look like it is summation over n plus one to n plus m right we assume that the first endpoints are training points and the remaining points are test points so the quantity on the left hand side is true error remember that because that has f x which we do not know quantity on the right side the first thing is empirical estimation of the error ok the second thing is a small constant however the epsilon i square and we assume that comes from a normal distribution with a small variance what is the third quantity actually i have given you the answer already but i want you to think about it i am saying it is the covariance between two things when i say it is the co variance between two things what is the first thing that i need to prove is that the two things are dash random variables i mean first thing we need to see is that the two things are random variables epsilon i clear it is a random variable what about this other thing or rather epsilon is a random variable what about the other thing and depending on the training instance that you have sampled this ongoing difference is going to differ right you are having your training or test instance whatever is this x i this is going to differ because these x\u2019s are different they are all random variables so there is difference between these two quantities also going to be a random variable is that fine ok but still is this the so then i have told you this is x and this is y and what i am saying is that the co variance between x and y is just e of x x into y is that correct"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/59_12.wav", "duration": 27.0, "text": "that is how you define co variance what is the definition of co variance if you have bothered to look at the prerequisites no expectation in the form of e so co variance is e of x minus mu of x into y minus mu of phi what is our x epsilon and what is our y what is mu of x zero so i will just simplify this a bit ok i will open up the product what is mu of y into e of x what is e of x what is the expected value of the noise zero"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/59_13.wav", "duration": 29.0, "text": "so then this turns out to be as that is that fine that is why we are writing the co variance is just the product of the two things so let us just take a minute to again understand this the true error is the empirical estimation of the error plus i mean plus or minus a small constant ok and then this nasty quantity that we do not know what to do with it so let us look at this quantity and see what we can say about it"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/59_14.wav", "duration": 100.0, "text": "now what is the co variance between these two i am trying to compute this expectation from the test data just remember that so each i here is a test instance are these two random variables dependent or independent is the question that i am trying to ask it is independent so let us look at it piece wise so remember that we had said that y is equal to f of x i plus epsilon i right this epsilon i had no relation to f of x i i mean i could choose any x i but this noise is going to be random so there is no relation between these two now is there a relation between f hat of x i and epsilon i we are doing tests so how did we come up with f hat of x i how did when i say how did we come up with f hat is i mean how did we learn the parameters of a f hat using the training data and what are we computing expectation with respect to now test data these these epsilon improve influence the parameters that we had learned further from the training data no since there is no dependence between these two guys so that is why epsilon i is independent of the other random variable that you see in this expectation is that clear do you get the intuition f hat x i further no but this is the mean this noise is what is present in the test data and you have not seen this add training time when you are training the parameters you did not look at this noise you are looking at the noise in the training data so this is not participated in the estimation of the parameters of f hat but that was for the training data right but this now i am doing the expectation from a test data"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/59_15.wav", "duration": 207.0, "text": "so these two random variables are independent that means i can write this as is this fine what will happen to this 0ok so what did we eventually conclude that the true error is equal to empirical test error plus a small constant right so what does this tell you now tell me forget the math tell me in english right what does this take what does this mean can you relate it to now why you do this training error validation error test error so what does this tell me this tells me that if i have trained a model and now if i take an estimate of the error on some data which i had not used for the training then that error which i see is actually very close to the true error it only differs by this small constant how many of you get that that is why when i look at the validation error it is not being overly optimistic it is giving me a true picture of what the actual error is right so there are two things that you need to understand here one this is the quantity that we are interested in which we cannot estimate we are trying to estimate it by using this we are trying to make an approximation so we are trying to see how good this approximation is what this derivation is telling us is that if you are approximated it using the test error or the test data then this approximation is actually very close to the true error and how close it is actually it just differs by this small constant so you get the importance of what we are seeing here right ok now to truly appreciate this i need to tell you what would have happened if you had used the training data for this estimation right it is largely dependent but that is again a normal assumption that you make so this is ok good that you asked at this point i will be doing a couple of things today where we will be deriving some things we will try to prove some things mathematically but all of these would have underlying some assumptions so if you remember the adam derivation with this we did there also we had made this funny assumption that the gradients are actually coming from a stationary distribution which will not happen in practice so this reminds me of this joke from big bang theory which says that i have a solution but it only works for squared eggs in a vacuum right so it is basically all these things always have some assumptions underlying them but the idea is to kind of ignore those assumptions and see what happens in a neat setting and at least see whether in a neat setting everything works fine or not so that is what is happening here so is a valid point that you are assuming that the noise comes from a zero mean distribution now if the noise did not come from a zero mean distribution then this would have not gone down to zero and the mean would have been higher than this is no longer a small constant and so on so those things are there so this is going to happen in some of the other derivations that i do today it is not that i am teaching you something wrong it is just that you have to take it with a pinch of salt in the sense that these assumptions are there and the original derivations these are not my assumptions and they work only under those assumptions so you have to be careful about that but the idea is that still with these assumptions can we at least make something meaningful out of it right is that fine with everyone can we all work with that basic premise so what i have done so far is told you that if you are estimating the errors from the validation data you are doing a good job"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/59_16.wav", "duration": 92.0, "text": "now let us see if i would estimate the error from the training data take a guess what would happen what would my argument for this be now this will not disappear right because these two are not independent now i cannot write it as a product of two expectations that means it will not go down to zero so that is the argument which i am going to make so hence actually the true error if you see right it is equal to the empirical estimation plus some quantity that means the true error is dash as compared to the empirical error that means the empirical error that we see is pessimistic or optimistic optimistic that is what i started with that you gave a very optimistic estimation of your error if you are looking at this empirical estimation from the training data because you have ignored this quantity is it fine so what is missing in the story let us see now what was this quantity so far all our discussions l theta right but now suddenly i have realized that my true error is actually l theta plus something else right you see where i am headed with this ok so that is what we need to see now ok now think it would be we should but i am pretty sure it is positive i cannot work it out right now but i am pretty sure it is positive and you can see and if you find it is not then let me know"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/59_17.wav", "duration": 20.878, "text": "so how is all this related to model complexity we started off with this idea that model complexity tells you how much is the bias how much is the variance and because of that you get these two curves that you are not happy with one curve being very optimistic and the other curve being a bit pessimistic now how does this discussion tie up to model complexity"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/6_0.wav", "duration": 17.0, "text": "so i was talking about successes in image speech pattern recognition even natural language processing and so on so one interesting thing here is about sequences so i will talk about sequences now"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/6_1.wav", "duration": 80.0, "text": "sequences are everywhere when you are dealing with data so you have time series which is like say the stock market trends or any other kind of a series time series then you have speech which is again a series of phonemes or you have music you have text which is a series of words you could even have videos which are the series of images right one frame each image each frame can be considered to be an image and so on so in speech data one peculiar characteristic of speech data is that every unit in the sequence interacts with other units so words on their own may not mean much but when you put them together into a sentence they all interact with each other and give meaning to the sentence right and the same can be said about music or speech or any kind of sequence data so all these elements of the sequence actually interact with each other so there was a need for models to capture this interaction and this is very important for natural language processing because in natural language processing you deal with sequence of words or all your texts or sentences or documents or all sequences of words so that is very important and the same in the case of speech also so if you take up any deep learning paper nowadays it is very likely that you will come across the term recurrent neural network or lstms which are long short term memory cells and so on"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/6_2.wav", "duration": 2.0, "text": "so this is also something which was proposed way back in one thousand, nine hundred and eighty-six"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/6_3.wav", "duration": 34.0, "text": "so a recurrent neural network is something which allows you to capture the interactions between the elements of your sequence i had said at a very layman level but of course you are going to see this in much more detail in the course and this was also not something new even though you hear about it a lot in the past three to four years the first recurrent neural network and what you see here is exactly a very similar to what we are going to cover in the course was proposed way back in jordan by jordan in one thousand, nine hundred and eighty-six"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/6_4.wav", "duration": 41.0, "text": "its variant was proposed by elmen in 1990so this is again not a very new idea this has existed for some time but now there are various factors because of which it has been possible to now start using them for a lot of practical applications as i said one you have a lot of compute time and the other you have a lot of data and the third is now the training has stabilized a lot because of these advances which i was talking about in terms of better optimization algorithms better regularization better weight initialization and so on so it has become very easy to train these networks for real world problems at a large scale so that is why they have become very popular and hear about them on a regular basis but it is again something which was done way back"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/6_5.wav", "duration": 30.0, "text": "so from one thousand, nine hundred and ninety-nine to one thousand, nine hundred and ninety-four actually people also looking at various problems will be training neural networks and recurrent neural networks and so that this problem which is known as exploding and the vanishing gradient problem which is again something that we will see in the course in reasonable detail we have this problem and it is very difficult to train recurrent neural networks for longer sequences so if you have a very long sequence or a time series you cannot really train a recurrent neural network to learn something from that"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/6_6.wav", "duration": 49.0, "text": "and to overcome these problems around one thousand, nine hundred and ninety-seven long short term memory cells were proposed and this is again something that we will cover in the course and this is now almost de facto standard used for training for a lot of nlp work lstm are used as one of the building blocks and another variants of lstms which are known as gated recurrent units and some other variants so this is also not something new even though they have become very popular nowadays like almost any article that you pick about to talk about any article on deep learning that pick about to talk about recurrent neural networks or lstms or gated recurrent units this is not something which is new"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/6_7.wav", "duration": 70.0, "text": "lstms had come way back in one thousand, nine hundred and ninety-seven but again due to various compute and other issues which i said at that time it is not so easy to use them but by two thousand and fourteen because of these parallel progresses which i mentioned in terms of optimization regularization and so on people are now able to use rnns lstms for large scale sequence to sequence problems and in particular a very important discovery at this time are very important model which was proposed at this time which is attention mechanism which is used in a lot of deep neural networks nowadays which enabled to deal with a lot of sequence prediction problems for example translation where you have given one sequence in one language and you want to generate the equivalent sequence in another language so this is known as a sequence to sequence translation problem so for that people proposed a sequence to sequence attention network and this was one of the key discoveries which then led to a lot of adaptation of or adoption of deep neural networks for nlp a lot of research in nlp happened which was then driven by deep neutral networks so a lot of existing algorithms which are non neural network based algorithms which are traditionally used for nlp was slowly replaced by these deep neural network based algorithms ok"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/6_8.wav", "duration": 31.704, "text": "and again this idea of attention itself is something that was explored earlier also somewhere around one thousand, nine hundred and ninety-one or so and it was something known as reinforcement learning which was used for learning this attention mechanism what attention basically tells you is that if you have a large sequence and if you want to do something with this sequence what are the important entities of this sequence or elements of this sequence that you need to focus on so this is again something that we will look at in detail in the course"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/60_0.wav", "duration": 9.0, "text": "so now we will try to see that how does this true error that we see depend on the model complexity"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/60_1.wav", "duration": 178.0, "text": "so using steins lemma and some trickery we can show the following what is steins lemma so i had this deal with my students last year you do not ask me what steins lemma is i will not ask you what steins lemma is ok so it is some lemma which tells us that this quantity what was this quantity the last term which was troublesome rate that covariance term which was troublesome that is this quantity this quantity is actually equal to this quantity so let us buy that let us all of us agree that steins lemma is correct and it tells us that this is the case ok and you saw the quiz one paper ok fine from last year i mean ok so now we will work with this premise and we will see what it actually tells us now when will this quantity be high so what this is telling us i mean jokes apart let us try to focus again that this quantity is actually equal to the summation of this quantity now let us take one term in this summation when would dou f hat x i by dou y i be large what does it actually tell you if i change one of these yi\u2019s a bit when the prediction for it is going to change by a lot do you get that how many of you get this some of you do not get this just think about it when would this be high what does the derivative capture if the derivative is high that means a small change in the denominator is going to lead to a large change in the numerator what is the denominator actually the true y that we have observed what is the numerator that is the predicted y so what you are saying is that if there is a small change in y i then there is going to be a large change in the prediction ok when would this happen would this happen for simple models or complex models complex models how many of you say complex models so this is the link to model complexity rate and i will make a more intuitive case for this but at least some of you get this that if your model is very complex that means it is even one of your data points changes and the prediction of the model is going to change largely so now relate this back to that sinusoidal model that we had and we had this complex model every model that i was training which was strained on a different set of twenty-five examples the model was vastly different and that is exactly what was happening when you were changing even one data point your predictions were changing largely that means your model was changing largely do you get that intuition so indeed a complex model will be more sensitive to the changes in the observation whereas a simple model will be less sensitive to it and hence we can say that the true error is actually equal to the empirical train error plus something which relates to the model complexity"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/60_2.wav", "duration": 53.0, "text": "now let us first verify that indeed a complex model is more sensitive to minor changes in the data so this is some data that i had sampled from the same distribution and i trained one simple model which is the green line which you see that was a linear model and i trained one complex model which was a twenty-five degree polynomial which you see ok now what i am going to do is i am going to take one of these points and change it a bit and i retrain the model what happens to the simple model it does not change much but what happens to the complex model it is more sensitive to these observations that i have and that is exactly the quantity that we were interested in that means a complex for a complex model which is more sensitive that summation that we care about is going to be high that means that difference between the true error and the estimated error is going to be high"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/60_3.wav", "duration": 65.0, "text": "so that is why instead of minimizing the train error we should always minimize the train error plus some quantity which is linked to the model complexity this is the basis for all dash methods regularization method so now you see where this comes from so ok where omega theta would be high for complex models and simple for simple models ok you get the intuition for this and the rest of the lecture we will spend in taking various cases where we will actually show that omega theta would be high and we are trying to control for omega theta this quantity for the rest of this lecture and for the rest of this course i will assume that we all know how to deal with we have done enough of this we have done a lot of back propagation we have done enough derivations of the laws with respect to the output layer and so on everything right so all of us understand how to deal with l train theta where l train theta is this l equal to one to m squared error loss or your log likelihood or any of these losses right so we all know how to deal with this today we are going to focus on this other term which brings in the regularization"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/60_4.wav", "duration": 54.0, "text": "so what omega theta does is actually acts as an approximation for this so what i should have actually tried to minimize is not just l train theta but l train theta plus this other quantity which was there in my equation you get this my true equation was that my loss is equal to l trained theta plus this term right which we approximated using steins lemma so i should have tried to minimize this quantity but i do not know how to really compute this quantity so i am going to just substitute it by omega theta and ensure that omega theta is such that it is high for complex models and low for simple models do you get the recipe everyone gets this how many of you understand this fine so we can show that l1 regulation l2 regularization early stopping all of these are actually special cases of this particular formulation that we have"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/60_5.wav", "duration": 48.0, "text": "and remember that this is the sweet spot that we were aiming for ok and this gap is actually this quantity because we are making a very optimistic estimation of the error whereas there is actually this quantity which we have been ignoring and that is why we see that the validation error is high ok so is the full picture in terms of the diagram and all the equations that we have seen so we should ensure using omega theta that this gap is also minimized therefore our function should be minimized l theta plus omega theta so essentially what we are trying to do is minimize this gap and hence the model would generalize better on the test data is this intuition clear to everyone"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/60_6.wav", "duration": 38.0, "text": "why do we care about this bias variance tradeoff model complexity this is not a course on machine learning they are highly complex models they have many parameters many nonlinearities in fact now can you relate this back to the universal approximation theorem what is the universal approximation theorem say give me any data i will give you a deep neural network which will exactly over fit the data right and that is exactly what we want to avoid that is why regularization is important in the context of deep neural networks fine it is very easy for them to over fit the data and derive training error equal to zero and that is why we need some regularization"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/60_7.wav", "duration": 42.243, "text": "so today we are going to look at different forms of regularization starting with l2 regularization some simple tricks so some of these are going to be mathematically motivated some of these are just going to be heuristics or empirical stuff so data set augmentation is one such empirical stuff how many of you tried data set augmentation for the immunized assignment or the back propagation as parameter sharing and tying is something that no i am not please do not give me that look yeah i am not suggesting that adding noise the inputs adding noise to the outputs early stopping ensemble methods and drop off right so these are the things that we are going to talk about this and all of this is in the context of regularization where you want to avoid some kind of model complexity"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/61_1.wav", "duration": 2.0, "text": "so let us start with l2 regularization so i have seen this before"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/61_2.wav", "duration": 104.0, "text": "so all of you see that this is l2 regularization right what does l2 regularization does now tell me in the context of things that we have discussed today what is this empirical estimate of the train error ok and what is this is that fine right so everything that we are going to write is l because of its w but fine right ok now why does this relate to model complexity what am i doing here actually by adding this so they are going to see a very detailed analysis of this but i just want to see first whether you get an intuition behind this so by doing that what you are trying to do not allow the model to become very complex right you do not want a model where your weights can take any possible value you just want the weights to be small so you are reducing the freedom on the model right less freedom less complex you get the intuition at least we will see this in more detail but at least you get the intuition why we are doing this so we are using omega remember that we are using this omega theta as a surrogate for model complexity so if you add something in all omega theta just make sure you understand that this relates to model complexity ok fine and now for sgd what would i need for gradient descent just in case you have forgotten what sgd is what do we need nothing we have done it fl gradient of this which is a sum of the derivatives of the two quantities of which you know one right you know this already and what is the other guy alpha w right"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/61_3.wav", "duration": 291.0, "text": "so you see this l2 regularization right one reason why it is preferred is now imagine you have already written code for gradient descent all you need to do is change it at one place add this to your update rule that is all you need and you can think of the vector form of this where you have a vector of parameters you can think of the matrix form of this variable vector matrix of parameters all you need to do is add one term to your update rule so it can be done with very minimalistic change and this would be your update rule now let us see geometric interpretation of this"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/61_4.wav", "duration": 78.0, "text": "what is this quantity zero ok so we now know that the derivative of the loss function with respect to w can be written as this quantity is it ok and i have just derived it step by step there is nothing great about it anyone is can why i am doing this is not clear that will become clear hopefully but what i am doing is clear right is that fine can i move ahead now what we are actually interested in is this quantity because this is the true loss that we are going to deal with right and we just saw in the previous slide that this quantity which is on the l h s is equal to this thing on the r h s this is what we saw on the previous slide can i just go back to the previous slide because the derivative of this was just alpha w now let us start with this so on the next slide let me just see if there is anything else that i need to see here ok so far everyone is clear what i have derived so far why is not clear but what is clear what is being derived so far so i have said that the derivative of the loss function or the regular is loss function can be written as this quantity ok is that fine where w star is the optimal solution for with respect to the un regularized loss function ok and now i have what i am interested in this solution with respect to the regularized loss function ok"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/61_5.wav", "duration": 71.0, "text": "now let w tilde be that solution for the regularized loss function so that means the derivative of the loss the regularized loss function at w tilde is going to be zero nothing great about this but i just told you on the previous slide that i can write this quantity as this quantity that is what we derived on the previous slide ok just take my word that is what we derived on the previous slide ok let just no confidence in me ok that is fine now can you are you if i write it as this just rearranging some terms oh sorry so i am just grouping all the w tilde some terms and this is a matrix is needed here right because i need to i can only add two matrices so what i am just doing is putting the elements across the diagonal everyone understands this everyone gets this step ok"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/61_6.wav", "duration": 76.0, "text": "so now i have a formula for w tilde in terms of w star ok i am going to go a bit further and be a bit bold and compute the inverse also so now i have a exact formula for w tilde in terms of w star so what is this actually what is this relation that i am trying to establish suppose i know the solution with respect to the un regularized loss and now i have added regularization what happens to the new solution so i am telling you the new solution would be smaller weights and so on that is what l2 regularization tells you now you are just trying to make an interpretation for that so i have given you a closed form solution that w tilde is actually equal to this quantity that you see on the right hand side ok why you are doing this is still not clear but right now i just focus on the what part of it this is just some mathematical steps that i am doing anyone who is not comfortable with this now notice what would happen if alpha tends to zero what would be w tilde be w star what do you mean by alpha equal to zero no regularization right so that is just one corner case that i want to do but that is not what we care about anything what that is stupid to do all this and tell you that if you do not use regularization you will get the same solution but that is not what i am going to tell you right we are interested in the case when alpha is not equal to zero ok so let us look at that case"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/61_7.wav", "duration": 93.0, "text": "now i am going to assume that h is a symmetric positive semi definite matrix squared egg in a vacuum ok so if that is the case then i can write h as this i have just done the dash of h eigenvalue decomposition all right ok and i know that since it is a squared symmetric matrix the eigenvalues are going to be eigenvalues are going to be orthogonal yes eigenvalue vectors are going to be orthogonal and that is why i can write this that q transpose is the inverse of q now let us start with whatever we had on the previous slide and substitute what what i am going to substitute instead of h i am going to use q lambda q transpose ok so i am doing that so is that ok i will just go over the steps and let me know at any point if you have a problem what i have done is i have replaced this i by this and its valid because q q transpose is just equal to i i have just taken q and q transpose as common right so this is a c b plus some a z b so i have taken a and b out right is that fine ok now what is the next thing i am going to do this is of the form a b c inverse so i am going to write it as and the inverses are neat right"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/61_8.wav", "duration": 190.0, "text": "this is fine what will happen to this quantity i what is this quantity q and this is what i am left with but there is still something more i can do i guess let us see ok so i can write this entire thing as a diagonal matrix how many of you see that it is a diagonal matrix because lambda is a diagonal matrix i of course is a diagonal matrix i is multiplied by a scalar which is also going to be a diagonal matrix and the whole thing is again multiplied by some diagonal matrix ok what is the inverse of a diagonal matrix the reciprocal of the diagonal elements so i its fine so i have a very neat formula for what w tilde looks like in terms of w star ok again why am i doing all this and god knows but and here d is equal to this quantity"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/61_9.wav", "duration": 152.0, "text": "so now what is happening so first this rotation is happening that no one is denying after rotating what is happening this is a this product is actually a vector that is fine ok what are we doing to every element of the vector scaling it scaling it by what quantity these quantities that every element is getting scaled by the corresponding entry in the diagonal in this diagonal right so the first entry is getting scaled by this the second entry is getting scaled by this and so on ok i just want you to take some thirty seconds and try to figure out where i am headed from here"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/61_10.wav", "duration": 352.326, "text": "now let me end with a pictorial interpretation of this you see two figures here and there is only one figure but you see two different things here can you tell me what this is and what this is that is the first question i want to ask you the hint is that in this lecture we care about the other hint is what was w star the solution for the student refer time one thousand, eight hundred and twenty-three unregulated loss which means which loss l theta you need any more hints sorry this box is the contours of l theta this box contours of omega theta so this thing just ignore this part of the figure for now ok this i have marked as w star w star was the solution when i only had the un regularized loss ok there is the solution when i had the un regularized loss ok so remember the contour maps that we had seen so this is the minimum of that particular function so this is the contour map for l theta that is clear now what probably is not clear is why is this the contour map of omega theta let me just go ahead actually"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/62_0.wav", "duration": 11.0, "text": "so how with that heavy math i will just interline with this something very simple which is something known as dataset augmentation"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/62_1.wav", "duration": 330.84, "text": "so what is dataset augmentation mean so you always given some training data so in the case of mnist you had this training data where you are given these digits images of digits and you wanted to train some classifier so in dataset augmentation what we do is so now we have what is happening here right conceptual is that there some seeing some training data and try to build a classifier and what you doing actually is minimizing the empirical train error that mean it will ensure that whatever you have seen in training is going to look it is going to be perfectly classified whatever we have seen in training that is going to look very good it is going to be the training error on that is the error of those training examples it is going to be very easy now my question is this if a training time you are seeing all this 2s which are roughly vertically drawn right and a test time you see at two which is written like this which is slightly tilted what would happen it will not be able to do a good job on that that means your model is not think of terms that you have used in this lecture not generalizing can you think of a simple trick based on your domain knowledge of how people right digits to kind of overcome overcome this problem you get the question right i am telling you that it is possible that someone writes to in a very tilted manner can you prepare for eventuality eventuality the title of this module was dataset augmentation so what would happen is are given some training data you can always generate for training data from that see here is another training instant that i have created i have just rotate it to two by some random angle i took this image i just rotate it and this is a simple operation that all pixels are moving by a certain angle i could have rotate it more i could have shifted it vertically that means in all my image the two was actually exactly at the centre i just shifted at a bit vertically so i am so think that you are reading one of those kyc forms or bank forms most people would write at the center of the block provided but some people could write to the extreme right or extreme left right so you are preparing for that they saying that ok all my data the digits are well written at the centre but let me just shift them bit so that i can also deal with people who write it at the corner left align or right align instead of center align i could have even shift it horizontally most people would write at the center but some people would write at the top or at the bottom i could blur the image but someone has taken a photo and send it to me and the photo is not very clear or i could just change some pixels randomly right i could add noise all of this is dataset augmentation with the hope that i am capturing with these variations i am capturing enough variations in the data so that i have a better chance of doing something better on the test data is that fine this is all still training data mind you i am still going to compute the empherical train error it is just that now i have blown up my data but much more than what i had initially do you all see by doing this you could have done better on the mnist assignment you could have done better again i am not asking you to do this so now i will do this then i will have supervised data because i know that by this small variations the label is not going to change and what am i using there i am using my domain knowledge right i cannot do this always right i hope you appreciated that suppose that changes the domain a bit and i am given images of defects of motor parts right where i have taken a image and there is a black spot somewhere which indicates defect i cannot go about doing the same thing there i cannot change some other pixels it will just means that the defects is at a different location right but in many cases you can do that so if you are given picture because of dogs and cats because the entire world case about classifying cats and dogs then you could do some rotations you could blur them a bit you could occlude certain questions of the picture and so on and still generate training data right and what you are trying to do is trying to take care of cases that you would end up dealing at test refer time four hundred and twenty-seven right is that clear ok and please be aware that we are exploiting some domain knowledge here"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/63_0.wav", "duration": 9.0, "text": "the next thing that i would like to talk about and this quickly go over this parameter sharing and tying"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/63_2.wav", "duration": 39.522, "text": "so parameter sharing and tying i will just quickly go on this because for the sake of completeness it is there in this lecture but it should it would really make sense when i do convolutional neural networks so for the time being just take my word for it that in convolutional neural networks you do a lot of parameter sharing where as the other place that you have seen parameter tying so that is again something that i am not going to talk about so this is typically used in auto encoders where the encoder and decoder weights are shared and that effectively reduces the number of parameters in the model which effectively reduces the complexity on the model if the complexity of the model goes down omega theta goes down because that is what which wise man told us that time steins lemma"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/64_0.wav", "duration": 7.0, "text": "we go down the next module which is adding noise to the inputs right"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/64_1.wav", "duration": 434.593, "text": "so we have some kind of a noise process and now can you relate that how that was related to regularization that was exactly the motivation in that case that we could have an over complete auto encoder which is a very complex model because it has a large number of parameters and to avoid that we were adding this noise to the inputs so that even if it tries to minimize the training error it is not actually minimizing the true training error right because you have fed some noise to it everyone gets this right ok now actually we can show that for a simple input output neural network right that means you do not have any hidden layer you just have a set of inputs and you have the output layer then adding noise to the input or rather adding gaussian noise to the input it is equivalent to weight decay so this can also be viewed so we will do this part right so we will just quickly do a small derivation where we show that adding gaussian noise to the inputs is the same as doing a l2 regularization that is a very neat idea so this can also be viewed as data augmentation right exactly what i shown on the previous slide you added two you just corrupted some inputs of it that is the same as adding noise to the data so the essentially augmenting the data right you have some training data and just augmenting it so to get more training data is that fine"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/65_0.wav", "duration": 9.0, "text": "so now going on to the next module which is adding noise to the outputs"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/65_1.wav", "duration": 21.0, "text": "so here when you are given some training data this is the label vector that you have been given right where one of these elements is one so these are like zero to nine eight where which digit it is and in this case it happens to be digit two so that element is one right that is the true training data given to you"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/65_2.wav", "duration": 220.074, "text": "so what you could do is actually and actually what you try to do is minimize this quantity p i log q i where what is p i p i is the vector which was given and what is q i the predicted probabilities ok so now when you try to add noise to the output what you actually do is you see that i do not trust the true labels they may be noisy whatever data you have given to me that is one way of looking at it that i do not trust it i will just say that it is noisy the other way of looking at it is that in some way i am ensuring that i do not try to over fit to this label right because now my true whatever i am trying to optimize let me just go to that and let us see so instead what we will do is we will use soft targets"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/66_0.wav", "duration": 8.0, "text": "i will do will do early stopping where again we will get into some of these eigenvector analysis so let us see that"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/67_0.wav", "duration": 13.0, "text": "so next we look at on ensemble methods and this is just to build the intuitions for something known as dropout which is very popular technique in deep neural networks and convolution neural networks and even recurrent neural networks"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/67_2.wav", "duration": 79.0, "text": "so how many you have seen ensembles before seen it in machine learning ensemble was not done in machinery done with ok ravi did it so as a combine so the ensemble is essentially just the combining the output of different models to reduce the generalization error right why does that make sense have these different models all of these would have different biases and variances right so now you are combining them so i will end up with a better thing on the test error right so that is the idea behind ensemble now the models could correspond to different classifiers right for example here i have a logistic regression and svm and a naive bayes i have trained them independently using the same data or different subsets of the data and a test time i am taking a prediction from all of them and then taking an ensemble of those predictions that is the basic idea now it could be different instances of the same classifier trained with different hyper parameters i could have the same neural network a 3layer neural network but trained with different hyper parameters so the hyper parameters could be learning rate it could be batch size it could be the number of neurons in each layer and so on right so it could be same classifier but different hyper parameters different features right so instead of looking at all the one hundred features that i have given i could train these classifiers with different subsets of the features ok or different samples of the training data"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/67_3.wav", "duration": 157.0, "text": "so bagging is one such ensemble method where you have different instances of the same classifier which are trained on different samples of the training data ok so i have one classifiers trained on a subset t one of the training data another classifier trained on a subset t two of the training data and so on right and so each of these model is trained with a different sample of the data"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/67_4.wav", "duration": 45.0, "text": "the terms having epsilon i epsilon j again the same thing they are independent so i can write the expectation of a product as the product of expectations and those expectations are zero so this is what it is going to look like what is this oh sorry actually we had not assumed that the covalence what is this right and what is this covariance i am sorry i have not we had assumed that there is some covariance said wed not assume they are independent right we would want it to be independent but in the general case we will assume some covariance and then i will show you the special case where they are independent so then how many vs do i have here k right and how many cs do i have here"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/67_5.wav", "duration": 25.0, "text": "this summation is k into k minus one right or i equal to one to k and j equal to i plus one to k fine and so this is what it looks like now can you make some inferences from this equation this is what the expected mean square error is going to be now think in terms of variance covariance and tell me when would this be beneficial i have already told you the answer if the errors are independent what would covariance be zero right so then what is the mean square error one by k one by k into v right so that means bagging would work when your classifiers the k classifiers that you are combining"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/67_6.wav", "duration": 97.0, "text": "if the errors are independent then the mean square error should actually have been v right for a single classifier it was v right because mean square error is nothing but the expectation of the error expectation of epsilon i square which is nothing but v but if you are if you are combining k classifiers and if these classifiers are independent in terms of their errors then your mean square error is going to be one by k into v because this term is going to disappear ok now if your classifiers are perfectly correlated then what would happen and basically c is equal to v right is that fine so now what would happen what is the net result if i substitute this as v going to be v right so if you are all your classifiers are perfectly correlated that is the other case we had tried taken and all of them are making errors on the same test instances and the same errors right then you will not get any benefit of doing bagging but if you look at the other extreme where all your errors are independent or all your classifiers are making independent errors then you will get a benefit your expected mean square error would go down from v to one by k into v everyone gets that"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/67_7.wav", "duration": 12.723, "text": "so this was just to develop an intuition that taking an ensemble helps right and using this intuition now we are going to see at how to do this ensemble in the case of deep neural networks"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/68_1.wav", "duration": 2.0, "text": "so in this module we will look at dropout now"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/68_2.wav", "duration": 100.0, "text": "so the intuition that we have developed in the previous module which was about ensemble methods is what that is that ensemble makes sense in most cases because you do not expect the errors of these k models that you are using to be perfectly correlated and we saw that whenever they are not perfectly correlated you are going to get some advantage now how do you do this in the context of neural networks so remember what was bagging multiple instances of the same network trained on different subsets of the data what is the problem with this in the context of neural networks each of these neural networks is very complex training each of these is going to take time and i going to train k of them is that fine right so you decide ok sorry so one option that you have is you train several different neural networks having different architectures right but this is going to be expensive because you have to train k of them the other option that you have is you train the same network but on different subsets of the data this is also going to be expensive so whatever ensambling sampling techniques you can think if in the think of in the context of neural networks which are essentially these two techniques different architectures and take an ensemble or train the same architecture on different subsets of the data both of them are going to be expensive right so now how do you go about it and it is not just training time expensive it even if we manage to train it at test time again when you are given a test instance you have to pass it through all of these complex neural networks each of which is going to take some computation and then take the ensemble of the outputs right so even at test time it is expensive it is not just that that training time it is expense"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/68_3.wav", "duration": 121.0, "text": "so now dropout is a technique which addresses both these issues which issues train time computation as well as test time computation so it effectively allows training several neural network architectures without any significant computational overhead so we will see how that works and it just not training time as i said it also allows us to do this quickly at test time"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/68_4.wav", "duration": 52.0, "text": "so this is the idea now let us see how to actually implement this idea okso suppose a neural network has n nodes using the dropout idea each node can be retained or dropped an example in the above case i have dropped some five nodes to get a thinned network so if there are n nodes what are the total number of thin networks that i can get from it and so that means i can get two raise to n different neural networks am i happy about this or sad about this sad there is just too many neural networks how can i train them actually right so how do i do this i am just creating a lot of suspense without giving you the answer ok so first trick is share the weights across all these networks ok we will see what that means and the second trick is sample a different network for each training instance ok none of which is clear at this point i can see i can read your faces i am good at it ok so let us see how to do that"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/68_5.wav", "duration": 268.0, "text": "so we initialize all the parameters of the network randomly or whatever may be used and start training when i start training i will pick up the first training instance or the mini batch or whatever i am doing we apply dropout resulting in this network what will i do and they forward prop forward propagation right ok now ok we compute the loss and back propagate how some weights are missing right how do i do back propagation now i have deliberately dropped up some of these connections they did not participate in the forward propagation this back propagate which are the parameters which will update now only the ones which actually participated right so i will just do back propagation just look at the red arrows i will just do it over the paths which are actually present in my network fair enough right that is what you meant by normally ok that is normal ok so i will just do it over the weights which actually participated that is fair enough that is the only thing you could obviously do"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/68_6.wav", "duration": 282.0, "text": "and so each thinned network gets trained rarely or sometimes even never but i am not worried about it because it is weights will get updated through some of these other thin networks"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/68_7.wav", "duration": 86.0, "text": "and let us see that a h i learns to detect faces sorry it learns to detect a nose so i am trying to do face detection whether an image is about a face or not and h i is the feature which fires if there is a face somewhere if there is a nose somewhere in the image is that fine now if all these guys start acting lazily ok this guy is going to detect a nose that means definitely face will be there so i do not need to do anything right what would happen now suddenly this guy is going to go away dropped out so then these other guys need to do one of two things either add redundancy that means one of them should also take responsibility for detecting a nose or do it in a different way take responsibility for detecting the lips or the eyes or some other part do you get that right because you know that i cannot co adopted with my other neurons i cannot say that ok in these front facing faces you just detect the nose and will be done and we will all keep quiet right i do not know whether you will do your job properly so i will have to add more redundancy you detect a nose i will also detect a nose or you detect a nose and i will detect something else which helps detecting the feature right so that is why these networks become more and more robust as you add this dropouts"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/68_8.wav", "duration": 39.636, "text": "so that is all that i had to say i still do not know whether i have answered your question or not all of them try to detect nose see as long as that helps reducing the final loss it is fine it is just the case that you would have some training images where the nose is not visible maybe that person is drinking something right so for at least for those training instances someone else has to take care that you detect from the other images right otherwise a loss would not be zero for that training instance so as long as you have some training instances see if all your training instances can be detected just by detecting the nose then there is nothing wrong in all of them trying to detect the nose so if the training it is like that it will happen but the hope is the training data is not like that right is that fine so we will end here"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/69_0.wav", "duration": 56.0, "text": "welcome to lecture nine of cs7015 today we will talk about greedy layer wise pre training better activation functions better weight initialization methods and batch normalization so today\u2019s lecture is more like tips and tricks to make deep learning work so when you are actually experimenting with deep learning in practice what are some of the things that you need to take keep in mind and it is also my way of connecting the history that we saw to where we are today right so there were certain things which we saw in the history and now i will try to bring those back and connect to where we are headed from here right where we have reached today and where we are headed from here so that is with that in module one i will do a very quick recap of training neural networks and not take more than five minutes and i need it for a specific purpose"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/69_1.wav", "duration": 88.0, "text": "so we already saw how to train such a very shallow neural network what was the learning algorithm gradient descent and this was the update rule right in particular i wanted you to notice that the gradient actually depends on the input so when you compute the gradient formula you have this multiplication by x so it is proportional to the input and this is one fact that we will use it at least a couple of cases in the lecture today so this was a very shallow single neuron network what if we have a wider network still which algorithm student gradient descent refer time one hundred and forty gradient descent ok and we just have these three different formulae and for each of these formulae note that the gradient or rather this gradient depends on the input that you are feeding in ok i did not keep this in mind"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/69_2.wav", "duration": 33.0, "text": "and finally we saw this thin so we saw a wide network we saw a thin network now we will see a wide network and a deep network right sorry we saw earlier we saw a wide network and a deep network now we see a wide and deep network and here again you have compute the gradient by applying this chain rule across multiple paths and that is what we use and we call it back propagation and remember again they are the same thing holds that the gradients at some point are proportional to the input at that layer everyone remembers that ok"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/69_3.wav", "duration": 163.005, "text": "so this is important so what we have is things to remember from what we have seen so far is that so training neural networks is basically a game of gradients right so you compute the gradients and everything depends on those how will you update the weights and everything from there on is about the gradients and these gradients actually tell you the responsibility of the parameters towards the loss and you appropriately update them and we saw a variant way different sorry various variants of how to use the gradient so we saw the gradient descent we saw nag momentum and all but in all of these the underlying core thing was to compute the gradient and then do some manipulations based on that and the other key thing is that the gradient at a particular layer depends on the input to that layer ok"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/7_0.wav", "duration": 16.0, "text": "now since i mentioned rl so we will go on to the next chapter which was now becoming much more ambitious with what you can do with deep learning and people started beating humans at their own game quite literally"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/7_1.wav", "duration": 20.0, "text": "so there was this starting with atari games in two thousand and fifteen where resources from deep mind show that you could train a deep neural network to play atari games and do much better than what humans do so that is something that they were able to show on atari games and then people started looking at other game"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/7_2.wav", "duration": 20.0, "text": "so then there was this go and this popular tournament and which alphago which is deep reinforcement learning based agent was actually able to beat the reigning champion at that time one of the best players of go at that time"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/7_3.wav", "duration": 11.0, "text": "then even at poker were something known as deepstack which is again a deep reinforcement learning based agent which is able to beat eleven professional poker players at this game"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/7_4.wav", "duration": 15.483, "text": "then other games like defense of the ancients since on which is a much more complex strategy based game where again deep reinforcement learning based agents have shown a lot of success in beating top professional players on this game"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/70_0.wav", "duration": 10.0, "text": "so with that we go on to the next module in which we will talk about unsupervised pre training"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/70_1.wav", "duration": 26.0, "text": "so this work which i am going to talk about they trying to understand what has changed since the late 90s or the early two thousand how did deep learning become so popular despite this problem with training them right this problem was there so what happened to them solve it right and this field actually got revived by this seminal work by hinton and others in two thousand and six"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/70_2.wav", "duration": 144.0, "text": "so let us see what that idea was so this is the idea of unsupervised pre training in the original paper they introduce idea in the context of something known as r b m\u2019s which we will do in the last thirty-three percent of the course but we could do the same with auto encoders which we have already done so in this lecture i am going to talk about this idea in the context of auto encoders"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/70_3.wav", "duration": 169.0, "text": "now at the end of this what would happen yeah what would h one learn student refer time three hundred and nineteen it will learn an abstract representation of x was that our original task what were we interested in student refer time three hundred and twenty-nine in the classification task but we are doing something very different why we will see ok now guess what would the next step be does this make sense"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/70_4.wav", "duration": 359.0, "text": "i will after this layerwise pre training is done i will add my output layer now all the weights in my network for every layer have been initialized and they have been initialized in a way that that layer learns a good abstract representation of the input right that is the thing that we have achieved at the end of unsupervised pre training that every layer has learned and more and more abstract representation of the input right now i will keep all these weights initialized to whatever i learned in the pre training setup does that make sense so that means instead of taking this big network with the output layer and initializing the way it is randomly i am just going to use whatever weights i learned using the unsupervised pre training ok so can you tell me what has happened in terms of the error surface and so on or my movement in the w b plane or in this case this very high dimensional w plane i have reached some configuration for the w\u2019s where i know that each of these layers is a good meaningful representation of my original input right is that a fair statement in english how many of you agree with this ah anyone has any questions at this point one layer weights that is what you do in answer because if you train all the four then you are again entering the same problem which you had earlier right you cannot back you cannot back propagate through all the four layers because now it is a deep network and we know that does not work so at every layer you fix whatever you have learned so far and at a time you are training only one layer so that is one interesting way of looking at it right you know that the deep neural network with four layers was not trainable so now we have reduced it to one layer at a time i knew that one layer at a time works right is that fine now i will add the output layer and what will i do train the weights of the student output layer refer time seven hundred and fifty-three i will not just do that i will fine tune the entire network that means i will train the weights of the output layer and i will also fine tune the entire network but now i am contradicting myself i just gave an answer to him that again i am doing this deep training and i know that deep training does not work but this actually works do you get the difference right one is that when i start from i take this big network i start from random weight initialization and try to train it that is the story from one thousand, nine hundred and eighty-six to two thousand and six that in most cases these networks did not converge so now in two thousand and six we came up or someone came up with this idea of unsupervised pre training where you train the layer network one layer at a time you do up till the last layer now you add the output layer and then fine tune the entire network that means back propagate over the entire network is a set up clear to everyone how many you understand the setup now again when i am doing the last step which is known as fine tuning i have to back propagate over the entire network because i am saying i will adjust all the weights but suddenly this works as compared to starting from scratch you see the problem and you see why this is important then because this has now given you a way of training deep neural network i still not told you why it works we will delve into it but not really give any concrete answers because concrete answers do not exist but we will at least try to get some intuitions behind why it works so you get the setup now that this is what was happening till one thousand, nine hundred and eighty-six to two thousand and six and now with this idea suddenly deep neural networks were being able to train well so in effect what we have done is we have initialized the weights of the network using the unsupervised objective right so now initial starting with random weights we have some weights which cater to the unsupervised objective that we had and the unsupervised objective was us layer wise reconstruction so that is what has happened in plain english is that fine everyone gets that"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/70_5.wav", "duration": 5.0, "text": "so let us first examine the case when it is because of better optimization"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/70_6.wav", "duration": 207.0, "text": "so let us first understand what is the meaning of this question when i ask is it because of better optimization then the question that i am asking you is that the first set up where i was trying to train everything from scratch compared to the second set up where i had this unsupervised pre training is it that the optimization problem becomes easier in the second set up now if the optimization problem becomes easier what do i actually mean by that that i was able to drive the dash to dash student loss to zero loss to zero right so is it that this is the optimization problem that we were interested in so is it the case that in the absence of unsupervised pre training we are not able to drive the loss to zero for the training data and hence poor optimization right that if you do not do this unsupervised pre training even for the training data we cannot drive at loss to zero that means our optimization problem itself is not working properly right i mean the problem is fine but the solution is not good you get that do you understand what is the subtle meaning of this how many if you get this so let us see this in more detail right"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/70_7.wav", "duration": 8.0, "text": "so that tells us something about what optimization means and whether this was an optimization problem or not"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/70_8.wav", "duration": 222.0, "text": "so let us look at the other question is it because of better regularization so what does regularization do or you gave the exact answer it constrains the weights to lie between lie in some regions so it does not allow the weights a lot of freedom right and so you know what l one regulation does it constrains the weights to this box and l two regularization constrains us to this circle why no why this i know this but why student refer time one thousand, six hundred and one in why the circle i am pretty sure most of you do not know what you are saying but you are saying the right answers but anyways i will test this in the quiz so i have given you another quiz question on camera so yeah so a prevents a loss from taking large values"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/70_9.wav", "duration": 233.0, "text": "so some other experiments have also shown that pre training is more robust to random initializations now what do i mean that mean by that so in these two graphs that you see here so this on the x axis you have the number of layers that you add to your deep neural network and on the y axis you have the error that your network gives when you try different initializations right so this box actually tells you the variance in the error so that means i tried training a network with four layers and i tried different initializations and the error varied in this range ok is that good or bad what would we want typically something which looks like the plot below right where all these variances are little that means even once you do unsupervised pre training right it is more robust to random initializations random initializations of what student refer time two thousand and fifteen the original random initializations from which point you started the unsupervised pre training ok because once you have done the unsupervised pre training that is your initialization everyone gets that"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/70_10.wav", "duration": 73.107, "text": "because what has happened since two thousand and six and two thousand and nine is that we have better optimization algorithms which are rmsprop ada grad adam even so on right many various and even now that research area is active as i was saying just in december there was a paper which pointed out some flaws in adam and how to improve it and so on we are better regularization methods the most prominent among those being student dropout dropout so these two are things which you have already seen today we are going to talk about better activation functions this is again something which evolved that maybe sigmoid tanh are not good so maybe something else is needed and then better weight initialization strategies so then people took this inference oh one way of looking at unsupervised pre training is that it actually initializes the weights in a better way from where on it becomes easier for me to reach convergence so why do not i come up with better weight initialization methods itself instead of relying on this indirect way of initializing the weights so you get this so get the whole picture now what we have been doing in the past few lectures and how it connects to the history and these studies which were done from the period two thousand to two thousand and nine how many if you get the whole picture ok so that is where we are now so today we are going to talk about better activation functions and better weight initialization methods"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/71_0.wav", "duration": 6.0, "text": "let us start with better activation functions"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/71_2.wav", "duration": 96.0, "text": "so before i get into activation functions right let me first tell you why i care about activation functions why do i actually want to come up with better activation functions so will start with the following question what makes deep neural networks powerful among other things what is this one thing which makes it powerful so let me give you this intuition"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/71_3.wav", "duration": 27.0, "text": "so what you are learning eventually we will just y as a linear function of x and initially at some point we started off with such linear functions right w transpose x in the case of perceptron and mp neurons so what does that lead to what kind of decision boundaries does that lead to linear decision boundary so if you do not have these nonlinearities we cannot have these arbitrary decision boundaries will only be left with linear decision boundaries"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/71_4.wav", "duration": 31.0, "text": "in particular will not be able to solve this problem that we had right we were given some red and blue points and there was no way to draw a line such that the red points are separated from the blue points what we needed is some kind of circles or ellipses to separate the red points from the blue points that cannot be done with linear decision boundaries that can happen only if you use a deep neural network with nonlinear decision boundaries and we actually have a proof for that what that proof the universal approximation theorem actually towards right"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/71_5.wav", "duration": 22.0, "text": "so that is why nonlinearities or the activation functions clear a very important role in the success of deep neural networks right hence you want to examine them very closely and see what are the newer kinds of nonlinearities that have been proposed so we always start with the basics so will start with sigmoid see what are the problems with sigmoid and then see what we can do to solve some of these problems"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/71_6.wav", "duration": 36.0, "text": "so this is what the sigmoid function looks like you have seen it a million times and it actually constrains the input to zero to one right so it takes some input and it constrains it two values between zero to one now since we are always interested in gradients right because the entire training and that is why i did that precursor in the first module the training always depends on gradients so it is always important to look at what does the gradient look like so we know what the gradient looks like we have computed this is just sigmoid of x into one minus sigmoid of x so now let us see what happens if you use such a sigmoid neuron in a deep neural network"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/71_7.wav", "duration": 51.0, "text": "this is a deep neural network and without loss of generality i am going to use a thin deep network but the same holds for a deep for a wide deep network also so suppose you are interested in computing the gradient with respect to w two right at some point in the chain rule you will have this term how many of you are convinced about this ok and that will lead to this could that cause a problem so at some one of the terms in your chain rule is going to be this dou h three by dou a three i am assuming all of you are convinced about that and i have given you the exact formula for dou h three by dou a three will that lead to a problem student refer time four hundred and thirty-two good so what is the consequence of this to answer this we need to understand the concept of saturation right"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/71_8.wav", "duration": 85.0, "text": "so a sigmoid neuron is said to have saturated if it is output is one or zero or rather close to one or close to zero ok what would happen in that case to the gradient student refer time four hundred and forty-eight it will vanish right because sigmoid of x into one minus sigmoid of x so it either extremes is going to vanish and you do not even need the formula for that you can just see it from the diagram right because the gradient here is going to be zero that is obvious right it just a what horizontal line so this gradient would be zero so fine why does it bother us what is our entire training premise based on gradients right what does our update rule what happens if this guy is zero no update e the weights just stay where they are right that means the training gets stalled right so think about this right if all the neurons in your network have saturated that means all the weights the gradients will be zero that means all the weights will remain where they are you pass another input nothing is going to change right it still be zero so if this neurons have saturated your training will just stalled ok so that was one of the reasons which is to cause problem in training deep neural networks earlier right"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/71_9.wav", "duration": 135.0, "text": "so that is one of the reason why it was not converging because these weights used to these neurons is to saturate so this is one problem with sigmoid neurons a saturated sigmoid neuron can cause the gradient to vanish"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/71_10.wav", "duration": 305.0, "text": "consider what would happen if you use sigmoid neurons and initialize the weights to a very high value they will start saturating and hence you will have this problem of vanishing gradients ok everyone gets this so this is a problem at this sigmoid neurons"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/71_11.wav", "duration": 4.0, "text": "so suppose this is the optimal w star"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/71_12.wav", "duration": 54.0, "text": "and we start with some random initialization because that is why we are going to start then the only way i can reach it is i may by making a series of this kind of movements right as the exact pattern is what will have to take because these are the only movements which are allowed or some movements which are allowed and it will lead to a certain cryptic pattern and i will not be able to have the complete freedom of moving in the direction which would have directly taken me to the optimal so that is a problem with something not being zero center and lastly sigmoids are expensive to compute because you have to do this exp right it is not something as easier as something else that we will see in the lecture today ok so these are some problems with sigmoid functions student refer time one thousand, four hundred and fifteen so this is some issues that were they with sigmoid functions so this pointed that ok maybe we should try better activation functions"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/71_13.wav", "duration": 54.0, "text": "that is why tanh become very popular but tanh is not something which happened post two thousand and six right so this was like ninety-two or ninety-three when i think yan lacunae had started moving to tanh from sigmoid functions right now again here other inputs are compressed between minus point to one ok where inputs are now zero centered which takes care of this problem which i mentioned at the end that these directions of movements are constrained and was the derivative of this function one minus tanh square right what happens at saturation even without looking at the formula the gradient would vanish to zero right so the vanishing gradient problem is still there what you have solved is a problem of zero centering and that itself used to give better results than just using a sigmoid function but it is still computationally expensive because you still have to do these e raise two components right the you still have to compute these exponential powers so it is still computationally expensive"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/71_14.wav", "duration": 33.0, "text": "so then in around two thousand and twelve i guess is when this relu was introduced in the context of convolutional neural networks right and this is what the relu function actually looks like is this a nonlinear function it just looks like a line right why is it a nonlinear function it is a nonlinear function right because x is you cannot write x the output as a function of i mean as a linear transformation right so you have this zero in fact if you take two relu functions smartly"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/71_15.wav", "duration": 37.0, "text": "you can actually get the sigmoid i mean you can get an approximate for the sigmoid function so you can go back and check this right so if you take these two functions and subtract one from the other what is this this is a relu function this is also a relu function right so i define relu as max of zero comma x so both of these are relu functions some variant of that and now if you subtract one from the other you will actually get a approximation of the sigmoid function right and this cannot happen if you have two linear functions take any two linear functions you will not be able to get this kind of an approximation"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/71_16.wav", "duration": 26.0, "text": "so relu is a nonlinear function what are the advantages of relu one is it does not saturate in the positive region right it is computationally very efficient the output is either zero or x there is no powers nothing like that right and it practice it converges much faster than sigmoid and tanh so that is what this two thousand and twelve paper show and now relu has actually become more or less the standard in all convolutional neural networks"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/71_17.wav", "duration": 422.0, "text": "but there is still a caveat while using relu ok so the derivative of relu we can see that if x is less than zero then the derivative is going to be zero right and if x is greater than zero then the derivative is going to be one and that straight away follows from the definition of relu which is zero or x so when it is zero the derivative will be zero and when it is x the derivative will be one so now consider this given network and let us assume and this is not a very far faced assumed assumption it can happen in practice that at some point a large gradient causes the bias b to be updated to a large negative value so what i am saying is that something happens and b gets updated to a large negative value"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/71_18.wav", "duration": 70.0, "text": "so then someone said leaky relu fine parametric relu is fine let us try to do exponential relu ok so it has all the benefits of relu it ensures that at least a small gradient will flow through even when your inputs are negative that means it avoids this dead neuron problem again close to zero centered outputs but it is expensive because now we have added this exponential right so these are all ideas which came out during this period and all of them were shown to work better than the other and so on and of course at the end i have to tell you a final conclusion right whenever i give you so many possibilities so i have given you sigmoid tanh relu parametric leaky exponential now what do you use right this the idea is not to confuse you but to give you one solution which would largely work yeah what regularization student refer time two thousand, four hundred and forty-five yeah you could have done yeah that refer time two thousand, four hundred and forty-eight there is exactly so a lot of this research right which has happened in this period it is not a lot of it is juristic right you solve one problem with relu ok the neurons and saturated ok just make it something which does not saturated"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/71_19.wav", "duration": 60.0, "text": "so that is there it is possible that the other solutions would also go there is not that this is the only solution which works now then someone came out with max out neuron which is a generalization of relu and leaky relu why do i say it is a generalization what was relu that means w one equal to b one equal to zero w two equal to one so it is a special case of the max out neuron what about leaky relu this was parametric value but again what about so now what is happening w one equal to alpha b one equal to zero w two equal to one b two equal to zero so you see how it generalizes right so this is how these variants keep kept coming up"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/71_20.wav", "duration": 92.707, "text": "now the problem of course is doubles the number of parameters right because you earlier had only w transpose x plus b now you have w one transpose b one w two transpose b two and so on right so it is actually doubling the number of parameters that you have"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/72_0.wav", "duration": 7.0, "text": "so in this module we will talk about better initialization strategies"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/72_1.wav", "duration": 404.0, "text": "so this is where we are in the story right we saw that deep learning has evolved and at least these are the four things which have happened so we have by the way this slide is incomplete what are the other things which have happened actually which you already said in the beginning two more things which are not technical but which happened more data right and more compute but these are not really technical in the sense that i mean this just happened we have large amounts of data that means more data means what if you are more data for training you would have complex networks but not over fit right because you have so many so much of data right and more compute of course it speeds up some of these matrix computations which happen so remember in a deep neural network most of the things which are doing are matrix matrix operations right you are taking are that is what exactly you did in your back propagation assignment you did a lot of matrix vector computations and so on and the advent of gpu\u2019s this became very very fast rate orders of magnitude fast so this two which are here as nothing much to talk about that is just something we all understand what has happened they and so now we will talk about better weight initialization strategies"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/72_2.wav", "duration": 49.0, "text": "so this at least this in practice you are not supposed to initialize the weights to 0s and equal values that is what we have learned so far now for the rest of the to convince you about some other weight initialization methods what i am going to do is i am going to take a feed forward network where you have as input some thousand points each of this point is five hundred dimensional and the input data is drawn from a unit gaussian what i mean by that is you have this x one two x one five hundred rate for the data instance one so all of these five hundred dimensions come from a unit gaussian is that fine so this comes from a unit gaussian this comes from a unit gaussian and so on ok that is what i am going to assume"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/72_3.wav", "duration": 28.0, "text": "and the network has five layers each layer has five hundred neurons the input is five hundred neurons each of the five layers is also five hundred neurons and now we will run forward propagation no backward propagation no loss nothing and i am not even giving you an objective this is just some input and i just want to see what happens up to the last layer i am not even bothered about the actual last layer that means i am not trying to minimize any cost entropy squared error loss anything"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/72_4.wav", "duration": 104.0, "text": "so let us try a few initialization strategies so we realize zero is not good realize equal is not good so let us try some random initializations but small weights ok and this is my way of randomly initializing with small weights so my w is a matrix of size fan in into fan out rate which is n cross n ok the number of weights coming in and out rate so n cross n and i am drawing from a uniform distribution and then multiplying it by point zero one which ensures that all the weights are very small you get the setup now with this i am going to start with the input and then keep doing these transformations so i will do w transpose x plus b pass it through a sigmoid and do this five times because i have five deep layers now this is what happens to the activations across the five layers so the first layer remember that we had drawn from a unit gaussian right so that is what the data input data looks like so this is the first layer which is the input data basically and then this is what happens across the different layers so what is actually happening and this is for the tanh activation function there is no variance in the output of so this tells me so this basically tells me that for all the neurons what is the average value that i am getting right and i should ideally get some histogram that for some neurons i am getting the value minus one for some neurons minus nine eight and so on but what this is telling me is as i keep progressing across the layers all the neurons have very similar values and they are all close to zero this is what actually happens in practice i have just actually run it and computed the histogram"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/72_5.wav", "duration": 143.0, "text": "and if i use sigmoid activation functions again something similar all the values tend to be close to the center which is five so this is five and although i had started with a nice gaussian distribution"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/72_6.wav", "duration": 65.0, "text": "now let us try to do the opposite of this very small values did not work so let me try large values and for large values i just sample from the uniform distribution i will get some numbers between zero to one now can you guess what will happen remember summation wi xi all your weights are large so why am i saying that number between zero to one is actually large it is not by all practical because this is going to give me this function is actually going to give me numbers between zero to one why am i calling them large weights student refer time one thousand, two hundred and fifty-four no i will i just talked about the weights assume there is no biases how many of you get that answer remember there are five hundred neurons so if you have five hundred small values that summation is going to be still large right if you all of these are four or five which still looks small but if you have two hundred and fifty of these or if you have five hundred of these the resultant sum could be somewhere of the order of two hundred and fifty right and that is very large because if you pass that to a sigma and neuron what will happen saturation right so you get this why i am calling these weights as large"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/72_7.wav", "duration": 157.0, "text": "so and this is actually what happens so when i have these tan h activations across all the five layers i observe that my neurons saturate i either get minus one as the output or plus one as the output and same thing happens if i use sigmoid activations i either get zero as the output or i get one as the output right neurons saturated means what will happen gradients will vanish right so even if you initialize the weights to very large values all your gradients are going to be close to zero because they are going to vanish and again you have a problem so what have we seen so far zero is not good equal is not good small weights is not good large weight is not good then what do we do"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/72_8.wav", "duration": 70.0, "text": "now i will assume that all my inputs are zero mean fine we have been assuming that forever and all my weights are also from zero mean ok what is the effect of that which quantities will disappear this will disappear because mean as zero means the expected value of the weight is zero so the square of that is zero an expected value of the input is zero the square of that is zero so what am i left with summation where i variance of xi into variance of w1i ok now i am going to assume that the variance of xi is equal to the variance of x that means it is the same for all the i\u2019s so i had this remember i had these five hundred inputs so i am assuming that for all the inputs the variance is the same they all come from a similar variance distribution and i am also going to make the same assumption for the weights fine and then i end up with this neat formula that the variance of s11 is equal to n times the variance of w into variance of x right because i assumed that all these terms are equal and there are n such terms everyone is fine with the maths so far with the assumptions that we have"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/72_9.wav", "duration": 44.0, "text": "so in general for any of these neurons right instead of just s11 i could take any s1i and this is what the variance is going to be variance would turn out to be because i have assumed that all the weights and all the inputs come out from the same variance distribution ok from a distribution having the same variance now let us what would happen if this quantity is very greater than one the variance of s1i would be very large right and what would happen if this variance tends to zero variance would be very low so i am just giving you two extremes to build the intuition and let us see what we are going to do with that intuition fine"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/72_10.wav", "duration": 377.0, "text": "now let me add one more layer and see so i have added one more layer and using the same procedure as above he will arrive at variance of s21 is actually given by this formula and actually what has happened here is that this is si had xi earlier but now instead of xi i have s1i because those are the inputs to this layer right so this is exactly the formula that we had arrived at earlier assuming zero mean and the same variance for all the weights and the inputs and i am arriving in the same formula for the next layer where instead of x i have s1i so this will result in this quantity ok but i already had a formula for a variance of s1i what was that n into this quantity so i will just substituted it there so i can say that variance of s2i is actually equal to this i just substituted this value so that turns out to be i have a square here when i have two here so you see where i am headed with this what will be the variance of s k i this raised to k and is on everyone gets this ok i can just continue the same analysis and i have assumed that these weights and always are the same variance right"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/72_11.wav", "duration": 17.0, "text": "you see a good spread in the weights and remember actually for sigmoid although these values look close to each other but this is the zero to one range this is actually minus one to zero which will not happen for sigmoid so within the zero to one range you get a good spread if you initialize the weights this way"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/72_12.wav", "duration": 35.0, "text": "but it turns out that this initialization does not work for the relu function in the relu function you still see this effect that you started off with a good spread but as you keep going across depths this spread disappears why would that happen to someone gave an intuition for this and is again one of those heuristic things that in the case of relu you need to account for this divided by half because half of the relu is not active right half of the relu is zero"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/72_13.wav", "duration": 50.02, "text": "so you need to account for that fact and do this simple trick that instead of taking the square root of the fan in you take the square root of fan in by two because you know that half the times it is not going to produce any output right so that is a very simple heuristic that someone tried and that leads to better activation functions better activations across all these layers right so as you see across all the layers the spread is good now so the same idea ok so now you have a good way of initializing neurons so this should help you in your future assignments fine so this is how what you have learned about how to initialize your weights and it makes a lot of difference to how your network will behave right and that is what the i was trying to show that by computing these activations across different layers and i showed that as you change these initializations strategies you get better activations"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/73_0.wav", "duration": 16.0, "text": "now we will end with something known as batch normalization which is again almost a defacto standard at least in convolutional neural networks so if you are dealing with convolutional neural networks you will use something known as batch normalization"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/73_1.wav", "duration": 10.0, "text": "so let us see what it is so this is again something which is some method which allows us to be less careful about initialization so let us see why that happens"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/73_2.wav", "duration": 266.0, "text": "so to understand the intuition behind this let us consider a deep neural network ok and let us focus on the last two layers h four and h three now typically will use some minibatch algorithm for training right so we will use minibatch version of gradient descent or minibatch version of adam or any of these algorithms right now what would happen if there is a constant change in the distribution of h three no just think about the question that i am trying to ask you so as far as these two layers are concerned h three is the input and h four is the output it does not matter what has happened so far or in particular does not matter what x was whether it came from a normal distribution or whatever distribution right at this point my input is h three and my output is h four now i am training it in mini batches what if across batches my distribution of h three looks very different what would happen is it a good thing or a bad thing it is a bad thing right so if you have training data right just think of this as i said just focus on this layer if you have an input which is not following a fixed distribution is constantly changing during your training then that is always a bad thing right because you try to adjust to one distribution and now again the distribution is completely changing so that always makes our training very very difficult right so if you have a very fluctuant distribution then a training is going to be hard ok so that is the intuition that i want to build"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/73_3.wav", "duration": 271.0, "text": "this is what a deep network will look like with batch normalization right so what will happen is you passed an input you computed this tan h then you will have this batch normalization layer watch is what is the operation that the batch normalization is going to do this is the operation that it is going to talk ok everyone gets that and now it gives me a unit normalized distribution sorry it gives me a input coming from a zero mean unit variance distribution and then i pass it to the next layer again at a batch normalization layer so after every layer you will actually add a batch normalization here now my question is is this legal what is legal in this course anything that is differentiable right so you have to make sure that if we have added this operation it should be a differentiable operation so that you can come so now the gradients have to flow all the way here right so that means i should be able to compute the gradients with respect to this so now this is one of my a i and i should be able to compute dou a i with respect to something or rather the loss dou of the loss function with respect to a i by turns out that the operation that you have done is actually differentiable"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/73_4.wav", "duration": 340.229, "text": "so now what we will do is we will compare the performance with and without batch normalization on mnist data using two layers"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/74_0.wav", "duration": 8.0, "text": "so today we are going to talk about learning vectorial representations for words"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/74_1.wav", "duration": 517.068, "text": "so these are the acknowledgement slash references for where are the things that i have referred to by preparing for this lecture so you can just go this some of these are also available as video lectures on youtube can take a look at them also in the first module we are going to look at one hot representations of words"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/75_0.wav", "duration": 26.0, "text": "so what we saw now was sparse representations or one hot representation sparse because only one bit is on from there we will move on to something known as distributed representations of words and you have already seen that sparse is in theory but it gives a very simple recipe of converting words to vectors but it does not serve much purpose"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/75_1.wav", "duration": 242.0, "text": "so let us see what distributed representations of words are so this around one thousand, nine hundred and fifty-seven j r firth made this very profound statement that you shall know a word by the company it keeps and this of course a play on some other similar code but what does this actually mean so it means that you want to know what does the word bank convey or what is the essence of the word bank right what this code says is that if you want to know about bank you should say you should see the company that it keeps that means what are the other words which appear typically in it is neighborhood and of course when you have a large amount of corpus given say the entire wikipedia of course at that time wikipedia did not exist but any large corpus and does this led to something known as distributional similarity based representations so to understand this we first have to understand the idea of a cooccurrence matrix"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/75_2.wav", "duration": 41.0, "text": "so now each row gives us the vectorial representation of the word so we have seen how we have moved from sparse representations to distributed representations so now take a guess now would this vector be sparse so we saw the extreme sparse right which was one hot now the vectors which you get here are they going to be dense or still sparse sparse right because every word does not appear with every other word right you still have these v dimensional vector and there are some words which will appear with very few words right so you expect to have non zero entries in very few columns right so these representations are also sparse"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/75_3.wav", "duration": 36.0, "text": "so there are some problems some of which are fixable so we look at the fixable problems first the first thing as the stop words are very frequent so these counts should be very large so if you take the entire wikipedia corpus and you take the word machine or system then the words the and for and so on would have appeared like more than one thousand times in the context of the word machine right and as compared to the other words like system or user they would have appeared much fewer times so this kind of skews your counts right it is like highly biased in the favor of stop words so how do you deal with this"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/75_4.wav", "duration": 272.0, "text": "so there are two ways one is ignore frequent words right so that is the solution which i suggested earlier that your number of columns would be less than the number of words is that fine so you do not actually consider frequent words at all the other is user threshold t so that means in these columns like for and with and so on whatever be the entry if that crosses a certain threshold then i will just replace it by that threshold is that clear so i am just saying that this means that the word has appeared more than one hundred times and i am not interested in keeping the actual count which was more than one hundred i just saying that more than one hundred is enough for me right because i know that all the other entries are going to be much less than this so just like replacing it by a very large number instead of actually counting that number"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/75_5.wav", "duration": 67.787, "text": "what about these representations still large it is still of size v it is still very high dimensional still very sparse not as parse as the one hot encoding but still sparse and it grows with the size of the vocabulary so now remember that penn treebank at fifty k words google 1t corpus at tha thirteen million yeah so it keeps going with the size of the corpus so now how do you know how do you fix this i wish i had that harry potter thing anyone remembers that spell to wipe out your memory how would you deal with it so you now see how it connects so now again you have ended up in a situation where you have a very high dimensional matrix right and you are looking for ways to reduce the dimensions so we will go back and rely on things that you have learned and one of those was svd right so you can use singular value decomposition why did i say svd and not pca because this is not necessarily a square matrix a this could be a rectangular matrix and for all practical purposes svd is just a generalization of pca"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/76_0.wav", "duration": 8.0, "text": "so in this module we will talk about using svd for learning word representations"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/76_1.wav", "duration": 91.0, "text": "so what does singular value decomposition do yeah these are all possible variants so people have tried various things and one of the ppmi one is the is the most reliable thing that is what is given but you can think of i mean you said one there are ten different things which we can do for the cooccurrence matrix right but this is the most popular and most stable thing to do yeah what is the single value decomposition do can you read it from the slide please it gives the rank k approximation of the matrix so let me start defining a few things so from now on when i refer to the cooccurrence matrix i would mean the xppmi matrix right which was the positive pmi which was replacing all negative pmis by zero and just do not have this nasty variable i will just call it as x so from now on whenever i say x i mean the positive pmi cooccurrence matrix ok so that is what this matrix is ok and we know that svd gives us this reconstruction of the original matrix and fine it gives us the best rank k approximation of the original matrix and it discovers the latent semantics in the corpus everyone remembers this like that is what we were by we were using pc and svd and auto encoders it was able to discover some latent semantics and we will concretize this intuition with the help of our current example but for now i just want you to recall that it helps in discovering the latent semantics"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/76_2.wav", "duration": 60.0, "text": "now notice that this product and i think i have done this in one of the assignments or something can be written as a sum of the following products so i can write it as sigma one u one v one transpose sigma two u two v two transpose and so on can you tell me what this sum is this is the rank two approximation of the original matrix and i keep taking more terms i get more and more rank approximations of the original matrix ok now and we all know that ok we all hopefully know that what is the dimension of this it is a scalar vector matrix scalar vector matrix studentmatrix ok now of course you will say matrix but what is the dimension of the matrix why is it a matrix it is an outer product of two vectors right this what is the size of this n cross one into n cross one so that sorry one cross n that gives you n cross n matrix everyone gets this otherwise how is it a rank one approximation you have to get the original dimensions right everyone is clear with this is an outer product"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/76_3.wav", "duration": 25.0, "text": "and it belongs to r m cross n ok and if we truncate the sum at the first term we get the rank one approximation and by svd theorem we know that this is the best rank one approximation now what does this actually mean that this is an approximation what do we mean by that so we will see that on the next slide and similarly in the same way if we truncate it in the second term you get the same best rank two approximation"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/76_4.wav", "duration": 62.0, "text": "now what do we mean by approximation here actually and i mean to say approximation always in this course at least try to think in terms of compression how many elements are there in the original matrix m cross n that is how many elements you need to describe the matrix completely if you do a rank one approximation how many elements are you using m plus n plus one right so the original matrix has m cross n entries entries and when you do a rank one approximation you have m plus n plus one entry so that that is the approximation right so you are trying to really compress the original data using only these many variables you get that ok and if we do a rank two twice this right so as many rank i mean as deeper as you go in the sum you will have that many elements to do the approximation ok but what is important is that the svd theorem tells us that this is not just any random approximation but this is the best approximation that you could have done that means if you wanted to use only these many elements these are the best elements to use right everyone gets that"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/76_5.wav", "duration": 76.0, "text": "so as an analogy consider this right suppose you are given eight bits to represent colors ok and this is how you represent very light green light green dark green and very dark green this is what your representation is in this original 8bit representation there is some similarity between the colors but it is still a bit latent but now if i were to ask you to use only four bits to represent these colors what would you do the lowest significant bits if you use the first four no then use only get very light that is not the essence of that color right you need the color to be there so if you compress what would happen is so that is what happens in when you go from two hundred and fifty-six bit colors to higher or lower right the distinctions between the colors go off so all of them would be compressed to green well that is the most important important information in terms of the color right because you need to be able to distinguish between green and red as suppose to very dark and very light that is the more important information that is there right so when you compress it the most important information in that entity should be retained and that is exactly what svd does when it does a compression it retains the most important information in the corresponding entries is that clear is the intuition clear fine"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/76_6.wav", "duration": 119.0, "text": "so let us actually do this so this is my original cooccurrence matrix x and i just repeat when i say x i mean x ppmi and now i have done svd and i have done a low rank approximation of it i do not know what was the value of k i selected but some value of k it was definitely greater than one or two so now you see a low rank approximation of x what is the first obvious thing that you notice it is dense now it is the longest sparse now can you tell me something about the colored entries what was happening in the original matrix x the word system and machine was never cooccurring because of which their value was zero same for human and user but remember there is some important information in this matrix which also tells you what are the words with user appears with and what are the words with human appears with and that actually gives you intuition that these two words are actually related right same for system and machine system and machine both would appear in the context of words like interface install run and so on so you know they are similar it just happens that these two words never appeared together so this similarity between them was latent or hidden in the original cooccurrence matrix now once i have done the svd what has happened because i have forced it to compress the data it has retained the most important in information and under that information these two words have actually come closer to each other right so you see that now you have a nonzero entry for the similarity between those two word pairs do you get the intuition and can you imagine that this would happen with svd and what is wrong in imagining you can but i guess right that is what is happening with this so you think about pca you think about svd you think about auto encoders all the intuitions that we had build there the same is being applied here right all if you get this ok fine yeah after svd you could have right that is not necessary that it should be positive in the original matrix you do not have negative entries"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/76_7.wav", "duration": 80.0, "text": "now here is a question right recall that earlier each row of the original matrix x served as the representation of a word ok this was my original x ppmi not the rank approximation now in that case what would x x transpose give me what would the ij th entry of x x transpose be so let us look at this toy example you have this x matrix you have xi and xj now i take x transpose ok now this is xi this is xj just standing now what would be the ij th entry of x x transpose it will just be the dot product between these two right is that fine so this is just the dot product between them and we know that dot product is more or less the same as cosine similarity module over the normalization right you just need to normalize it by the norms of x and xi and xj in this case right so i will just assume that this is a substitute for the cosine similarity ok so every entry at every ij\u2019th cell in x x transpose is the cosine similarity between the representations of the i\u2019th word and the g\u2019th word is that clear to everyone ok fine and in the original case which was the xppmi the cosine similarity between human and user was twenty-one"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/76_8.wav", "duration": 130.0, "text": "now once we do in svd what is a good choice for the representation of the word i after svd what is the dimension of x hat it is again n cross m because it is a sum of m cross n matrix so that the dimension of x hat is m cross n although it has been constructed using fewer information but the dimension is m cross n right that means what is the size of the representation of every word still high dimensional still the same n or v whatever everyone gets that is there any confusion with that ok now you could say that ok i will just take the i\u2019th row of the reconstructed matrix and use that as the representation because i know that now this representation is better some of those zero entries have changed they have captured the latent semantics between the words so this is definitely better none is denying that that this compression has given us better representation because we are only keeping the most important information now if i do x hat x hat transpose remember x hat is the reconstructed matrix then again by the same argument the ij\u2019th cell actually gives me the cosine similarity between the i th word and the j th word and you can see that now the cosine similarity between human and user has actually increased so this is just for me to convince you that we have learned more meaningful representations so now what do we choose as the representation i have still while computing this cosine similarity i have still used xi which is high dimensional which has the entire vocabulary as the number of columns as a representation right so there are two things coming out of here one is i really like this cosine similarity i see that it has improved that means the representations were computing something meaningful but on the flip side i am still not happy because the representations are still high dimensional so can you construct a wish list for me based on this i would want the same cosine similarity to be present as given by x hat x hat transpose right but i would like to represent it by fewer dimensions that is exactly what my wish list is ok"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/76_9.wav", "duration": 31.0, "text": "so let us see how do we do that now for no reason i am going to construct a matrix w word equal to u sigma what is u sigma it is the part of the svd right the svd told us it was u sigma v transpose so i am just considering this matrix i am going to call it w for no particular reason ok now let me take x hat x hat transpose i can write it as this is that fine now what is the next step"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/76_10.wav", "duration": 77.0, "text": "what does this mean i want an answer right this is that aha moment should be there or otherwise there is no point what is how many rows are there in w the same as the number of words in our vocabulary what is the dimension of each row k so now w word has low dimensional representations for the words in the vocabulary but while doing this what have we not sacrificed the cosine similarity the cosine similarity obtained by this is actually the same as this do you get that how many if you see this is very very important that if you have not understood this everything is meaningless so you see how from svd we got a low rank or a low dimensional representation for the words right w word is just to be clear k and k is very very less than v right so now we have representations for words which are much smaller they are no longer v dimensional remember in practice this k would be of the order one hundred two hundred three hundred and remember your vocabulary was of the order fifty k one thousand k and so on right so the huge reduction that you have got and you have still been able to learn meaningful representations which give you better similarity between related words right"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/76_11.wav", "duration": 81.349, "text": "so conventionally w word which is u sigma and belongs to m cross k so i am sorry for messing this up but i have used m n and v are interchangeably so you would understand it from context that m is v and the other matrix which is v is known as the w context matrix right what is the size of w context n cross k or k cross n right that means it has the representations for all the context words and w word has a representation for all the target words right so we had these words on the rows and the context words on the column so w word has the representations for the rows and w context has the representation for the corpus ok so this what we have seen so far and this is where we learn today is what a nlp was six years back right before the advent of deep learning if you wanted to use word representations this is what you would do you would do con construct a cooccurrence matrix try these tricks of pmi ppmi positive negative zero and all those things those heuristics then do a simple svd retain the most important one hundred two hundred dimensions and treat that as word representations and use it for whatever you want to do now what needs to be seen is what happened with deep learning and how have this way of computing word representations changed over the past few years right so that is what we are going to see in the next lecture right"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/77_1.wav", "duration": 58.368, "text": "so we will start from where we left yesterday ah so we did this whole story on starting from co occurrence matrices we learnt how to get better word representations and the key thing there was we used svd as a dimensionality comp reduction tool and we came up with this neat result that you could use w word as the representation of the mate of the words it has m rows and k columns where k is very less than the size of the vocabulary so you have achieved lot of compression and you are still able to learn very meaningful representations which you could use for several downstream tasks what to use these for and how to use these for you will see that later maybe four lectures from now i mean i say four lectures i mean four two hour lectures right so it might be more in terms of actual lectures so we will get to that but for now we have a way of learning representations for words"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/78_0.wav", "duration": 27.0, "text": "so from here on so none of this that we covered had anything to do with neural networks say but it was important to understand the context and i will tell you why it was important to go over the traditional way of learning word representations and then we will see how it ties to the modern way or the neural network way of learning representations so we will start with the first neural network based model for learning word representation which is known as the continuous bag of words model"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/78_1.wav", "duration": 47.0, "text": "so just to set the context the methods that we have seen so far are known as count based models because they rely on these co occurrence counts for learning representations of words and the methods that we are going to see now are called prediction based models and it will become clear shortly why the term prediction and how they learn the word representations so in a way in the original thing there was no learning involved of course you can say that you were trying to learn these eigenvectors and eigenvalues and so on but it was not in the same way as it be as we have been learning parameters of a neural network and so on right it was not in the same spirit but now once i do these second type of models this distinction would become very clear one why is there a learning involved and why they are prediction based models"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/78_2.wav", "duration": 294.0, "text": "so the story is we are going to look at continuous bag of words model then something known as skip gram so this is the famous word2vec model which you guys have already started looking at then we look at glove word embeddings which is some kind of a hybrid between the count based models and the prediction based models and then we see how to evaluate word embeddings and then end with this depressing note that good old svd is just fine right so all the progress that has happened in the past fifty-six years you could just use svd and still go by but if you do that you will probably not get a job right you have to learn these things"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/78_3.wav", "duration": 179.0, "text": "and we will see how to model this using a neural network so these are the two questions which i need to tell you how to model this task and what is the connection between this task and our original task of learning word representations these are the two things that i am going to answer"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/78_4.wav", "duration": 121.0, "text": "how many if you get this and what are the parameters w context and w word ok and we are going to focus on these parameters and understand what they actually mean"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/78_5.wav", "duration": 183.0, "text": "now how do you obtain p on given sat no no so for a given training instance so when you so you could so i will so for a given training instance you said that your corpus has been divided into those training windows right so it is possible that engineer sometimes the word does not and is not the next word but for this training instance what is it so that is what you have to predict right is that fine"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/78_6.wav", "duration": 224.0, "text": "so now i can say that p on given sat is actually proportional to the dot product between the j\u2019th column of w context and i\u2019th column of w word why am i saying that so remember that this was the i\u2019th word in your vocabulary and on was the j\u2019th word in your vocabulary so can you explain the meaning of this sentence to me first let us look at the first part what is h it is a j\u2019th column of w context oh sorry this should be i this should be j so this you already saw that h is the jet column of w context because i am multiplying a one hot vector with the matrix is that fine and what is the i\u2019th column of w word so why what is this product actually equal to if i say w word into h w word into h that is a vector and then i am taking the i\u2019th entry of that so i am saying that is the same as taking the i\u2019th column of w word and multiplying it by h how many if you get this is basically in your algebra right now these four different ways of multiplying matrices i am just using one of those right so if i multiply a matrix with a vector and then take the i\u2019th entry of that that is the same as multiplying the i\u2019th column of the matrix with the vector ok just go back and verify this just take my word for it for now so now what is happening is that it is proportional to the product between the j\u2019th column of w context and the i\u2019th column of w word is that clear now everyone gets this"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/78_7.wav", "duration": 87.0, "text": "so for some i will do some more stuff on this because there is some in interesting interpretations of the gradient descent update rule here so i will refer to the word sat by the index c and the word on by the index w ok and you already saw that the appropriate loss output function is softmax the appropriate loss function is cross entropy so let me just look at this right so w was the index of the output word so my cross entropy formula would just boil down to this everyone is fine with this ok i will just try to maximize the w th entry in my y hat how many of you are fine with this okay and that is nothing but the probability of the word given the context now remember that h is equal to w context into x c i am going to call that as u c so u c is the dash of the word sat title of the lecture it is a vectorial representation of the word sat everyone is fine with that because that is exactly what this product is going to do and now my y hat w is equal to this because i already said it is the product of the c\u2019th column of w context and the w\u2019th column of w word"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/78_8.wav", "duration": 70.0, "text": "so now i have a formula for y hat w what is the training algorithm that you will use gradient descent with back propagation now let us consider one such input output pair and see the update rule for v w"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/78_9.wav", "duration": 15.0, "text": "so now my gradient update rule is going to look like everyone is fine with this i have derived this formula and i have just substituted that here and this negative and this negative ok so now let us look at this update rule"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/78_10.wav", "duration": 93.0, "text": "so this update rule has a very nice interpretation which allows us to understand what does the continuous bag of words model actually learn now suppose y hat w tends to one what would that mean your prediction is very correct right you are almost predicting it has probability as 1ok what would happen to the update in that case there will be no updated if it is one there will be no update if it is close to one there is going to be very minimalistic update that means you have already learned the v w well enough ok on the other hand if i am very bad if y hat w is close to zero what would happen just tell me the case when y hat w is actually zero what is the update rule have you seen something similar ever before have you seen something similar before where did you see this update rule perceptron what happened when you did this w and x came closer to each other the angle between them actually decreased so the same thing is happening here so what you are trying to do is you are trying to make your word representation closer to the context representation is that clear how many if you get this it straight away follows from the update rule right because you are adding a fraction of your context vector to your word vector and we know that when we add two vectors they come close to each other the cosine between them decreases that is what we proved in the word to it lecture in the perceptron lecture right"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/78_11.wav", "duration": 545.0, "text": "so you can go back and refer to this slide on lecture two now so the training objective is essentially ensuring that the cosine similarity between v w and context word is maximized between the word and the context word is maximized"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/78_12.wav", "duration": 26.0, "text": "now in practice of course this is a very mate expensive matrix multiplication it is stupid to do it that way what you will do is you will just slice of those columns from w context right and then just add them up so you do not really need to do that stupid mate matrix multiplication because you know that the matrix multiplication is essentially just selecting these columns and adding them so just select those columns and add them up so you do not do that bad matrix multiplication operation is that fine"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/78_13.wav", "duration": 235.0, "text": "now what happens during back propagation in this case in the generic case the ordering does not matter is what you have seen yes it does not matter yeah there is some assumption of the model so it is that is why the name of bag of words you are not relying on the sequence so this comes from nlp that if you rely the sequence you call it sequence if you just going to take the words in the sequence you just call it a bag of words because once you put them in a bag there is no ordering there right that is why the word name bag of words so and again p on given sat is given by this softmax formula ok now tell me during back propagation and if you give me a right answer to this i really feel happy that you have understood everything right from the beginning of the course so no pressure so which are the parameters which are going to get updated during back propagation which are the two large matrices w word and w context so obviously the answer is not w word and w context otherwise i would not have asked you the answer is some dash of these two some subset of these two which subset let us start with w context which is the input do we are we going to update the entire w context did it participate the entire w context participate in the computation only those columns corresponding to the words so only those parameters will get updated so how many columns will get updated d columns right w word till all the columns of w word participate in the computation how many of you say yes how many if you say no the others do not care can you just focus on this circle did all the columns of w word participate in the computation you see the summation at the bottom it is over all the columns of w word all of them participated so the parameters which will get updated are w word and all the columns of the input words and same back propagation will work again is that fine so remember that and this is i cannot emphasize it enough whatever i have explained is only for an intuitive explanation you will never ever do this matrix multiplication right and that is why what you are going to do is you are just going to select those columns add them up and feed them and the network will take care or rather you will take care that you update those parameters only and you do not update the entire w context matrix because anyways there is no gradients flowing to the other components so remember that in the practical implementation of w of word two vec do not search for this matrix multiplication at the input or if you are writing the code on your own which is highly unlikely do not do it that way so if you whatever code that you look at did not have this complex matrix multiplication typically they will just pick up the columns and add them and feed them right and i think the tensor flow way of doing is you have this word embeddings matrix and you can slice columns from there and so so everyone understands this so far now what are these problems with this why is this not as simple in some sense as the mnist data set again focus on the circle this softmax computation is a very expensive operation right you have a v cross k sized matrix somewhere there and unlike at the input here you will have to do this matrix multiplication right so we have a v cross k matrix multiplied by a k cross one vector and there is no simplification of this you have to do this multiplication what are the sizes of v that we saw in practice fifty k one hundred k and if you had googled thirteen million or something right so this is not feasible we cannot do this expensive matrix multiplication"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/78_14.wav", "duration": 8.506, "text": "so although all of this works very fine we need to think of ways to simplify this softmax computation where the denominator requires the summation over all the words in the vocabulary so you have to do that many matrix multiplications"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/79_0.wav", "duration": 5.0, "text": "so with that we will move on to the next model i am still not telling you how to solve this problem we will come to that later"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/79_1.wav", "duration": 8.0, "text": "i am just going to the next model which is the skip gram model ok and this is the famous word2vec which you are trying to implement"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/79_2.wav", "duration": 11.0, "text": "the model that we just saw was known as a continuous bag of words it predicts the output given the context skip gram model does the reverse of that"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/79_3.wav", "duration": 72.0, "text": "you are given a word you want to predict all the context words so now i am given the word on i am trying to predict the words which appear on the left and right side of it is that fine so how many prediction problems am i solving how many predictions am i giving you four in this case right so you see that this is a case where your y actually belongs to r four right of course it is not r four it is four into v and because you are predicting the entire distribution but what i meant is that you want these four different outputs you just do not want one single output apart from that does everything else remain same you have an input word you compute a hidden representation from that hidden representation you try to predict the outputs you get a probability distribution what is your loss function it is a dash of cross entropies sum of cross entropies how many cross entropies do you have four in this case and also notice that i have i hope i have yeah i have changed w word and w context they are flipped now is that fine the role of context and the word has changed"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/79_4.wav", "duration": 54.0, "text": "in the simple case when you are trying to take one word as the input and only predict one word around it it just becomes the same as the first case that we saw in the continuous bag of words there is no difference there because there also you take one word and predicts the other word so the entire math\u2019s remains the same how many of you get that and even when we have multiple context words our loss function is just going to be the sum of the cross entropies for all those d predictions that i need to make or d minus one predictions that i need to make and then once i see a loss function which is a sum of some things i am not worried because i know how to deal with each of these components and gradients are additive so if you have the gradient of some it is just the sum of the gradients so as i long as i know how to deal with one of these i can deal with the sum so that is why i do not really worry all of you are at that level"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/79_5.wav", "duration": 33.0, "text": "where you do not worry with the sum as a loss function what are the problems with this already written there same as the bag of words right now we are doing these four expensive computations at the end so the softmax computation is expensive there are three different solutions and there are three different ways that we can deal with it one is something known as use negative sampling the other is to use contrast of estimation and the third is to use a hierarchical softmax so we are going to see all of these and i will shamelessly continue for a few more minutes so first we will see use negative sampling because that is very easy"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/79_6.wav", "duration": 78.0, "text": "so let d be the sat set of all correct w comma c pairs in the corpus what do we mean by that all words which actually appeared in the word comma context pair so you can look at the vector which i have constructed so sat on sat or sat chair you can imagine that all of these appeared in the context of each other so this is my correct corpus as from what i got from my data now let d prime with a the set of all incorrect w comma r pairs in the corpus and r here stands for random some how am i going to construct this corpus so i take a word i know all the words which appeared with it and i know all these other words which have not appeared with it so i will randomly sample a word from there and put it as r is that fine so i can compute d prime again d prime comes for free d was always for free now d prime is also obviously for free so i have w comma c and w comma r and i have these corpora d and d prime and as before let v w be the representation of the word and u c be the representation of the context word ok so v w will try to these two and you see will try to this and u r something else that we will use for this hopefully is that fine okay"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/79_7.wav", "duration": 45.0, "text": "now for a given w comma c which belongs to d which is the true corpus what are we interested in maximizing so let us think of z is a random variable weather which tells us whether this is a true pair or not so given w comma c i want to maximize that p of z is equal to one ok now this is what i want to maximize now it depends on me how do i model this probability so can you guess how am i going to model this the answer is there in the figure can you tell me what is the model that i have chosen can you tell me what is the formula for z equal to one given w comma c that i have chosen this stands for dot product this stands for the sigmoid function"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/79_8.wav", "duration": 69.0, "text": "i know this is some uc representation this is some vw representation note that these representations are not learned yet i need to learn them using the training objective that i set but at the beginning they are initialized to some random values and the way i am going to model probability of z equal to one given wc is that i am going to say that it is just the sigmoid function of the dot product between them how many of you get this are you comfortable with this this is the modeling choice which i have made or rather the authors of skip gram right now how am i going to now what do i want to do for all w comma c belonging to d i want to maximize this probability is that fine for all the w comma c pairs which belong to my true corpus which is the d corpus i want this probability to be high how many such pairs do i have many many right so let us call them as i have n such w comma c pairs so can you tell me what my loss function is going to look like maximize this for the first pair and for the second pair and for the third pair all the way up to the end pairs"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/79_9.wav", "duration": 37.0, "text": "so what is it going to look like for every w comma c which belongs to my correct corpus i want to maximize that probability of z equal to one given that w comma c pair right and since it is an and i will have this product how many of you are comfortable with this so this as such and this is something that you do regularly you should have done this in machine learning or pattern recognition or somewhere right that you want to basically maximize the log likelihood of the data which is saying that you want to maximize the probability of every training instance which is saying that you want to maximize the and of all these probabilities right be you take the and of all of them is that fine"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/79_10.wav", "duration": 59.0, "text": "now for the other case wr belonging to d prime what is it that i want to maximize this probability right because i know this is an incorrect pair so i want my random variable to output zero ok now what is this going to be the probability one minus the probability that it was correct and that actually if you just simplify a bit it turns out to be this now for all the elements which belong to d prime what is the objective function that i have i want to maximize this for the first w comma r random pair for the second w comma are random pair and so on for all the random pairs in my corpus so it is just going to be a product of all these probabilities is that fine so now what is my total objective function for every pair in d maximize that for every pair in d and for every pair in d prime maximize the zero probability so what is the total going to be is this fine"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/79_11.wav", "duration": 86.0, "text": "how many of you agree with this so for everything belonging to d i had this and rule for everything belonging d prime i had another and rule and i am interested in both the acts right maximize for d and maximize for d prime of course different quantities for d and d prime ok fine so you get this once you basically take the log and so on so this is a simple set of math operations that i do you will end up with this neat formula ok that for all the w comma c pairs belonging to d you want to maximize this quantity which means you want to maximize what you want to maximize the when will this quantity be maximized when the dot product between the two is high that means again what are you doing we are trying to bring the context vectors close to the word vectors again transitively what will happen the words which appear in the same context will go close to each other what is the additional thing that you are ensuring here the words which do not appear in the same context you are trying to push them apart why because of second loss function you see the difference between the two now in the first case you are only opt i mean you are obsessed with bringing things close together here you are also focusing on the case that where you do not want certain things to be close together because they never appear in the same context is that fine so you see that this is a more powerful loss function in the earlier one so that is what the skip gram model does"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/79_12.wav", "duration": 61.389, "text": "and in the original paper mikolov et al sample k random pairs for every positive pair right so that means if your size of d was n what was the size of d prime b k into n so that they had that many positive examples and k times that the number of negative examples and this was a hyper parameter which was tuned and they used a value of k such that it gave them the best results also remember that we have this problem of constructing w comma r now i said that consider all the words which do not appear with your word and sample from there and put something there so they used a slightly that means how do i sample that one is i assign all the words a uniform distribution that every word is equally likely what is a better way of doing that okay i think i just finished this next time"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/8_0.wav", "duration": 18.0, "text": "so this was all happening where deep learning now started showing a lot of promise in a lot of fields nlp vision speech and again this deep reinforcement learning and so on which led to this complete madness starting from two thousand and thirteen"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/8_1.wav", "duration": 22.0, "text": "well almost for every application the traditional methods were then overwritten or kind of beaten by deep neural network based system so something like language modelling which has been around since probably 1950s or so now the reining algorithm or the better algorithm for language modelling is now something which is based on deep neural networks"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/8_2.wav", "duration": 18.0, "text": "then similarly for speech recognition lot of work a lot of probabilistic lot of work based on probabilistic models was done in this or in the speech area or the speech literature for the past thirty forty years and now all of that has been overcome by deep neural network based solutions"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/8_3.wav", "duration": 15.0, "text": "same for machine translation a lot of interest in this field a lot of companies now have their machine translation systems based on deep neural networks as opposed to the earlier phrase based statistical machine translations or the probabilistic models which were used earlier"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/8_4.wav", "duration": 27.0, "text": "similarly for conversation modelling dialogue a lot of new work started in dialogue post a deep learning era where people now realize that if you have a lot of sequences of conversations you could actually try to train a deep neural network to learn from this sequence and have conversations with humans of course you are nowhere close to human level conversations we are very very far off from them but in limited domains these bots are showing some success now"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/8_5.wav", "duration": 7.0, "text": "same for question answering where you are given a question and you want to answer it either from a knowledge graph or from a document or from a image and so on"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/8_6.wav", "duration": 20.0, "text": "and in the field of computer vision things like object detection most of the reigning systems or the best performing systems nowadays are deep neural network based systems a lot of advances are being made on these systems over in the last few years"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/8_7.wav", "duration": 4.0, "text": "same for visual tracking where you want to track the same person in a video or image captioning where you want to generate captions for images for example people upload a lot of images on facebook"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/8_8.wav", "duration": 24.0, "text": "and if you want to automatically caption them or imagine you are on a reselling site right something like olx where you upload your furniture and you do not provide a description from that but can the machine already automatically generate a description for it so it is easier for the human to read what that product is and so on"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/8_9.wav", "duration": 18.0, "text": "so similarly video captioning i given a video anyone to caption the main activity which is happening in that video all of these problems are being solved using deep learning based solutions using a combination of something known as feed forward neural networks or convolutional neural networks or recurrent neural networks and so on"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/8_10.wav", "duration": 5.0, "text": "visual question answering you are given an image and a question and you want to answer that question"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/8_11.wav", "duration": 3.0, "text": "video question answering answering questions from videos"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/8_12.wav", "duration": 11.0, "text": "video summarizations if you are given a large video and you want to generate a trailer a sort of a trailer for that video contains which kind is the most important frame for that video even these systems are based on deep learning"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/8_13.wav", "duration": 53.0, "text": "then this was all about classification recognition and so on but now people started getting more ambitious that can we humans are very good at creativity so can we use machines to be creative right to generate images so now if i have seen a lot of celebrity faces can i generate new celebrity faces or if i have seen a lot of bedroom images and i am if a fireman architect now can i generate new bedroom images can i can we train a machine to generate new bed bedroom images so a lot of phenomenal progress or work has happened in this field in the last four five years starting with things like generative adversarial networks variational autoencoders and so on and people are now starting to seriously invest into creativity that how to make machines creative again we are far off from where the desired output but there is still significant progress happening in this field generating audio"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/8_14.wav", "duration": 6.0, "text": "so that was about generating images you can generate music also"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/8_15.wav", "duration": 2.962, "text": "and this is again about generating images and so on"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/80_1.wav", "duration": 36.0, "text": "so what i will do is i will quickly go over what we were doing yesterday and then by the time people come in we can start with the new stuff right so we were looking at so that is so this needs to be corrected someone who pointed out yesterday same as bag of words it should be same problems as the bag of words model so we are trying to fix this problem where we have this large softmax computation which is very inefficient and you wanted ways of getting rid of that so the first thing that we were looking at is using negative sampling"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/80_2.wav", "duration": 18.0, "text": "and here the key idea was to con construct this d and d prime where d prime was the random corpus and d was a true corpus and how do you create this random corpus is something that was left at the end and which i need to go over today"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/80_3.wav", "duration": 18.0, "text": "so i will go over that and then we realize that this actually could be modeled using such a network where you take the dot product between the word representations"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/80_4.wav", "duration": 3.0, "text": "and try to maximize this to dot product for all the correct pairs by setting up your loss function accordingly"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/80_5.wav", "duration": 35.0, "text": "and try to maximize or rather minimize this dot product minimize this dot product for all the incorrect pairs by again setting the objective function appropriately so we had this objective function where we want to maximize the probability that the pair is correct for the correct pairs and maximize the probability that the pair is incorrect for the incorrect pairs and both these probabilities we had modeled using a sigmoid function and inside the sigmoid function we had the dot product between the corresponding representations so the net effect is you either maximize the dot product of the correct pairs or minimize the dot product of the or rather and in minimize the dot product of the incorrect pairs fine"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/80_6.wav", "duration": 194.0, "text": "and then so now today the part which was remaining about the comparison between d and d prime so what i was saying last time is that d prime is actually k times d that means in sample more negative examples than positive examples so if you think about it actually the number of negative examples in the language is much much more than a number of positive examples let us say if you have fifty k words in your vocabulary most of them do not appear together right so that number is actually very very large as compared to the number of words which can occur together so how do you account for this natural imbalance so they said that if you keep it same then we are saying that the size of d prime and d is going to be same that means the words which appear together and not to appear together we are keeping those two corpora as the same so that does not sound reasonable so they decided that we will keep it k times ok now this k was a hyper parameter which was tuned based on the data that they had and can you guess how they would have tuned it no what do you tune your parameters on what did how did you tune your parameters for the back propagation of the word no using what student validation set a validation set is it too early in the morning it fine validation set so they might have had some validation set and if you look at the original word to word code which someone had posted yesterday which allows you to compute the distance matrix right so you could what you could do is you could learn these representations take a few pairs of words and take a few pairs of good words right say cat and dog or cat and feline and so on and also bad words like cat and truck bad combinations rather and see if the distance between cat and truck is much higher than the distance between cat and feline or cat and dog so you select that k which gives you the best performance on your validation set and the validation set here would essentially be to find if you get good representations for word pairs that you care about and for word pairs that you do not care about ok now the other thing was how do you create this r so you have v words in the vocabulary you are looking at one of those w you know that some of those have appeared with w in some context but there is this large set which has not appeared with w in any context right so you are going to draw r from this set and the simplest thing to do would be to just draw the uniform distribution that means all words and let us call this suppose there are capital r words here all of these words could be drawn from using the probability one by r where r is less than v is that fine that is one way of doing it just randomly pick any word from the remaining words and put it a pair it with w but you would also want to account for the individual frequencies of those words right if the word is actually very frequent pair it up more with w if it is not frequent do not pair it up enough does that make sense so i could actually use the frequencies of each of these words and sample according to that frequency right instead of using a unigram distribution"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/80_7.wav", "duration": 168.903, "text": "so they did something similar but they had this hyper parameter again so basically i was sampling using the probability of r which is equal to count of r divided by the number of times number of all the words in the corpus that is actually the frequency of r divided by the total number of words in the corpus so instead of just taking that they had this wearied factor of three by four do you we realize that if you take this three by four you get the best performance so let me just make a few comments on that so the original code of or rather the original skip gram or the bag of words model actually worked very well and it kind of hard a lot of seminal effect or a lot of revolutionary effect on the field of nlp right so now everyone started talking about word vectors and how you can use this meaningful representations of words as features for various down steep nlp thus right so at the end in nlp what you are doing is you are collecting of a bunch of words a document or a sentence or something and trying to do some processing on that now earlier used to construct features out of these sentences using some handcrafted features but now someone said that there is this automatic way of constructing word features right which is using this method so people really bought onto that idea and a lot of work started happening and then later on at the end of the course we will see something that what it eventually led to but later on when people started analyzing this more carefully right they realized that the original word2vec implementation had a lot of these heuristics or lot of these parameters which need to be really tuned to the core for it to be able to compete with svd right so that is what we look at the end so svd was already one way of computing word representations ah which while popular was not so popular it was used for various reasons but it was not like every npl application is using svd representations right but now it is almost like every npl application is using word representations so later on we will see that some of these things like three by four or k the value of k the value of learning rate and some other hyper parameters if you really tuned them very very well it is only then that as this word2vec algorithm can beat the world representations learned by svd or rather the other thing that if you introduce some parameters in svd and tune them because remember for svd there was no tuning right we just got a solution we just had the closed form solution which is the eigen vectors but you could do some things for creating the cooccurrence matrix if you introduce some factor there which is also looks like this three by four or something like that or if you also introduced something which looks like a k then you will be able to get the same kind of representations or equally powerful representations from svd as what you get from word2vec so that is why i am stressing on these hyper parameters there is some significance of those"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/81_0.wav", "duration": 14.0, "text": "so we will move on to the next way of dealing with the expensive softmax so remember that so this is known as contrastive estimation"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/81_1.wav", "duration": 350.0, "text": "so remember that this is where we are in the story that we saw the bag of words model we saw the skip gram model and we saw that both of them have this expensive softmax computation at the end and that is the problem we are trying to deal with so we saw one way of dealing with which was negative sampling so you i hope you saw that there was no expensive computation there the only computation there was the dot product between the two words which appear together or which do not appear together now let us see what happens in contrastive estimation"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/81_2.wav", "duration": 19.845, "text": "so then can you give me the full objective function maximize this but at this condition already holds then do not do anything is that fine so that is about this so and again observe that we have gotten rid of the expensive softmax computation"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/82_1.wav", "duration": 19.0, "text": "the next one is a bit tricky so the third solution is to use something known as hierarchical softmax this is a bit counterintuitive in the sense it is a very smart trick but it is not something which is very obvious so just pay a bit attention on this it is a neat way of handling this large vocabulary thing and this i think used in various nlp applications where speed is important not often but wherever speed is important"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/82_2.wav", "duration": 29.0, "text": "so this is what our original network was this was the either you take it as a skip gram model or you take it as a continuous bag of words model right let us take it as a continuous bag of words model you had a word as the input and then you had this large prediction and you had this softmax computation which gives you the probability and you are trying to maximize this probability for the correct word right where v w is the correct word"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/82_3.wav", "duration": 141.0, "text": "now instead of this the hierarchical softmax says that you construct a binary tree such that your tree has how many nodes v nodes it has one node corresponding to every word ok and there exist a unique path from the root node to every leaf node every leaf node corresponds to a word and there is a unique path from the root node to leaf node of course there will be overlapping things for example for this word the path is these nodes and for this word also the path is like there is some overlap in the path but for every word there is a unique path how many if you get that setup now let lw one lw two up to lw p be the nodes on this path so i am calling this as lw1 lw2 lw3 sorry sorry sorry sorry yeah actually it is so actually this is l on one l on two l on three that means the third node on the path of on the second node on the path of on and so on right that is how it is going to be and let pi w be a binary vector"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/82_4.wav", "duration": 92.0, "text": "finally each of these internal nodes is associated with a vector ok so i have u one u two u three so how many of these would i have if there are v nodes at the leaf how many nonleaf nodes do you have in the binary tree v you all know this right so if you have v nodes at the leaf then you will have v nodes internally so for each internal node i have a vector associated with it so how many vectors do i have in all u v and my input side is still the same right i have this w word or w context depending on whether it is a skip gram or by or continuous bag of words model so how many parameters does this model have is it same as the bag of words model or less than the bag of words model or more than the bag of words model this is how you will think you will see how many input parameters do the pool two models have how many output parameters to the two models are input parameters same output parameters how many vectors do you have u one to uv each of size k same as the original model right it is just as an original model i had put everything inside as w context which was k cross v right so it is the same number of parameters"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/82_5.wav", "duration": 171.0, "text": "so the total number of parameters in the network is the same"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/82_6.wav", "duration": 311.366, "text": "so this is what i will do so as i said for the on example this is what you want this is the path that you want to be executed"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/83_0.wav", "duration": 10.0, "text": "so now from here we will move on to yet another way of learning word representations which is known as the glove representations"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/83_1.wav", "duration": 312.0, "text": "so the count based methods rely on global co occurrence counts from the corpus for computing word representations that is what we saw in svd they look at these co occurrence counts and from there they build the word representations the predict based models set up a learning problem where you have this feed forward net network and it tries to predict certain things from the given words and then you learn the parameters of that network and you set up the task in such a way that the parameters actually correspond to word representations so this was the difference between count and predict based methods now what is the obvious next thing to do like hear the answer from a few of you but i want to hear it from everyone what is the obvious next thing to do you have count based methods you have predict based methods combine the two right so come up with some kind of a hybrid so that is exactly what glove does which is known as global vectors"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/83_2.wav", "duration": 115.715, "text": "i am saying that these parameters can also be learned so effectively using all these three i should be able to get this this is what i desire now set up the loss function using these two things come on that should not be so hard what is this this is what you are trying to predict what is this this is what you know is true because you have computed from the corpus now can you come say the loss function the difference between these two right so you could have this as the loss function this is the predicted value using models parameters this is the actual value computed from the corpus so think of this that you are trying to learn the parameters in such a way that you end up predicting this and if you predicted this you know you have done the right thing ok and this you know already because you have computed it from the corpus so this is the true value and this is the predicted value so as in any loss function predicted minus true the whole square does that make sense how many if you are fine with this"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/84_0.wav", "duration": 6.0, "text": "now we come to this important part about how do you evaluate word representations"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/84_1.wav", "duration": 111.0, "text": "so there are different tasks that are set up i hope some of you have read that paper and i can see that none of you have read that paper so semantic relatedness is one way of evaluating word representations"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/84_2.wav", "duration": 31.0, "text": "so that is one way of evaluating how good your word representations are right so as i was saying earlier how do you tune those parameters so you could have such a set once you have learned some word representations and you want to see whether parameter k one was better than sorry rather hyper parameter k one was better than hyper parameter k two you could just take those two word representations learned by these two different hyper parameter settings evaluate them on this corpus and whichever gives a higher correlation you can keep that hyper parameter how many of you get that"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/84_3.wav", "duration": 71.0, "text": "other task is synonym detection so from a resource known as word net or from other dictionaries you could get all the synonyms of a word so then people create a corpus where you give us in sin a word and give four candidates or some k candidates out of which one of these is the correct synonym the others are just distraction words right and distracting words now what would you expect your word representations to do you have word representations for all of these what would you want how would you pick up the synonym based on word representations students refer time three hundred and thirteen the one which has the highest cosine similarity so again you will compute the cosine similarity you will rank these and you will pick up the synonym right and now again i gave you one hundred such instances i gave you a word for candidates and i gave you one hundred such different word comma candidate pairs and you pick the synonym for everyone and see for sixty of them you got it right then your accuracy sixty percent so that tells you how good your word representations are again if you are given two different hyper parameter settings one gives you sixty percent accurate the other gives you seventy percent accurate you will probably go with the one which gives you seventy percent accurate they are find how you can use this"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/84_4.wav", "duration": 271.309, "text": "the third is analogy task"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/85_0.wav", "duration": 10.0, "text": "now and later on actually the same guys they also came up with this formal relation between svd and word2vec which is again under some assumptions"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/86_0.wav", "duration": 57.0, "text": "so why let us start so far in the course we have looked at feed forward neural networks we have seen how to train them and we have seen two special cases of feed forward neural networks one was the auto encoders for learning representations or learning latent representations of inputs and the other thing that we had seen was how to use a feed forward neural network to learn word representations where we saw this word to wake algorithm and it is different variants it was continuous bag of words skip gram model graph and so on so those are all since some since applications of the feed forward neural network and now we will move on from there though we will look at different type of neural network today which is convolutional neural networks and we look at some specific architectures which have become popular over the past few years ok"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/86_1.wav", "duration": 130.0, "text": "so with that i will start this lecture on convolutional neural networks so in the first module we will look at the convolution operation ok"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/86_2.wav", "duration": 20.0, "text": "so the measurement that you take a t one t two t three all the way up to t minus infinity and for each of them would have a weight associated with this so this operation right this thing you can write it as the following operation that you have a vector of measurements or an array of measurements which is x and you have an array of weights associated with these measurements the farther the measurement from the current time step hopefully smaller is the weight assigned to that and this operation is known as the convolution operation right"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/86_3.wav", "duration": 314.0, "text": "so you have x which is the input w is known as the filter and the operation that is defined as this equation is known as a convolution operation right"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/86_4.wav", "duration": 44.0, "text": "so there is no correct answer here different convolution operations i mean different packages use different convolution operations but the most standard one i believe is when you look at the next neighborhood right that means you at this pixel and you will look at this neighborhood the neighborhood after it right not the before it ok and in fact so this is the formula that i am going to look at plus j and plus p that means i am looking at pixels in the rows after this and in the columns after this pixel all of you get this instead of before now what is even more natural to do the names surrounding thing right so i will have this pixel and i will look at it is such a way that this pixel is the center of the neighborhood right so that is what i am going to go towards after a couple of slides and that is what i will use for all my convolution operations but in terms of textbook definitions these are the definitions that you will find in textbooks ok"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/86_5.wav", "duration": 44.0, "text": "so let us let us apply this to a toy example so i have this input which is two dimensional input i have a kernel which is a two two kernel so my m is equal to n is equal to two so i am going to place this kernel at this location ok and then what will i get as the output"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/86_6.wav", "duration": 16.0, "text": "so right now i just you to notice it is obvious nothing great about it but i will just get back to it more formally later on so for the rest of the discussion we will use the following formula for convolution which is the centered formula right so to that means i will be looking at a neighborhood which is centered on the pixel of interest that is why this to is that fine ok 2m2n2m2m"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/86_7.wav", "duration": 14.0, "text": "so this is how i am going to look at it so this is how i will place if this is the pixel of interest which i want to re estimate i will replace the kernel such that it this pixel lies at the center of the kernel ok"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/86_8.wav", "duration": 2.0, "text": "so we will be looking at both preceding and succeeding neighbors ok"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/86_9.wav", "duration": 140.0, "text": "so let us see some examples of 2d convolutions applied to images"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/86_10.wav", "duration": 8.0, "text": "so enough of examples so now we will see a working example of a 2d convolution so i just want to drill this idea of what happens when you do a 2d convolution"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/86_11.wav", "duration": 136.0, "text": "so what we are going to do is we have this three three kernel and assume that everything here is a pixel ok everything here is a pixel so i am going to slide this three cross three kernel across this filter now when i place the filter once on the image how many outputs do i get student one one output so if i keep sliding it across the image i will keep getting one one pixel in the output ok so what the resulting thing that i get is known as a feature map ok because it is the original input that we have taken for every pixel you have tried to approximate it or whatever filter weights you have applied and it necessarily does not mean that you are taking an average it could be some weird average of your neighborhood right so you have extracted some features from there so for example in the edge detector case you could think of it that you have extracted the feature that this pixel does not lie at a boundary right that is why you get the black pixel do you get that you see this way of interpreting a convolution operation that you are trying to extract some features from that neighborhood so in this earlier example whenever you got a black you are basically extracting the feature that this pixel does not lay at a boundary is that ok fine so now you could get one such feature map by using a single three cross three convolution operation ok if i use multiple such convolution operations what would happen i will get multiple feature maps ok so let us try to understand this what is the dimension of my original image m cross n into three why is it into three student rgb channels rgb channels ok rgb is what we will have right so we will have this three m n so we will return back to this idea and from now this one image by using a single kernel so this in fact in for this figure right i am assuming that the input is one cross m cross and i am not assuming there are three channels although it is a colored image but just bear with me so it is a one cross m cross an image and when i apply a filter i get a one feature map if i apply k such filters i will get k feature maps so one feature map could be for the blurring one one could be the sharpening one one could be the edge detector and so on right there are various such filters that you could apply"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/86_12.wav", "duration": 10.0, "text": "now in the 1d case we slide a one dimensional filter over a one dimensional input in the 2d case we slide a two dimensional filter on a two dimensional input what would happen in the 3d case"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/86_13.wav", "duration": 132.986, "text": "so now we are going to this rgb images right so we will have three cross m cross n as the input what would happen in the 3g 3d case not 3g"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/87_0.wav", "duration": 11.0, "text": "ok so now we will go to the next module where we will try to learn the relationship between the input size the output size and the filter size ok"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/87_1.wav", "duration": 138.0, "text": "so so far we have not said anything about the dimensions of the inputs i have just been very vague that its m n and also for the filter i have just said three three five five and so on and in fact i am not even told you what the dimensions of the outputs are except that i be got some intuition that it seems that the output dimension is smaller than the input dimension right so let us look at these in more detail and see what do these different outputs look like why do i care about these things what do the inputs and the output sizes look like because these are your matrices that you will be dealing with this tell you these tell you how many parameters you are going to have these tell you what is the size of the memory that you need to load this entire network into your memory and so on it so that is why this computation is very very important and i will have some more things to say about it towards the end of this lecture or some lecture ok"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/87_2.wav", "duration": 47.0, "text": "so let us compute this for one example so this is my original image so i am looking at a two dimensional input which i believe is seven seven and i am applying a three three filter to it so every time i slide the filter i will get one pixel in the output and i got the entire feature map now it is obvious that the size of the output is less than the size of the input why is it so because there are certain pixels at which i cannot place the filter why you will go out of the boundary right so i cannot if this is my pixel of interest i cannot place my filter there because then the filter will go outside the image and i do not know what the average to come to how to compute the average right those values are undefined do you get that ok"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/87_3.wav", "duration": 400.0, "text": "so in general for let me see for the three cross in fact this is true for all these pixels which have been shaded or any of these pixels i cannot place the filter because you will go outside the boundary so now for a three three filter what is the reduction in the size of the output compared to the input the width decreases by two and the height decreases by student two two right so can i be bold enough and say that the width and height decreases by not yet ok so let us see if we had a five five kernels ok then which are the places at which i will not be able to place the filter these two shaded boxes and both these boxes i cannot place the filter because the filter will go outside the image"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/87_4.wav", "duration": 32.0, "text": "finally coming to the depth of the output what would the depth of the output be so let me just see right now all our formulas were w2 h2 in the presence of filter padding and size a stride sorry but we never had a formula for d2 so that is what i am asking now what is the depth of the output same as the every filter is going to give you one two dimensional output if you have k filters student k you will get k two dimensional outputs that means the depth of your output is k right"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/87_5.wav", "duration": 77.662, "text": "so the depth is very simple it is just equal to k the number of filters that you have so i want you guys to note down these three formulas"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/88_0.wav", "duration": 7.0, "text": "ok so now we will go to the next module this is for the camera and this is on convolutional neural networks"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/88_1.wav", "duration": 32.0, "text": "so far we have done what we have just talked about a convolution operation you just taken some input boxes and converted them to output boxes what does this anything of this have to do with neural networks i keep saying that is a course on neural networks right so everything has to link to that so what is the connection so we will try to understand this by taking the example of image classification and i will use the same trick to get everyone\u2019s attention so the next few slides are going to tell you the difference between machine learning and deep learning ok so now everyone will pay attention"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/88_2.wav", "duration": 276.0, "text": "so this is the task you have give given an image and you want to classify it into one of k categories and i am considering four categories here car bus monument flower ok what is the simplest thing that you can do suppose this is a twenty cross twenty image you know the simplest thing student sir given on the slide you will just take this as a four hundred dimensional input feature vector right and you will treat it as a four class classification problem train some multiclass svm or anything on that right so you have a simple input so you are given some one million images all of these are four hundred dimensional and they come from one two three or four these are the four classes which is car bus monument and so on"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/88_3.wav", "duration": 30.0, "text": "so that is equivalent to learning only the soft max layer in case of a feed forward network that is the output layer right now instead of using these so this is the question instead of using these handcrafted kernels or features such as edge detectors or blur detectors or what not can we learn meaningful kernels in addition to learning the weights of the classifier do you get this question at least whether the answer or not but you get the question so what i am asking is that why should i hand code this edge detector ok"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/88_4.wav", "duration": 94.0, "text": "why not have after what is the edge detector it is like a three cross three matrix right and i have seen tons of such matrices in my feed forward neural networks i have dealt with very large matrices which were called parameters of the network so why not have a three cross three or a five cross five or whatever dimensional matrix and try to learn what should be the right values in this matrix instead of hand coding the edge detector matrix do you get the idea how to do that as still far but at least do you get the idea that is what i am we are trying to do ok so now instead of just learning the weights of the classifier we also want to learn the weights of the kernels that means instead of using handcrafted features i am now going to student refer time six hundred and thirty-seven learn the features so that is the difference between deep learning and machine learning so you had handcrafted features there and now you are going to learn the representations also by treating them as additional parameters in your networkhow you will do that we will see and it is very simple given that you understand how to train feed forward networks"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/88_5.wav", "duration": 46.0, "text": "in fact why not why just stop there what is the next thing that i am going to try to do multiple layers of features right so that means at the first layer i learned this representation now i could take this and try to learn an even more abstract representation and then keep doing this to make it deeper and deeper do you get this ok so at every stage now i have these parameters which are helping me learn the representation of the input i am learning multiple representations at every layer and then having multiple layers of these representations right and everything is learnable end to end ok so you get the difference between deep learning machine learning now there is no handcrafting of features you are learning the feature representation i know i understand there is some confusion about how you would do this"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/88_6.wav", "duration": 44.0, "text": "but we will get to that just trust me on that that you will be able to figure out how to do this ok and all of this we have some weight matrices here we have some weight matrices here these are the layer one weight matrices the other layer two weight matrices and these are the output layer matrices and you see this layer wise arrangement of these weight matrices and they are very comfortable with this because we have done feed forward neural networks where we had these multiple layers and we knew how to back propagate from the last layer to the first layer now what i am trying to say is that i would like to adjust these weights of filters in such a way that my classification loss is minimized and what is the loss function that i am going to use here student refer time eight hundred and fifty-one cross entropy because this is a multi class classification problem ok"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/88_7.wav", "duration": 10.0, "text": "so just hang on with this intuition and we will make it more clear fine so such a network which has these multiple convolution learned convolution operations at every layer and then multiple such layers is known as convolutional neural network"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/88_8.wav", "duration": 20.0, "text": "ok fine so get this idea that we need to learn kernel filters by just treating them as parameters of the classification model ok but how is this different from a regular feed forward neural network you could have taken a regular feed forward neural network and i will show it to you on the next slide and what is the difference between that and a convolution operation"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/88_9.wav", "duration": 254.0, "text": "so if you understand that then you would be done for this lecture yeah so we have an input so let us say now i will take back the eminist case where you are given an input as an image and these are digit inputs and you want to classify them into one of ten inputs and i am going to assume that my input is four cross four that means i have sixteen pixels ok so the simplest thing that i could have done or the feed forward neural network way of doing this is that i would just flatten out this image i will get sixteen inputs i need ten outputs at the output layer so i have an output layer which will have one of these ten classes and then i add as many layers that i want in between ok this is what a feed forward neural network would look like and if i consider any one neuron in the first layer it takes inputs from all the sixteen inputs right that is how a feed forward neural network is you have these extremely dense connections where every output depends on every input at every layer ok"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/88_11.wav", "duration": 90.0, "text": "another characteristic of cnns is something known as weight sharing so let us see what it is so remember i had considered this two cross two kernel and i was placing it at these four pixels which is pixels one two five and six and i was pacing another kernel at these four pixels which is pixels eleven twelve fifteen and sixteen right these four pixels and i have used different colors for them indicating that these filters are different so they are both two cross two filters but i am assuming at the values inside them are different does this have to be the case just think what a filter is trying to do student refer time one thousand, four hundred and twenty-seven it is striding across the entire image at every location i want to do the same operation remember when we are doing blurring or edge detection or sharpening i had the same filter which i was applying at every location so i want to see what is the effect of this filter throughout the image so i do not really want to change this filter that means these four weights would be the same as student pink weights the pink weights how many of you get this so this is a question do we want the kernel weights to be different for different portions of the image so imagine that we are trying to learn a kernel that detects edges so the same kernel configuration is required throughout the image because that is the kernel configuration which will detect an edge"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/88_12.wav", "duration": 60.0, "text": "so you want the same kernel to be there everywhere so we are going to share these weights they should not be these pink and orange weights we will just have the same weights everywhere ok so this is known as weight sharing so now this is something ridiculous if you think about it now how many weights do i have in layer one student refer time one thousand, five hundred and thirty-three four weights that is all that looks too less right it would lead to student refer time one thousand, five hundred and thirty-nine dash fitting student refer time one thousand, five hundred and forty-two under fitting because we have very few parameters so how do i deal with the situation student refer time one thousand, five hundred and forty-five you will have multiple kernels right so you will have another kernel which takes something else you will have one more kernel which takes something else and you can have as many such kernels right so the more the number of kernels will have you will have that many into four as the number of parameters and that many outputs at layer one how many if you get this ok good so these are the two important characteristics of convolutional neural networks one is sparse connections and the other is weight sharing ok"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/88_13.wav", "duration": 9.627, "text": "so so far we have focused only on the convolution operation now let us see what does a full convolutional neural network look like or maybe i will do this next time i think this is"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/89_2.wav", "duration": 26.0, "text": "so we will start from where we left yesterday so this is what we had seen yesterday we saw what\u2019s the difference between a convolutional neural network and a feed forward neural network and we focused on two main properties one is sparse connectivity and the other was weight sharing that is about it and then we saw that this representation of i mean we saw this diagram about how to you could have multiple kernels and each kernel would apply across the entire image and the weights would be shared for that kernel"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/89_3.wav", "duration": 156.0, "text": "so far we have only focused on the convolution operation and even when you have seen the neural network or the convolutional neural network we have only seen the convolution layers right so there is something more in a typical convolutional neural network and that is what i was about to start yesterday so we just continue from there"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/89_5.wav", "duration": 576.0, "text": "so now what we will do is now that we have some idea of what a full convolutional neural network looks like so it looks like alternating convolution and max pooling operations we know what a convolution operation looks like in particular we know that a 3d filter applied to a 3d input results in a 2d output because we are not applying the convolution along the depth we just applying the convolution along the width and the height right so that is what we know so far"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/89_6.wav", "duration": 137.144, "text": "so now how do we train a convolutional neural network what is the answer your nodding that means you do not know or you know it is too trivial to even ask this question how will you train it student refer time one thousand, five hundred but how do you back propagate through a convolution operation that is a very nasty looking operation"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/9_0.wav", "duration": 22.0, "text": "so lot of fields have adopted deep learning now and lot of state of the art ai systems are based on deep neural networks but now what is needed is after all thi s madness were deep learning has taken over a lot of research areas can we now bring in some sanity to the proceeding so this is really a need for sanity"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/9_1.wav", "duration": 203.0, "text": "and why i say that is that because there is this paradox of deep learning so there is this interesting question that why does deep learning works so well despite having a high capacity so the deep neural networks have a very high capacity which means that susceptible to over fitting so most of you would have done some course on machine learning so there you know that over fitting is bad because you are just memorizing the training data and then you might not be able to do so well and at tested and over fitting happens when your model has a high capacity so even though deep neural networks have high capacity why are they doing so well we will focus on this high capacity but when we talk about the universal approximation theorem and give some arguments for why deep neural networks have such a high capacity the other thing is they have this numerical instability right so we spoke about these vanishing and exploding gradients and again we will talk about this later on in the course so despite this training difficulties why is it that deep neural networks performs so well and of course they have this sharp minima which is again it could lead to over fitting so if you look at there is an optimization problem it is not a neat convex optimization problem so it is a non convex optimization problem so why does it still do so well so it is also not very robust so here is an example on the right hand side the figure that you show so the first figure is actually of a panda and the machine is able to detect this panda with some fifty-seven percent confidence right we have trained a machine for a lot of animal images we have shown it a lot of animal images at test time we show at this image the first image that you see on the right hand side and is able to classify this is a panda with fifty-seven percent confidence but now what i do is i add some very random noise so that second image that you see with some very random pixels if i add it to this image i will get a new image so every pixel in this image is added to this new noise image and i get the image which is see on the third the third image that you see right to you and me or to any average human this still looks like a panda there is hardly any difference between this image and the original image but now if you pass this to the machine all of a sudden instead of recognizing this is a panda it starts to recognize it as a gibbon and that too with ninety-nine percent confidence so why is it that they are not very robust and despite this not being very robust why are deep neural networks so successful so people are interested in these questions and people have started asking these questions there are no clear answers yet but slowly and steadily there is an increasing emphasis on explainability and theoretical justifications so it is not enough to say that your deep neural network works and gives you ninety-nine percent accuracy it is also good to have an explanation for why that happens is it that some components of the networks are really able to discriminate between certain patterns and so on so what is going on inside the network which is actually making it work so well right and hopefully this will bring in some sanity to the proceedings so instead of just saying that i apply deep learning to problem x and got ninety percent success we will also make some kind of more sane arguments just to why this works and what is the further promise of this and thinks like that so that is roughly a quick historical recap of where deep learning started and where it is today starting all the way back from advances in biology in one thousand, eight hundred and seventy-one to recent advances till two thousand and seventeen and so on deep learning right and here are few url"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/9_2.wav", "duration": 5.0, "text": "so you could take a look at this for a lot of interesting applications of recurrent neural networks"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/9_3.wav", "duration": 6.0, "text": "bunch of startups which have come up in this space is working on very varied and interesting problems and here are all the references that i have used for this particular presentation"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/9_4.wav", "duration": 8.651, "text": "so that is where we end lecture one and i will see you again soon for lecture two"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/90_0.wav", "duration": 13.0, "text": "so now we will go to the next module we will talk about some success stories on imagenet right so this is the challenge which actually made convolutional neural networks very famous back in two thousand and twelve"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/90_1.wav", "duration": 308.0, "text": "so they are going to look at some algorithms in fact two more hopefully today"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/90_2.wav", "duration": 11.0, "text": "so that is the number of parameters that they had in this layer ok eleven into eleven into three into ninety-six now what is the next layer going to be a max pooling layer"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/90_3.wav", "duration": 20.0, "text": "ok so they had a max pooling layer where they used a three cross three max pooling that means you are going to pick up max from a three cross three grid and the stride was two that means we are going to get half the output and now can you tell me what w2 h2 would be roughly half of fifty-five fifty-five right so twenty-seven twenty-seven"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/90_4.wav", "duration": 35.0, "text": "and what is the number of parameter is going to be don\u2019t be lazy everyone be say it student zero zero right so that is the max pooling layer now what is the size of your input volume at this point student twenty-seven twenty-seven cross twenty-seven cross student ninety-six ninety-six as opposed to the original input which was two hundred and twenty-seven cross two hundred and twenty-seven cross three so as you keep progressing your width and height is decreasing but your depth is increasing because you are using more and more filters to capture more and more patterns in the images"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/90_5.wav", "duration": 23.0, "text": "now so you have twenty-seven twenty-seven ninety-six then they decided to use two hundred and fifty-six filters each of size five five with a stride of one and padding of zero ok is it right so how many parameters do you have now student refer time six hundred and fifty-three two hundred and fifty-six into student five into five five into five into student ninety-six ninety-six"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/90_6.wav", "duration": 12.0, "text": "so thats the number of parameters that you will have and the size since would decrease only by one right because you have a stride of it will decrease by two because a filter size is five and you have a stride of five ok"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/90_7.wav", "duration": 8.0, "text": "so these are the number of parameters we had six million parameters in this layer what is the next layer going to be pooling"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/90_8.wav", "duration": 31.0, "text": "so you do a max pooling again you do a three three you do a stride of two so your width in height is going to decrease the depth does not change remember in max pooling the depth does not change because the max pooling operation is per feature map it is not across the depth fine then use a three three filter and three hundred and eighty-four of those"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/90_9.wav", "duration": 150.0, "text": "and then you have a convolution operation again which is a three hundred and eighty-four convolutions each of size three three and so many parameters followed by a convolution operation again followed by a max pooling operation then followed by a fully connected layer"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/90_10.wav", "duration": 29.0, "text": "then so the total number of parameters in this network is two thousand, seven hundred and fifty-five million parameters and ok at this point i will and obviously you notice that most of these parameters were there in the fully connected layer so you had four million here then sixteen million here and then again four million here right so roughly twenty-four million of the twenty-seven million parameters were there in the fully connected layer you see that skew in the number of parameters ok"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/90_11.wav", "duration": 253.0, "text": "and i will just look at the fully connected layer again so the last max pooling layer actually gave you a two hundred and fifty-six cross two cross two output you just flatten it to get a one thousand and twenty-four dimensional vector and then you connected fully to the four thousand and ninety-six vector right so that is what i mean by a fully connected layer why do you move max fully so the reason for that is basically to shrink the size of the image right because after that if if you keep working with this size right then the number of parameters is going to really blow up a by using a larger stripe yeah both of them are feasible right so now see from here remember that we had the original image sizes two hundred and twenty-seven cross two hundred and twenty-seven and by the end we were just left with two cross two and then adding a fully connected layer on that makes sense right if i had not done this shrinkage throughout either by increasing the stride of the convolution layer or by doing max pooling right then you would have left with something of the order of two hundred cross two hundred here and then you have to do a fully connected on top of that is just infeasible right it just throws away all the hard work that you have done by doing weight sharing and sparse connectivity right so that is not feasible there are also papers with say which i think it is titled fully convolutional neural network which does not have any max pooling layers and they show that that also works fine in fact when we see vgg net we will see that it has back to back convolution layers and very few max fully layer right so these are all things which people have trained not so many years two years the challenge came out in two thousand and ten and in two thousand and twelve this was used right so it is like not really a large gap right and if you read the original paper they had to do a lot of tricks to actually make this work it was not as simple as i am showing it of course now with all the stability which comes from these platforms tensor flow pytorch you can probably just go and implement this as it is and you should be able to reproduce the results but six years back that was not the case there was a lot of hard work involved in getting this too work and they this was also the paper which introduced the relu nonlinearity in the context of convolutional neural networks right so they had to change from sigmoid or tan edge to relu a lot of these small small things which they had done and at that time it is also not possible with the existing hardware to train this on the given gpus that you had at that time so they had to do some splitting across gpus and so on so it was not as simple as it is today with all the hardware as well as api developments or platform developments around this right so probably that is why it took two years to yeah sure so each of these things so after you do the convolution operation you pass it through the relu nonlinearity ok so what does that mean is that the convolution operation gave you a feature map every entry here was just a weighted average of the neighbors right you take this entry or rather you take this feature map and create a new feature map where every entry here is the sigmoid of every entry here do you get that or not sorry sigmoid some nonlinearity and they use the relu has the nonlinearity so you do get everyone gets this so all the convolution layers are followed by a relu nonlinearity layer so you get this volume pass it through the relu and get a new volume but i have just shown that as a single operation it is before pulling so this was the fully connected layer so now we look at the next architecture which is zfnet"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/90_12.wav", "duration": 17.0, "text": "then again they had the same max pooling operation this layer there was no difference between zfnet and alexnet and then after that you had again layer three which was exactly the same as alexnet"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/90_13.wav", "duration": 32.0, "text": "then layer four again the same as zfnet afterwards layer five instead of three hundred and eighty-four filters they decided to use five hundred and twelve filters the rest of the thing remains the same that means the size or the spatial extent of the filter remains the same that again results in some difference in the parameters so thats the number of parameters that got added in zfnet as opposed to alex net and of course the oh sorry sorry oh sorry the bottom one is a zfnet yeah that is correct sorry so in zfnet you had five hundred and twelve filters as opposed to three hundred and eighty-four filters in alex net ok is it fine"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/90_14.wav", "duration": 5.0, "text": "and then the next layer again instead of three hundred and eighty-four filters they had one thousand and twenty-four filters"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/90_15.wav", "duration": 5.0, "text": "then again instead of two hundred and fifty-six they had five hundred and twelve filters and then a max pooling layer then the same dense fully connected layers ok"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/90_16.wav", "duration": 13.0, "text": "so everyone gets this this is the difference between the two architectures and this led to that difference in the error of around three to four percent is that we have seen earlier"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/90_17.wav", "duration": 242.782, "text": "so difference the total number of parameters was one hundred and forty-five million and of course zfnet had more parameters because is that it has these more filters in the deeper layers ok so we go to the last point which is may be more in that vgg net"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/91_0.wav", "duration": 26.0, "text": "this is where we left off in the last class so we look at three networks for image classification starting with alex net then zf net and then vgg net vgg net in particular had sixteen layers including convolutions and fully connected layers and one thing that we saw that a large number of parameters are there in the first fully connected layer"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/91_1.wav", "duration": 110.227, "text": "because you are connecting a five hundred and twelve seven seven volume to a four thousand and ninety-six dimensional vector right so that is one thing the other thing that i would like to kind of mention right now so that it becomes useful for the later part of the lecture is that if i look at any of these pink boxes here right or even these things which are known as the fully connected layers and if i just flatten them out and view them as a vector what does that vector actually capture it captures a it captures an abstract representation of the image right so now imagine what would happen is suppose you have trained one of these networks alex net vgg net or any of your favorite networks and by what i mean by training is that you have been tracking the cross entropy laws and you have run it for several epochs with some patience and so on and i was satisfied with whatever training error you are getting and you have stopped training now right now after this if i pass images through these net through this network and i take the representation from any of these boxes or from the fully connected layer what is it that i have essentially got now i have got an abstract representation of the image that i have been feeding it right so just remember this and this is something that we will use so this is very common to do so you have a trained image net many people have released different models for image net the ones which we have covered being included them and now for him any image task if you want to do some processing then it\u2019s common to take the strain network pass your image through that so you can train any you can use any image trained image net and pass that image through it or sorry any trained convolutional network trained on image net and pass the image through that and you can get a representation for that image and these are known as the fc representations and these are as the convolution representations ok any of the convolution layers fine"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/92_0.wav", "duration": 12.0, "text": "so we will go to the next module where you wanted to look at two more architectures for image classification these are googlenet and resnet"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/92_1.wav", "duration": 683.0, "text": "so here is a question right so consider the output at a certain layer of a convolutional neural network so you have this layer after layer of convolutions and max pooling and so on and you are at somewhere in the middle and this is what your volume looks like this is what your output volume looks like now after that you could apply a max pooling layer you could apply a one one convolution you could apply a three three convolution or you could apply a five five convolution right and so far we saw that all these architectures they do one of these things they either do a max pooling or they do a three three convolution or they do a five five convolution or a seven seven eleven eleven right any convolution but they are all uniform they are all either three three all either five five or either seven seven right so why choose between these options why not do all of this at every layer do you get the question that i am trying to ask right so far what we were doing is that you have this volume this volume at a certain layer of the convolutional neural network and after that you are either using all three cross three filters so you are using two hundred and fifty-six three three filters or five into three three filters or using seven seven or using five five you are never using a mix of all these right so why not use a mix of all these why the why take a decision on that i only want three three because it is possible that you want to capture interactions at different levels so you should have varied size filters at every layer so how many of you get the question and the intuition that i am trying to ask ok so the idea here in googlenet or in the inception net is that why not apply all of them at the same time and then concatenate the feature maps right so i will also do max pooling i will also do three three feature maps i will also create five five eleven eleven and then just concatenate all of these together so let us see how to do that right"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/92_2.wav", "duration": 23.0, "text": "so this is exactly what i explained so instead of having this nasty looking connection which would have been fifty thousand, one hundred and seventy-six cross one thousand you just take the average from this grid and just get a one thousand and twenty-four dimensional vector which results in a much smaller weight matrix at the output everyone gets this so ok yeah so this is fine"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/92_3.wav", "duration": 611.431, "text": "so this has twelve times less parameters than alexnet it has two times more computations right so that is what i meant by the tradeoff so the number of parameters has reduced significantly of course a large amount of this savings happen in the fully connected layer its not the ingenuity in the inception module which led to the fewer number of parameters that actually leads to more number of parameters right but the reason they could afford more number of parameters in the convolution layers is because they reduced a lot of parameters in the fully connected layer do you get that so they did this tradeoff and it has two times more computations then alexnet but it is still acceptable because you see that there are many many layers as compared to alexnet right so let us actually count the number of layers that we had here so one two three four five six seven eight nine ten eleven twelve thirteen fourteen right so it has fourteen layers and each of these inception modules is again like split layer right it has this parallel components there so having two times more computations was still an acceptable tradeoff and it of course led to much better accuracy as compared to alexnet or zf net or vgg net right that we had seen in the original trend graph ok so now we will go on to the last architecture that we will discuss for image classification which is resnet"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/93_0.wav", "duration": 19.0, "text": "so in this lecture we will look at various ways of visualizing convolutional neural networks and although it is not very obvious at this point as we go along we will see what i mean by that so let us start this lecture"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/93_1.wav", "duration": 212.0, "text": "so i forgot to add the acknowledgments slide so a lot of the material that i am going to cover today is based on some content by andrey karpaty in his online course stanford course we will add the appropriate acknowledgments and a link to the course ok so with that i will start module one which is visualizing patches which maximally activate a neuron ok so what are we trying to do here is we are trying to the quest today largely is going to be able to understand what a cnn has actually learned right and what i mean by that is we said that there are these filters which try to detect edges which try to detect blurs and so on and then there are these neurons which fire for certain things and so on so we want to see different ways of finding out what a convolution neural network has actually learned or what have the filters actually learned or what are the different neurons in the convolutional neural network actually capturing what do they fire for what are the kind of images that make them trigger and so on right so that is the first thing that we are going to look at how do you visualize patches which are causing a neuron to fire"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/93_2.wav", "duration": 123.889, "text": "so let us look at the results of one such experiment done by a group of researchers so they considered some neurons in the pool five layer and they did this experiment that they pass a lot of images and whenever this neuron fired they went back and saw what was the patch in the image which was causing this neuron to fire so that they found that one set of neurons is actually fires for people places so if you go back and trace which is the image which caused is to fire or which is the patch then it is largely centered around a persons face or which is something which is very clearly a person ok another set of neurons fires for dogs another set of neurons fires for flowers all sorts of flowers and different orientations different maybe colors are same here but they are all different thing right somewhere inside a bouquet somewhere inside a flower pot some somewhere on a table and so on but expected of that these neurons are firing for any flowers that appear in your input image and the fire only for that patch nothing around it so it is very is actually able to localize and fire there are some images which fire for this images the digits and alphabets written in the image so these are some addresses or dates or billboard signs or something like that and whenever there are these characters or numerals there and this neurons fire and some neurons fire for houses and then some neurons fire for shiny surfaces so there is this different sets of neurons which fire for different sets of things right so also that means your convolutional neural network is trying to learn specific characters of the input characteristics of the input and this is one way of visualizing so this is not like anything tricky here it is just that its good you can think of this as debugging tools for your convolutional neural network right because in your you i guys are used to programming where you give different inputs and see what is the output and then try to debug it so this is one way of trying to figure out whether your network has learned does it really need more training is there a certain class of images for which it is not firing at all or is it confusing between two classes and so right so that is one way of visualizing"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/94_0.wav", "duration": 36.0, "text": "so now this was visualizing the neurons inside the convolutional neural network so neurons remember are the outputs right these are not these are the feature maps what about the weights itself what are the weights in a convolutional neural network student refer time twenty-five the filters the filters themselves are weight have you ever tried to visualize weights before when student auto encoders auto encoders and what was a trick there how did we student refer time thirty-six visualize what was the optimization problem that we solved student refer time forty how many of you went and looked at the prerequisites how many of you looked at the prerequisites ok"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/94_1.wav", "duration": 95.0, "text": "so we had done something similar while discussing auto encoders so because that we had done something similar while discussing auto encoders right so we were interested in knowing that there is a particular hidden neuron inside the auto encoder and we wanted to see that what does this neuron capture so if i give it emnist digits then what kind of patterns does it fire for and if you remember we had solved this optimization problem and realize that this neuron will fire for an input which looks like this where w1 or all the weights which are connecting to this neuron ok what was the dimension of the input if you are dealing with emnist digits student refer time one hundred and twenty-two seven hundred and eighty-four what is the dimension of this a one thing which i have circled here student refer time one hundred and twenty-seven seven hundred and eighty-four right it is written x equal to so it has to be seven hundred and eighty-four why is it seven hundred and eighty-four because there are seven hundred and eighty-four weights connecting each of the input pixels to that neuron right so that means this weight matrix itself we can visualize it as an image and thats exactly what we had done if you remember we had this grid of images that we were analyzing and in some images we saw that some dark element fires here and each we were arguing that this is the curve which exists in two or nine or eight and that is the one which is capturing and in some cases there was a cusp here which was firing and we were arguing that this could be for the three or for a nine or for a eight or something like that right so we were trying to visualize these things and the way we had plotted it was just treating this weight matrix or weight vector as an image and seeing what causes the neuron to fire right"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/94_2.wav", "duration": 62.0, "text": "so we can do something similar for convolutional neural networks i want you to think how would you do that i will give you some hints the answer is there on the next slide but i just want you to think about it right so remember here you have dense connections ok that means your weight vector was the same dimension as the input vector what about filters in the case of cnn they are smaller they are three three five five or seven seven much smaller than your original image so then what do these filters correspond to just think of the animation that we had seen right we had this image and we were taking a filter and applying it at different places so what does the filter correspond to what is the filter overlap with patches in the image right so now what kind of analysis can you do student dense what kind of patches does this filter fire for or what kind of patches does the neuron connected to this filter fire for does that make sense everyone gets the intuition how many if you get the intuition please raise your hands thank you"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/94_3.wav", "duration": 60.0, "text": "so now recall that we can think of a cnn as a feed forward neural network and in particular when you have a filter it actually interacts only with few pixels right so interacts with say pixel one two five and six so that is the patch that it interacts with and now i want to see when does this neuron fire so that is the same as asking what do i put in one two five six for this neuron to fire or similarly what do i put in three i do not know this was one two five six i guess so three four seven eight for the same different neuron to fire right but all these neurons fire because they are connected to the same filter so that means i am interested in these patches which will cause the neuron to fire and those patches can appear anywhere in their image is that fine that is the whole point of convolution neural networks wherever there is a nose whether it is at the top corner of the image or the center or the bottom it should be able to detect right that is the whole point of weight sharing and sparse connectivity ok"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/94_4.wav", "duration": 96.967, "text": "so we are going to do exactly the same thing we will have a three three filters or five five filters or seven seven filters were just going to visualize as them as images but unlike the earlier case where the image actually correspond to the full mnist image here these images are just corresponding to those three cross three or five cross five patches and you want to see what kind of patches causes the neurons to fire ok and the solution is still the same we will have this w by w the normalized weight filter weight which is causing the input to fire how many if you are fine with everything at this point please raise your hands high up"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/96_0.wav", "duration": 40.0, "text": "so now so far what we have done is we have seen the influence of neurons on the or what image patches cause a neuron to fire then we have visualized the weights so neurons have been visualized weights have been visualized then we have done some occlusion experiments on the input image now we will take this further and we are interested in seeing that what pixels in the image actually help in the output or in any neuron in the intermediate layers and we will find out some principal way of finding this influence right and we are going to use back propagation that means we are going to use gradients ok"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/96_1.wav", "duration": 81.0, "text": "so we can think of an image as an m cross n inputs going from x0 x1 all the way up to x m n nothing great about that and we are interested in finding the influence of each of these inputs on a given neuron ok now what is one way of computing influence that you have learned in this course what is the hero of this course gradients right so gradients tell you the influence so now can you tell me if i want to compute what is the influence of this neuron or this input on this neuron what would you do student refer time one hundred and twenty-seven hj xi but can you compute that how will you compute that how do you compute the gradient with respect to the input we have always stopped at the last hidden layer and the weights before that so how will we do that how will you do this ok this is a trick question just a hint is there a restriction on the chain rule or can you do it you can just keep adding links to the chain right so what is so difficult about that you already know how to compute the gradients till this point and in fact you will also know how to compute the gradients till this point and what is stopping you from doing it up to this point what if i just call this h instead of x then you would not have a problem right and actually we call it h right we call it h0 we can do it right it is straightforward so let us see"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/96_3.wav", "duration": 49.0, "text": "now the question is how do we compute these gradients so we will just treat them as a free forward neural network we already know how to do back propagation across these roots and we just need to add one more term to the chain right so i will just show you what we will do here so i am interested in h32 x2 so i will observe that there are four paths which go from h32 to x2 or rather from x2 to h32 so i will just sum up the gradients along these four paths right and if i solve it i will just be left with this ok so that is how i will visualize so this is very simple we have done a lot of gradients in class so you can just go back and check this and it should work out well ok so you can just see this and this way we can just compute the gradients for all the input pixels"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/96_4.wav", "duration": 48.507, "text": "and now i am going to plot it as a image and this is what my image looks like do you see what is happening here its all very murky right most of it is great that is fine we expected it but there is nothing really standing out right even in this patch where you have some non gray pixels it is almost like the entire cat region is appearing as non gray the influences are not coming out to be very sharp we would have wanted something like only the eye pixels cause some neuron to fire or only the ear pixels cause some neuron to fire and that is not really happening ok so it does not produce very sharp influences so someone proposed something known as guided back propagation which we are going to see next and that helps you to better understand the influence of the input pixels"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/97_0.wav", "duration": 10.0, "text": "so we will see what guided backpropagation is so idea here is a bit hacky a bist heuristically but it still works very well so let us see what it is right"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/97_1.wav", "duration": 241.003, "text": "so suppose you feed an input image to a convolutional neural network that image will go through all the convolution layers and say it one convolution layer this is what your feature map looks like i am operating at a very small scale i am just considering a two two feature map ok now we consider one neuron in some feature map at some layer ok so we will consider this particular neuron and we are finding interested in finding the influence of the input on this neutron so this is what i will do is i will set all the other neurons in this layer to zero because i do not care about them i only care about this particular neurons i just focus on that"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/98_0.wav", "duration": 16.0, "text": "ok the next thing that we are going to do is optimization over images so this is again interesting and it eventually led to this whole field of adversarial deep learning or adversarial machine learning in general right so we will see what this is"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/98_1.wav", "duration": 213.0, "text": "suppose i have a trained convolutional neural network ok and now i want to figure out what kind of image should i pass through this so that it gets recognized as a dumbbell why we want to do i would not want to have such a weird objective can you think of a reason why would want such a weird objective i know there is a convolutional neural network which can distinguish k classes these classes could be anything now i want to deliberately create images which get passed as the dumbbell class why would i want to do this ok you are going into your details so i will give you a application right suppose this network is supposed to do face detection and the k classes which are there are k people right now you want to see what kind of image should i feed to this so that i get recognized as amitabh bacchan right so now that could have certain benefits and various high places and so on its i would want to do that right so thats the whole idea behind adversarial learning so now i am asking this question that i want and here its in of course a toy setup there is no reason i why i would want to generate dumbbells but say if i am going to if its an automatic verification whether my product looks like a dumbbell or not i might want to do this right so you could think of all sorts of reasons why you want to do this so what we will do is the question that we are interested in is that i have a blank slate with me it just contains some pixels i want to be able to modify this pixel so that my class dumbbell class gets fired now we have done enough gradients enough back propagation everything in this class so i will ask you to give me a solution for this and the hint is treat the image itself as a parameter matrix the second hint is assume that all of this is going to remain constant you are not going to change any of this and you have initialized your parameters which is the image pixels to 0s that means you are started with a gray image now i will change the question a bit only a bit and all of you will be able to answer this ok suppose my network is strained and now i want to change the weights in this layer so that my accuracy improves so that when its a dumbbell class it predicts dumbbell how will you do that it will pass the same image what will you do how will you change the weights in this layer back propagation what is the update rule say the gradient descent update rule say that the gradient descent update rule student refer time three hundred and one w is equal to ok you guys actually unanimously said gradient is an update rule ok so w is equal to w minus oops oops oops ok minus eta into ok student refer time three hundred and sixteen thats what you will do now if i ask you the question for this you can answer it but if i ask you the same question here why cannot you answer it student refer time three hundred and twenty-seven so here what were you doing computing the gradients of the loss with respect to the weights what will you do here student refer time three hundred and thirty-three it put respect to each of these pixels and then update this pixel by using what formula student refer time three hundred and thirty-nine i1 thats the first pixel is equal to i1 minus eta gradient i1 where what is gradient i1 actually everyone gets the intuition right you can do it now"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/98_3.wav", "duration": 388.0, "text": "and now we can just think of the entire image as a collection of parameters and we can now update the weights of this matrix which is the image matrix ok"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/98_4.wav", "duration": 27.0, "text": "now let us see if we take a cup and this is like the trophy cup i believe so this is what is appearing here there is one more cup here and there is one more cup here its a generating these cups so that you cant be you would not be able to see it its different oh it really looks like i am manipulating it but i am not you can go back in check it those cups are there ok"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/98_5.wav", "duration": 23.0, "text": "and then for dalmatian actually this at least you can see some white and black spots right at least thats fine so dalmatians are these dog which have these white and black spots so and you can also see some kind of a shape here right which with my drawing so it is actually producing that doglike shape and its producing multiple of those so its being redundant i am trying to compute that right"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/98_6.wav", "duration": 37.0, "text": "and now you see right with these very arbitrary images which to you and me do not know nowhere close to we will fire will classify this as dalmatian but for the machine and is classifying this as a dalmatian and this is bad right this is not good there is nothing to be impressed about this is actually bad because i can give it these horrible images and still get away by something called as a dalmatian so if i want to sell some a dalmatian on olx this is what i can do right i can upload this image and a machine would trigger it and some one would buy it ok so and this is a bell paper so you can go back and see you see a lot of bell papers here and similar for lemon and so on right"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/98_8.wav", "duration": 40.0, "text": "so various classes you can see that its actually trying to produce those shapes but its nowhere actually producing a clear image which is undoubtedly of that object right is generating something which can later on be used to fool the network right which is not a good thing ok and we can actually do this for any arbitrary neuron so i was trying to actually fire this neuron which was the output layer but maybe i want something else to fire here so i want to actually see what is it that causes this neuron to fire so i could repeat the same algorithm by setting something here as high and then again back propagating the gradients only from here and reconstructing the image every time so that this neuron then five is right"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/98_9.wav", "duration": 31.996, "text": "so these are what the updated images look like which excite certain neurons and some layers so what does this look like its actually like a pirates ship if its not very clear you have these multiple layers of things and something like this ok so its some neurons are actually firing for this kind of a pattern there are some other neurons which are firing for different kinds of patterns and so on right so you can just create images which cause certain neurons to fire and all these are lot of fun to do so you should i would encourage you to do this i will get more insights into what your network is"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/99_0.wav", "duration": 8.0, "text": "the next thing that we will see is how do you create images from embedding so let me see what that means"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/99_1.wav", "duration": 142.0, "text": "so remember that each of these things can be thought of as an embedding of the image right because you had this original image which was two hundred and twenty-seven two hundred and twenty-seven dimensional and now you have a four thousand and ninety-six representation for that or a two hundred and fifty-six seven seven representation for that so you could just flatten it as an out as a vector and you could treat that as a embedding for the original image right now for any kind of embedding or hidden representation what do we always want from that representation think auto encoders it should capture all the important characteristics of the original image and in particular i should be able to dash the original image from it student refer time one hundred and three we construct the original image from it right so thats what i would want from a good embedding so let us see if we can do this right so find an image this is the optimization problem that i am interested in find an image such that its embedding a similar to a given embedding what do i mean by that is suppose i take a monkey image and pass it through all these layers and compute all these embeddings right now again i start with a blank image and my optimization problem is such that for this blank image i want to modify it so again this blank image is my parameter matrix and i want to modify it such that the embedding that it produces should be similar to the embeddings that the monkey image produced so how can you set this as a optimization problem what would your loss function be so lets call the original monkey images i1 and let us call this as embedding of i1 now can you tell me what the objective function would be for the new image that you are trying to create this entry the first entry in its output that let me call that e i two ok so e i two one and ei one one that means the first dimension of the embedding they should both be student very very close so in such cases what is the error function that we will choose student refer time two hundred and twenty-nine refer time two hundred and thirty right so you have to get comfortable with designing these loss functions right so you have seen you have seen this loss function before we just have to be able to related to the problem that you are trying to work on"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/99_2.wav", "duration": 33.0, "text": "so let phi zero be the embedding of the image of interest let x be a random image and we will report the repeat this forward pass using x and compute phi of x right that means were computing the embedding of this random image that we have started with then we compute this loss function and add appropriate regularization for that and that propagate and update what what will you update student refer time three hundred and six image right you will update your x matrix right and you will keep doing this till convergence"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/99_3.wav", "duration": 52.0, "text": "and let us see what happens so its suppose so now what i am trying to do is this is my original image and i have the convolution one embedding of it so in this i am using convolution one as the embedding and then i am trying to solve this optimization problem to recreate x such that its very close to the original image so let us see what are the different outputs that i get so this is the original image and on the right hand side you have the reconstructed image such that the conv one embedding of both the images is the same so you can see that when i am trying to do a reconstruction from the conv one layer i get almost the same image back now if i keep doing it from different layers what do you expect it to be if i do it from conv two conv three conv four and so on student refer time three hundred and fifty-nine it wont be so accurate right so let us see what happens if i try to reconstruct it from conv two"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/99_4.wav", "duration": 2.0, "text": "ah relu one"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/99_5.wav", "duration": 2.0, "text": "max pooling"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/99_8.wav", "duration": 222.0, "text": "relu two i am keep i am going deeper and deeper into the network so what i am trying to do here is remember that i have different choices for these embeddings so the first thing which i showed you was when i was trying to the first thing was when i was trying to set my objective function such that i am trying to map this embedding the second image that i showed you was when i was trying to map this embedding and the last image that i will show is when i was trying to map these to embedding so my objective function was to create an image such that this embedding of the created image is the same as this embedding of the original monkey image right so thats what i am progressively trying to do"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/99_9.wav", "duration": 5.0, "text": "as you can see as i keep going ahead i get more and more abstracter reconstructions and i dont really get the monkey back"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/99_10.wav", "duration": 3.0, "text": "and once i go to the last fc six or f seven layers i get very weird looking reconstructions"}
{"audio_filepath": "/home/richard/Downloads/AI4Bharat/Final_run/audio_chunks_new/99_11.wav", "duration": 49.077, "text": "and thats expected right because by that layer they have completely abstracted it out right you have just probably captured there is something like a nose something like eyes or some for here and there but you have loss the entire shape and other characteristics of the original image right from the deeper layer the construction would not be that good and thats kind of expected right"}
